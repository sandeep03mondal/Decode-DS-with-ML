{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLlDthLdJXFf"
      },
      "source": [
        "###1.1.What is the difference between static and dynamic variables in Python , with example?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvdMtXbwJjNF"
      },
      "source": [
        "Scope and Lifetime:\n",
        "\n",
        "Static Variables: Shared among all instances of a class. They are defined at the class level and exist as long as the class exists.\n",
        "\n",
        "\n",
        "Dynamic Variables: Unique to each instance of a class. They are defined within instance methods and exist as long as the instance exists.\n",
        "Access:\n",
        "\n",
        "Static Variables: Accessed using the class name or instance name (MyClass.static_var or obj.static_var).\n",
        "\n",
        "\n",
        "Dynamic Variables: Accessed using the instance name (obj.instance_var).\n",
        "Modification:\n",
        "\n",
        "Static Variables: Modifying a static variable affects all instances of the class.\n",
        "\n",
        "\n",
        "Dynamic Variables: Modifying an instance variable affects only that particular instance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXQyypfNKwzY",
        "outputId": "097b3e36-8988-4191-a0ec-5c92bbdff457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "#static variables\n",
        "\n",
        "class MyClass:\n",
        "    # Static variable\n",
        "    static_var = 0\n",
        "\n",
        "    def __init__(self, instance_var):\n",
        "        # Dynamic variable\n",
        "        self.instance_var = instance_var\n",
        "\n",
        "# Create two instances of MyClass\n",
        "obj1 = MyClass(1)\n",
        "obj2 = MyClass(2)\n",
        "\n",
        "# Access and modify static variable\n",
        "print(MyClass.static_var)  # Output: 0\n",
        "MyClass.static_var = 10\n",
        "print(MyClass.static_var)  # Output: 10\n",
        "print(obj1.static_var)     # Output: 10\n",
        "print(obj2.static_var)     # Output: 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXTXQ47yLQM4",
        "outputId": "3a9b992c-b5d0-41c0-9fe5-71e0939c721d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "5\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "#Dynamic variables\n",
        "\n",
        "class MyClass:\n",
        "    # Static variable\n",
        "    static_var = 0\n",
        "\n",
        "    def __init__(self, instance_var):\n",
        "        # Dynamic variable\n",
        "        self.instance_var = instance_var\n",
        "\n",
        "# Create two instances of MyClass\n",
        "obj1 = MyClass(1)\n",
        "obj2 = MyClass(2)\n",
        "\n",
        "# Access and modify instance variables\n",
        "print(obj1.instance_var)  # Output: 1\n",
        "print(obj2.instance_var)  # Output: 2\n",
        "\n",
        "obj1.instance_var = 5\n",
        "print(obj1.instance_var)  # Output: 5\n",
        "print(obj2.instance_var)  # Output: 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqTuIy2aL2OR"
      },
      "source": [
        "### 2. Explain the purpose of \"pop\",\"popitem\",\"clear()\" in a dictionary with suitable examples?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEahCUXWL844"
      },
      "source": [
        "\n",
        "In Python, dictionaries are collections of key-value pairs. The methods pop, popitem, and clear are used to manipulate the contents of a dictionary by removing elements.\n",
        "\n",
        "\n",
        "**pop()**\n",
        "\n",
        "The pop() method removes and returns the value associated with the specified key. If the key is not found, it raises a KeyError unless a default value is provided.\n",
        "\n",
        "syntax\n",
        "dict.pop(key[, default])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ5fBUqeMa0B",
        "outputId": "4425d05c-ada8-4b15-d33f-1689b692a275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "{'a': 1, 'c': 3}\n",
            "default\n"
          ]
        }
      ],
      "source": [
        "#Example of pop\n",
        "\n",
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "# Remove and return the value for key 'b'\n",
        "value = my_dict.pop('b')\n",
        "print(value)\n",
        "print(my_dict)\n",
        "\n",
        "# Remove and return the value for key 'd' with a default value\n",
        "value = my_dict.pop('d', 'default')\n",
        "print(value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTo_AvLnMnsb"
      },
      "source": [
        "**popitem()**\n",
        "\n",
        "The popitem() method removes and returns the last key-value pair inserted into the dictionary as a tuple. This method is useful for implementing LIFO (Last In, First Out) data structures. If the dictionary is empty, it raises a KeyError.\n",
        "\n",
        "syntax\n",
        "dict.popitem()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4uYhrH9MvgQ",
        "outputId": "65c5fd62-76c2-4694-bc46-c03dd125a6f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('c', 3)\n",
            "{'a': 1, 'b': 2}\n"
          ]
        }
      ],
      "source": [
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "# Remove and return the last key-value pair\n",
        "item = my_dict.popitem()\n",
        "print(item)\n",
        "print(my_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwTDrPhiM6JS"
      },
      "source": [
        "**clear()**\n",
        "\n",
        "The clear() method removes all items from the dictionary, resulting in an empty dictionary.\n",
        "\n",
        "syntax\n",
        "dict.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ige6ElqqNBtX",
        "outputId": "37c426b4-b603-47df-b8d6-d6f8c3060166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{}\n"
          ]
        }
      ],
      "source": [
        "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "\n",
        "# Clear all items from the dictionary\n",
        "my_dict.clear()\n",
        "print(my_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQMeOQiNGpG"
      },
      "source": [
        "###3.  What do you mean by FrozenSet? Explain it with suitable examples?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw223c2hNc-B"
      },
      "source": [
        "A frozenset is an immutable version of a Python set. Once a frozenset is created, its elements cannot be modified, added, or removed. This immutability makes frozenset hashable, meaning it can be used as a key in a dictionary or as an element of another set, whereas regular sets cannot be used in these contexts.\n",
        "\n",
        "**Characteristics of frozenset**\n",
        "\n",
        "Immutability: Elements cannot be changed after the frozenset is created.\n",
        "Hashability: Can be used as dictionary keys or elements of other sets.\n",
        "Unordered and Unindexed: Like sets, frozenset does not maintain order and does not support indexing or slicing.\n",
        "\n",
        "**Creating a frozenset**\n",
        "\n",
        "A frozenset can be created using the frozenset() function, optionally taking an iterable (like a list, tuple, or set) as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrLBWSQFNwLB",
        "outputId": "11aa66ff-71d0-4eee-db14-ffca7666c2b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frozenset({1, 2, 3, 4})\n",
            "frozenset({'b', 'c', 'a'})\n",
            "frozenset()\n"
          ]
        }
      ],
      "source": [
        "# Creating a frozenset from a list\n",
        "frozen_set1 = frozenset([1, 2, 3, 4])\n",
        "print(frozen_set1)\n",
        "\n",
        "# Creating a frozenset from a tuple\n",
        "frozen_set2 = frozenset(('a', 'b', 'c'))\n",
        "print(frozen_set2)\n",
        "\n",
        "# Creating an empty frozenset\n",
        "empty_frozen_set = frozenset()\n",
        "print(empty_frozen_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqQSQntHQAIG"
      },
      "source": [
        "###4. Differentiate between mutable and immutable data types in Python and give examples of mutable and\n",
        "immutable data types?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DXtwiMGQPTO"
      },
      "source": [
        "**Modification:**\n",
        "\n",
        "Mutable: Can be changed after creation.\n",
        "\n",
        "Immutable: Cannot be changed after creation.\n",
        "\n",
        "**Examples**:\n",
        "\n",
        "Mutable: List, Dictionary, Set, Byte Array.\n",
        "\n",
        "Immutable: String, Tuple, Frozen Set, Integer, Float, Boolean.\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "Mutable types are useful when you need to change the content frequently.\n",
        "\n",
        "Immutable types are useful for fixed values and ensuring that the data remains constant throughout the program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "027auYtWQuv8",
        "outputId": "dd4e9c93-072a-4aa2-c3d4-29d55ca4b466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello\n",
            "HELLO\n"
          ]
        }
      ],
      "source": [
        "#immutable\n",
        "my_string = \"hello\"\n",
        "new_string = my_string.upper()  # Creating a new string\n",
        "print(my_string)\n",
        "print(new_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-wlqlUkQ_Fd",
        "outputId": "6ebb5040-e73c-4edb-806b-59c096908577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 2, 3)\n",
            "(1, 2, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "#immutable\n",
        "my_tuple = (1, 2, 3)\n",
        "new_tuple = my_tuple + (4,)     # Creating a new tuple\n",
        "print(my_tuple)                 # Output: (1, 2, 3)\n",
        "print(new_tuple)                # Output: (1, 2, 3, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgGG7YkdRJIg",
        "outputId": "9c267eff-bf40-4693-9bbb-a998919b448f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frozenset({1, 2, 3})\n"
          ]
        }
      ],
      "source": [
        "#immutable\n",
        "my_frozenset = frozenset([1, 2, 3])\n",
        "# my_frozenset.add(4)           # This would raise an AttributeError\n",
        "print(my_frozenset)             # Output: frozenset({1, 2, 3})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8trIGKRIRU_V",
        "outputId": "021a07f9-faba-40a0-e543-4e49db722d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "11\n"
          ]
        }
      ],
      "source": [
        "#immutable\n",
        "my_int = 10\n",
        "new_int = my_int + 1            # Creating a new integer\n",
        "print(my_int)                   # Output: 10\n",
        "print(new_int)                  # Output: 11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPSoT6z9RgGN",
        "outputId": "2c92678d-e70c-45bd-d9b8-928174cd3c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "#mutable\n",
        "my_list = [1, 2, 3]\n",
        "my_list.append(4)      # Modifying the list\n",
        "print(my_list)         # Output: [1, 2, 3, 4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O23zqJKhRqZf",
        "outputId": "4e3c00e7-c839-4239-fccf-4f9ff179e213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3}\n"
          ]
        }
      ],
      "source": [
        "my_dict = {'a': 1, 'b': 2}\n",
        "my_dict['c'] = 3       # Adding a new key-value pair\n",
        "print(my_dict)         # Output: {'a': 1, 'b': 2, 'c': 3}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9hjGE9aRwey",
        "outputId": "940e9f0f-3593-4fd1-be40-d568235a79b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "my_set = {1, 2, 3}\n",
        "my_set.add(4)          # Adding an element to the set\n",
        "print(my_set)          # Output: {1, 2, 3, 4}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDcNz8ER2BK"
      },
      "source": [
        "###5. What is __init__?Explain with an example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHwnQ97OR8O7"
      },
      "source": [
        "\n",
        "The __init__ method in Python is a special method known as a constructor. It is automatically called when an instance (object) of a class is created. The purpose of the __init__ method is to initialize the newly created object's attributes with the values passed to it during the creation of the object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UTF2F4ZSH8s",
        "outputId": "84a756e7-25b0-49a6-9f97-77ba057e7329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: Alice, Age: 30\n",
            "Name: Bob, Age: 25\n"
          ]
        }
      ],
      "source": [
        "class Person:\n",
        "    def __init__(self, name, age):\n",
        "        self.name = name  # Initialize the 'name' attribute\n",
        "        self.age = age    # Initialize the 'age' attribute\n",
        "\n",
        "    def display(self):\n",
        "        print(f\"Name: {self.name}, Age: {self.age}\")\n",
        "\n",
        "# Creating instances of the Person class\n",
        "person1 = Person(\"Alice\", 30)\n",
        "person2 = Person(\"Bob\", 25)\n",
        "\n",
        "# Displaying the details of each person\n",
        "person1.display()  # Output: Name: Alice, Age: 30\n",
        "person2.display()  # Output: Name: Bob, Age: 25\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMmy_HDiSXI9"
      },
      "source": [
        "###6. What is docstring in Python?Explain with an example?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OurOWLBkScvk"
      },
      "source": [
        "Purpose: To document the functionality, parameters, return values, and any other relevant information about the code.\n",
        "\n",
        "\n",
        "Syntax: Enclosed in triple quotes (\"\"\" ... \"\"\" or ''' ... ''').\n",
        "\n",
        "\n",
        "Accessibility: Can be accessed using the __doc__ attribute of the function, class, or module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkTAMrP_SqOO",
        "outputId": "78677e20-50cb-4e02-8758-5ed788f27f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Add two numbers and return the result.\n",
            "\n",
            "    Parameters:\n",
            "    a (int or float): The first number to be added.\n",
            "    b (int or float): The second number to be added.\n",
            "\n",
            "    Returns:\n",
            "    int or float: The sum of the two numbers.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "def add(a, b):\n",
        "    \"\"\"\n",
        "    Add two numbers and return the result.\n",
        "\n",
        "    Parameters:\n",
        "    a (int or float): The first number to be added.\n",
        "    b (int or float): The second number to be added.\n",
        "\n",
        "    Returns:\n",
        "    int or float: The sum of the two numbers.\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "# Accessing the docstring\n",
        "print(add.__doc__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XPfm6sdSzY8"
      },
      "source": [
        "###7. What are unit tests in Python\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYClNKh6S-LN"
      },
      "source": [
        "Unit tests in Python are a way to validate that individual units of code (usually functions or methods) work as expected. They are an essential part of the development process, helping ensure that code behaves correctly and that changes or additions to the codebase do not introduce new bugs.\n",
        "\n",
        "Isolation: Each test should be independent of others. Changes in one part of the code should not affect the outcome of other tests.\n",
        "\n",
        "Automation: Unit tests can be run automatically to verify that the code meets the specified requirements.\n",
        "\n",
        "Repeatability: Tests should produce the same results every time they are run, given the same inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "aWXVKGh2Tdru",
        "outputId": "13307dc8-0994-4054-e4e7-0325d0d9abf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E\n",
            "======================================================================\n",
            "ERROR: /root/ (unittest.loader._FailedTest)\n",
            "----------------------------------------------------------------------\n",
            "AttributeError: module '__main__' has no attribute '/root/'\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.006s\n",
            "\n",
            "FAILED (errors=1)\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "True",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Calculator:\n",
        "    def add(self, a, b):\n",
        "        return a + b\n",
        "\n",
        "    def subtract(self, a, b):\n",
        "        return a - b\n",
        "\n",
        "    def multiply(self, a, b):\n",
        "        return a * b\n",
        "\n",
        "    def divide(self, a, b):\n",
        "        if b == 0:\n",
        "            raise ValueError(\"Cannot divide by zero\")\n",
        "        return a / b\n",
        "\n",
        "#Writing Unit Tests\n",
        "\n",
        "import unittest\n",
        "\n",
        "class TestCalculator(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.calc = Calculator()\n",
        "\n",
        "    def test_add(self):\n",
        "        self.assertEqual(self.calc.add(2, 3), 5)\n",
        "        self.assertEqual(self.calc.add(-1, 1), 0)\n",
        "        self.assertEqual(self.calc.add(-1, -1), -2)\n",
        "\n",
        "    def test_subtract(self):\n",
        "        self.assertEqual(self.calc.subtract(3, 2), 1)\n",
        "        self.assertEqual(self.calc.subtract(-1, 1), -2)\n",
        "        self.assertEqual(self.calc.subtract(-1, -1), 0)\n",
        "\n",
        "    def test_multiply(self):\n",
        "        self.assertEqual(self.calc.multiply(2, 3), 6)\n",
        "        self.assertEqual(self.calc.multiply(-1, 1), -1)\n",
        "        self.assertEqual(self.calc.multiply(-1, -1), 1)\n",
        "\n",
        "    def test_divide(self):\n",
        "        self.assertEqual(self.calc.divide(6, 3), 2)\n",
        "        self.assertEqual(self.calc.divide(-1, 1), -1)\n",
        "        self.assertEqual(self.calc.divide(-1, -1), 1)\n",
        "        with self.assertRaises(ValueError):\n",
        "            self.calc.divide(1, 0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBRXbpShUZbU"
      },
      "source": [
        "###8. What is break, continue and pass in Python\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVRGxqIjUkrj"
      },
      "source": [
        "**break**\n",
        "\n",
        "The break statement is used to exit a loop prematurely when a certain condition is met. It can be used in both for and while loops.\n",
        "\n",
        "**continue**\n",
        "\n",
        "The continue statement is used to skip the rest of the code inside the current iteration of the loop and move to the next iteration. It can be used in both for and while loops.\n",
        "\n",
        "**pass**\n",
        "\n",
        "The pass statement is a null operation; it does nothing when executed. It is used as a placeholder for future code. When pass is executed, nothing happens, but it can be useful to fill syntactical requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLWXCDncUw-O",
        "outputId": "0365e290-a68d-422c-d3cf-58ce0dec42a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "#break\n",
        "for i in range(10):\n",
        "    if i == 5:\n",
        "        break\n",
        "    print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y-F1quOU7UB",
        "outputId": "3d07cdf3-5ac5-425a-d82a-c6b5ed47b961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "#continue\n",
        "for i in range(10):\n",
        "    if i % 2 == 0:\n",
        "        continue\n",
        "    print(i)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_mFhPOcVBxO",
        "outputId": "2e683624-fac7-46b6-b271-d621943522e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "#pass\n",
        "for i in range(10):\n",
        "    if i % 2 == 0:\n",
        "        pass  # Placeholder for future code\n",
        "    else:\n",
        "        print(i)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPH9ARCN-mT8"
      },
      "source": [
        "### 9. What is the use of self in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqYQVJAIY12"
      },
      "source": [
        "In Python, self is a reference to the instance of the class being manipulated. It is used within class methods to access instance variables and methods.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DORbTsYLInAz",
        "outputId": "034601db-ad37-4271-ebfd-d8b0a7d23935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buddy says woof!\n",
            "Hello, Buddy! Buddy says woof!\n",
            "Max\n",
            "Buddy says woof!\n"
          ]
        }
      ],
      "source": [
        "#Instance Variable Access\n",
        "class Dog:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def speak(self):\n",
        "        return f\"{self.name} says woof!\"\n",
        "\n",
        "my_dog = Dog(\"Buddy\")\n",
        "print(my_dog.speak())  # Outputs: Buddy says woof!\n",
        "\n",
        "#Calling Other Methods\n",
        "class Dog:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def speak(self):\n",
        "        return f\"{self.name} says woof!\"\n",
        "\n",
        "    def greet(self):\n",
        "        return f\"Hello, {self.name}!\"\n",
        "\n",
        "    def full_greet(self):\n",
        "        return self.greet() + \" \" + self.speak()\n",
        "\n",
        "my_dog = Dog(\"Buddy\")\n",
        "print(my_dog.full_greet())  # Outputs: Hello, Buddy! Buddy says woof!\n",
        "\n",
        "#Distinguishing Between Instance and Local Variables\n",
        "class Dog:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def set_name(self, name):\n",
        "        self.name = name  # self.name is the instance variable, name is the local variable\n",
        "\n",
        "my_dog = Dog(\"Buddy\")\n",
        "my_dog.set_name(\"Max\")\n",
        "print(my_dog.name)  # Outputs: Max\n",
        "\n",
        "#Inheritance and Method Overriding\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Some generic sound\"\n",
        "\n",
        "class Dog(Animal):\n",
        "    def speak(self):\n",
        "        return f\"{self.name} says woof!\" if hasattr(self, 'name') else super().speak()\n",
        "\n",
        "my_dog = Dog()\n",
        "my_dog.name = \"Buddy\"\n",
        "print(my_dog.speak())  # Outputs: Buddy says woof!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1CKhZQ1-nxr"
      },
      "source": [
        "###10. What are global, protected and private attributes in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9PBrXGQJsst"
      },
      "source": [
        "Global Attributes\n",
        "\n",
        "Global attributes are not typically defined within a class. They are defined outside any class or function and are accessible throughout the entire module .\n",
        "\n",
        "Protected Attributes\n",
        "\n",
        "Protected attributes are intended to be accessible within the class and its subclasses but not from outside these classes. By convention, protected attributes in Python are prefixed with a single underscore (_).\n",
        "\n",
        "Private Attributes\n",
        "\n",
        "Private attributes are intended to be accessible only within the class in which they are defined. In Python, private attributes are prefixed with a double underscore (__).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "YC0xcY0LKFzX",
        "outputId": "0cbefe73-6899-4b4e-9bd8-a2f8696ee05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is protected\n",
            "This is protected\n",
            "This is private\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MyClass' object has no attribute '__private_var'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bad0e7b5947f>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_private_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Outputs: This is private\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__private_var\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Raises an AttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'MyClass' object has no attribute '__private_var'"
          ]
        }
      ],
      "source": [
        "#Global Attributes\n",
        "GLOBAL_VAR = 100  # This is a global variable\n",
        "\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.instance_var = GLOBAL_VAR\n",
        "\n",
        "    def print_global(self):\n",
        "        print(GLOBAL_VAR)\n",
        "#Protected Attributes\n",
        "class BaseClass:\n",
        "    def __init__(self):\n",
        "        self._protected_var = \"This is protected\"\n",
        "\n",
        "class SubClass(BaseClass):\n",
        "    def access_protected(self):\n",
        "        return self._protected_var\n",
        "\n",
        "obj = SubClass()\n",
        "print(obj.access_protected())  # Outputs: This is protected\n",
        "print(obj._protected_var)      # Technically allowed, but not recommended\n",
        "\n",
        "#Private Attributes\n",
        "class MyClass:\n",
        "    def __init__(self):\n",
        "        self.__private_var = \"This is private\"\n",
        "\n",
        "    def get_private_var(self):\n",
        "        return self.__private_var\n",
        "\n",
        "obj = MyClass()\n",
        "print(obj.get_private_var())  # Outputs: This is private\n",
        "print(obj.__private_var)      # Raises an AttributeError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ7eWxfR-s7R"
      },
      "source": [
        "### 11. What are modules and packages in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywr2wScuKk78"
      },
      "source": [
        "Modules\n",
        "\n",
        "A module is a single file containing Python code. It can define functions, classes, and variables, and it can also include runnable code. Modules help organize code by grouping related functionality together.\n",
        "\n",
        "Packages\n",
        "A package is a collection of related modules organized in a directory hierarchy. A package must include a special file named __init__.py, which can be empty or contain initialization code for the package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q86vUbV-MsI4"
      },
      "outputs": [],
      "source": [
        "# mymodule.py\n",
        "def greet(name):\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "class Person:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def introduce(self):\n",
        "        return f\"Hi, I am {self.name}.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8JVGExzMvuv"
      },
      "outputs": [],
      "source": [
        "# main.py\n",
        "import mymodule\n",
        "\n",
        "print(mymodule.greet(\"Alice\"))\n",
        "\n",
        "person = mymodule.Person(\"Bob\")\n",
        "print(person.introduce())\n",
        "\n",
        "from mymodule import greet, Person\n",
        "\n",
        "print(greet(\"Alice\"))\n",
        "\n",
        "person = Person(\"Bob\")\n",
        "print(person.introduce())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "MisVMzQgM8Oj",
        "outputId": "0a667c8f-713c-4043-e933-fc4cb8840cc6"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '├' (U+251C) (<ipython-input-8-80c880382dc6>, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-80c880382dc6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ├── __init__.py\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '├' (U+251C)\n"
          ]
        }
      ],
      "source": [
        "mypackage/\n",
        "├── __init__.py\n",
        "├── module1.py\n",
        "└── module2.py\n",
        "# module1.py\n",
        "def func1():\n",
        "    return \"Function 1 from module 1\"\n",
        "\n",
        "# module2.py\n",
        "def func2():\n",
        "    return \"Function 2 from module 2\"\n",
        "# main.py\n",
        "from mypackage import module1, module2\n",
        "\n",
        "print(module1.func1())\n",
        "print(module2.func2())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek2mJ9U8-t4m"
      },
      "source": [
        "###12. What are lists and tuples? What is the key difference between the two ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqvnzVGPOeZN"
      },
      "source": [
        "Lists-\n",
        "\n",
        "Definition: A list is an ordered collection of items which can be of different types. Lists are mutable, meaning their elements can be changed after they are created.\n",
        "\n",
        "Tuples-\n",
        "\n",
        "Definition: A tuple is an ordered collection of items which can also be of different types. Tuples are immutable, meaning once they are created, their elements cannot be changed.\n",
        "\n",
        "**Difference**\n",
        "\n",
        "\n",
        "Mutability:\n",
        "\n",
        "Lists: Mutable (elements can be changed).\n",
        "\n",
        "Tuples: Immutable (elements cannot be changed).\n",
        "\n",
        "Syntax:\n",
        "\n",
        "Lists: Defined with square brackets [].\n",
        "\n",
        "Tuples: Defined with parentheses ().\n",
        "\n",
        "Performance:\n",
        "\n",
        "Lists: Slightly slower than tuples due to their mutability.\n",
        "\n",
        "Tuples: Slightly faster than lists due to their immutability.\n",
        "\n",
        "Use Cases:\n",
        "\n",
        "Lists: Suitable for collections of items that need to be modified.\n",
        "\n",
        "Tuples: Suitable for collections of items that should not be changed, such as constants or fixed collections.\n",
        "\n",
        "Methods:\n",
        "\n",
        "Lists: Have more built-in methods for adding, removing, and modifying elements (e.g., append(), remove(), pop()).\n",
        "\n",
        "Tuples: Have fewer methods, mainly for operations that don't modify the tuple (e.g., count(), index())."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZjJg2zsOrXi",
        "outputId": "0e271f77-684a-4635-f8a4-1b8d595ee9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'cherry', 'date']\n",
            "(10.0, 20.0)\n"
          ]
        }
      ],
      "source": [
        "# List example\n",
        "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
        "fruits.append(\"date\")\n",
        "print(fruits)  # Outputs: [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
        "\n",
        "# Tuple example\n",
        "coordinates = (10.0, 20.0)\n",
        "print(coordinates)  # Outputs: (10.0, 20.0)\n",
        "# coordinates[0] = 15.0  # This will raise a TypeError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfNWmsi2-yJv"
      },
      "source": [
        "13. What is an Interpreted language & dynamically typed language?Write 5 differences between them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a22fwabQPWWN"
      },
      "source": [
        "\n",
        "### Interpreted Language\n",
        "\n",
        "An interpreted language is a type of programming language where most of its implementations execute instructions directly, without the need for prior compilation into machine-language instructions. In an interpreted language, the source code is typically translated and executed line by line by an interpreter.\n",
        "\n",
        "**Examples**: Python, JavaScript, Ruby, PHP\n",
        "\n",
        "### Dynamically Typed Language\n",
        "\n",
        "A dynamically typed language is a type of programming language in which variable types are determined at runtime rather than at compile time. In a dynamically typed language, you do not need to explicitly declare the type of a variable; the interpreter assigns the type based on the variable's value at runtime.\n",
        "\n",
        "**Examples**: Python, JavaScript, Ruby, PHP\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "While interpreted languages and dynamically typed languages often overlap (many interpreted languages are also dynamically typed), they refer to different aspects of a programming language. Here are five key differences:\n",
        "\n",
        "1. **Compilation vs. Interpretation**:\n",
        "   - **Interpreted Language**: Code is executed line by line by an interpreter, without the need for compilation into machine code.\n",
        "   - **Dynamically Typed Language**: Variable types are checked and assigned at runtime, regardless of whether the language is interpreted or compiled.\n",
        "\n",
        "2. **Execution Speed**:\n",
        "   - **Interpreted Language**: Generally slower than compiled languages because code is translated on the fly during execution.\n",
        "   - **Dynamically Typed Language**: Type checking at runtime can introduce overhead, potentially slowing down execution compared to statically typed languages.\n",
        "\n",
        "3. **Type Declaration**:\n",
        "   - **Interpreted Language**: Does not inherently require or enforce specific type declarations; this is orthogonal to whether a language is interpreted or compiled.\n",
        "   - **Dynamically Typed Language**: Variables do not need explicit type declarations; their types are inferred at runtime based on their assigned values.\n",
        "\n",
        "4. **Error Detection**:\n",
        "   - **Interpreted Language**: Errors are detected at runtime, often leading to errors being caught only when the interpreter reaches the erroneous code.\n",
        "   - **Dynamically Typed Language**: Type-related errors are detected at runtime, which can lead to type errors appearing only when the erroneous code is executed.\n",
        "\n",
        "5. **Use Cases**:\n",
        "   - **Interpreted Language**: Often used for scripting, web development, and situations where rapid development and ease of debugging are important. Examples include scripting in Python or web development in JavaScript.\n",
        "   - **Dynamically Typed Language**: Useful for rapid development and flexibility, as developers can write code without worrying about type declarations. Examples include prototyping in Python or dynamic web applications in JavaScript."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQDAZEkZ-5FV"
      },
      "source": [
        "###14. What are Dict and List comprehensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXPzJNCUQAHG"
      },
      "source": [
        "List Comprehensions\n",
        "\n",
        "List comprehensions provide a compact way to create lists.\n",
        "\n",
        "Dict Comprehensions\n",
        "\n",
        "Dict comprehensions provide a similar way to create dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT6X8VddQLLA",
        "outputId": "c835bda0-e943-4660-de8b-b2085bc8c6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
            "{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n"
          ]
        }
      ],
      "source": [
        "#List Comprehensions\n",
        "\n",
        "squares = [x**2 for x in range(10)]\n",
        "print(squares)  # Outputs: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
        "\n",
        "#Dict Comprehensions\n",
        "squares_dict = {x: x**2 for x in range(10)}\n",
        "print(squares_dict)\n",
        "# Outputs: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElcENN7S-71n"
      },
      "source": [
        "###15. What are decorators in Python? Explain it with an example.Write down its use cases?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C5LBBZSQdK3"
      },
      "source": [
        "A decorator is a function that wraps another function. The primary function is passed to the decorator, and the decorator returns a modified function.\n",
        "\n",
        "Syntax\n",
        "The @decorator_name syntax is syntactic sugar for applying decorators.\n",
        "\n",
        "Use Cases\n",
        "\n",
        "Decorators are used in various scenarios. Here are some common use cases:\n",
        "\n",
        "Logging: To log the function calls, arguments, and return values.\n",
        "Authorization: To check if a user is authorized to use an endpoint or function.\n",
        "Memoization: To cache the results of expensive function calls and reuse the cached result when the same inputs occur again.\n",
        "Timing: To measure the time a function takes to execute.\n",
        "Validation: To validate the inputs and outputs of a function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dpHmPRCRUlg",
        "outputId": "2435dc72-4eb7-484b-9a99-8bb5192fc1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling add with args: (3, 5), kwargs: {}\n",
            "add returned 8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def log_decorator(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        print(f\"Calling {func.__name__} with args: {args}, kwargs: {kwargs}\")\n",
        "        result = func(*args, **kwargs)\n",
        "        print(f\"{func.__name__} returned {result}\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@log_decorator\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "add(3, 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7teG84mRsHy"
      },
      "source": [
        "###16. How is memory managed in Python\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoHT6rnSSNET"
      },
      "source": [
        "Memory management in Python involves several mechanisms to ensure efficient allocation, usage, and deallocation of memory during the execution of a program.\n",
        "\n",
        "### 1. **Memory Allocation**\n",
        "Python uses a private heap to store objects and data structures. The management of this private heap is ensured internally by the Python memory manager. The memory manager has different components to handle different aspects of memory management:\n",
        "\n",
        "- **Object-specific allocators**: For example, integers, strings, and tuples have dedicated allocators.\n",
        "- **General-purpose allocator**: Used for other types of objects.\n",
        "\n",
        "### 2. **Reference Counting**\n",
        "Python uses a reference counting mechanism as part of its memory management strategy. Each object in memory has an associated reference count which tracks the number of references to that object. When the reference count drops to zero, the memory occupied by the object is deallocated.\n",
        "\n",
        "- **Reference count increment**: When a new reference to an object is created.\n",
        "- **Reference count decrement**: When a reference to an object is removed.\n",
        "\n",
        "### 3. **Garbage Collection**\n",
        "In addition to reference counting, Python also employs a cyclic garbage collector to deal with reference cycles (where two or more objects reference each other). The garbage collector:\n",
        "\n",
        "- **Identifies cyclic references**: It looks for groups of objects that reference each other but are no longer accessible from any other part of the program.\n",
        "- **Collects cyclic garbage**: It deallocates the memory occupied by these cyclic references.\n",
        "\n",
        "### 4. **Memory Pools and Arenas**\n",
        "To optimize memory allocation, Python uses a system of memory pools and arenas.\n",
        "\n",
        "- **Pools**: These are chunks of memory allocated for objects of the same size class.\n",
        "- **Arenas**: These are larger chunks of memory that are subdivided into pools.\n",
        "\n",
        "### 5. **Pymalloc**\n",
        "Python includes a specialized allocator called `pymalloc` for small objects (less than 512 bytes). `pymalloc` is designed to be fast and efficient, reducing the overhead of allocating and deallocating small objects.\n",
        "\n",
        "### 6. **Automatic Memory Management**\n",
        "Python's memory management is largely automatic. The programmer does not need to manually allocate or deallocate memory. This is managed by Python's memory manager, making memory management simpler and less error-prone compared to languages like C or C++.\n",
        "\n",
        "### Example\n",
        "Here’s a simple example to illustrate memory management in Python:\n",
        "\n",
        "```python\n",
        "# Creating a list\n",
        "my_list = [1, 2, 3, 4, 5]\n",
        "\n",
        "# The reference count of the list increases\n",
        "another_reference = my_list\n",
        "\n",
        "# The reference count of the list decreases\n",
        "del another_reference\n",
        "\n",
        "# If no more references exist, the memory is deallocated\n",
        "del my_list\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ9Za-Cx7-NT"
      },
      "source": [
        "### 17. What is lambda in Python? Why is it used\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVTo53fx8AHH"
      },
      "source": [
        "A lambda function in Python is a small anonymous function defined using the lambda keyword. Unlike regular functions defined using def, lambda functions are typically used for creating small, one-off functions without needing to formally define a named function.\n",
        "\n",
        "Syntax:-\n",
        "lambda arguments: expression\n",
        "\n",
        "Why Use Lambda Functions?\n",
        "Lambda functions are used in various scenarios where small, unnamed functions are convenient. Some common uses include:\n",
        "\n",
        "Simplifying Code:\n",
        "Lambda functions can make the code more concise, especially when used as arguments to higher-order functions.\n",
        "\n",
        "Functional Programming:\n",
        "Lambda functions are often used in functional programming constructs like map(), filter(), and reduce(). These functions take another function as an argument and apply it to a sequence of elements.\n",
        "\n",
        "map(): Applies a function to all items in an input list.\n",
        "\n",
        "filter(): Filters items in a list based on a function that returns a boolean value.\n",
        "\n",
        "reduce(): Applies a rolling computation to sequential pairs of values in a list.\n",
        "\n",
        "Sorting and Custom Key Functions:\n",
        "Lambda functions are commonly used as the key argument in sorting operations.\n",
        "\n",
        "Inline Function Definitions:\n",
        "Lambda functions can be used for simple, inline function definitions where a full function would be overkill."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhISpHkR8esf",
        "outputId": "ee5a2e68-2055-46e5-fb5a-cef45fd9adc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "[1, 4, 9, 16]\n",
            "[2, 4, 6]\n",
            "24\n",
            "[(5, -1), (4, 1), (1, 2), (3, 3)]\n"
          ]
        }
      ],
      "source": [
        "#Example\n",
        "\n",
        "# A lambda function that adds 10 to its input\n",
        "add_ten = lambda x: x + 10\n",
        "\n",
        "# Using the lambda function\n",
        "result = add_ten(5)\n",
        "print(result)  # Output: 15\n",
        "\n",
        "\n",
        "#using map()\n",
        "# Using lambda with map\n",
        "numbers = [1, 2, 3, 4]\n",
        "squares = map(lambda x: x**2, numbers)\n",
        "print(list(squares))  # Output: [1, 4, 9, 16]\n",
        "\n",
        "#using filter()\n",
        "# Using lambda with filter\n",
        "numbers = [1, 2, 3, 4, 5, 6]\n",
        "even_numbers = filter(lambda x: x % 2 == 0, numbers)\n",
        "print(list(even_numbers))  # Output: [2, 4, 6]\n",
        "\n",
        "\n",
        "# Using lambda with reduce\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "numbers = [1, 2, 3, 4]\n",
        "product = reduce(lambda x, y: x * y, numbers)\n",
        "print(product)  # Output: 24\n",
        "\n",
        "\n",
        "# Using lambda to sort a list of tuples\n",
        "points = [(1, 2), (4, 1), (5, -1), (3, 3)]\n",
        "points_sorted = sorted(points, key=lambda x: x[1])\n",
        "print(points_sorted)  # Output: [(5, -1), (4, 1), (1, 2), (3, 3)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Xj3zuv9ISA"
      },
      "source": [
        "###18. Explain split() and join() functions in Python ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhLk19fG9UvG"
      },
      "source": [
        "The split() and join() functions in Python are used for string manipulation.\n",
        "\n",
        "split()\n",
        "The split() function divides a string into a list of substrings based on a specified delimiter. By default, the delimiter is any whitespace.\n",
        "\n",
        "Syntax:-\n",
        "str.split(sep=None, maxsplit=-1)\n",
        "\n",
        "join()\n",
        "The join() function concatenates a list of strings into a single string with a specified delimiter\n",
        "\n",
        "Syntax:-\n",
        "str.join(iterable)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDZ7ywms9x20",
        "outputId": "ea1cb8c9-855d-4967-e465-b1b69cab22c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello world\n",
            "['Hello,', 'world!']\n"
          ]
        }
      ],
      "source": [
        "#join()\n",
        "\n",
        "words = ['Hello', 'world']\n",
        "sentence = ' '.join(words)\n",
        "print(sentence)  # Output: \"Hello world\"\n",
        "\n",
        "#split()\n",
        "\n",
        "string = \"Hello, world!\"\n",
        "words = string.split()\n",
        "print(words)  # Output: ['Hello', 'world!']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr374FyT9_rb"
      },
      "source": [
        "###19. What are iterators , iterable & generators in Python\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR3CLFts-Ebe"
      },
      "source": [
        "In Python, iterators, iterables, and generators are fundamental concepts for working with sequences of data.\n",
        "\n",
        "### Iterables\n",
        "An iterable is any Python object capable of returning its members one at a time, permitting it to be iterated over in a loop. Examples include lists, tuples, strings, and dictionaries.\n",
        "\n",
        "### Iterators\n",
        "An iterator is an object that represents a stream of data; it returns the next item in the sequence when the `next()` function is called. An iterator is an object that implements the iterator protocol, which consists of the methods `__iter__()` and `__next__().\n",
        "   \n",
        "\n",
        "### Generators\n",
        "Generators are a simple way to create iterators using a function that uses the `yield` statement. Each time `yield` is called, the function generates a value and saves its state for resumption when `next()` is called again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0QPD3-l-uGm",
        "outputId": "19cd6866-5ab9-4f67-9a06-d00374152dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "#iterable\n",
        "my_list = [1, 2, 3, 4]\n",
        "for item in my_list:\n",
        "    print(item)\n",
        "\n",
        "\n",
        "\n",
        "#iterator\n",
        "my_list = [1, 2, 3, 4]\n",
        "iterator = iter(my_list)\n",
        "\n",
        "print(next(iterator))  # Output: 1\n",
        "print(next(iterator))  # Output: 2\n",
        "\n",
        "#generators\n",
        "def my_generator():\n",
        "    yield 1\n",
        "    yield 2\n",
        "    yield 3\n",
        "\n",
        "gen = my_generator()\n",
        "for value in gen:\n",
        "    print(value)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2w8KLkA6Av"
      },
      "outputs": [],
      "source": [
        "###20. What is the difference between xrange and range in Python\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzkyPzyUBAx5"
      },
      "source": [
        "\n",
        "\n",
        "### range\n",
        "- **Generates a List**: `range` returns a list of numbers.\n",
        "- **Memory Usage**: Because it generates the entire list at once, `range` can be inefficient for large ranges.\n",
        "- **Syntax**: `range(start, stop[, step])`\n",
        "  - `start`: The starting value of the sequence.\n",
        "  - `stop`: The end value of the sequence (exclusive).\n",
        "  - `step`: The difference between each pair of consecutive values (default is 1).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### `xrange`\n",
        "- **Generates an Iterator**: `xrange` returns an xrange object, which generates the numbers on the fly.\n",
        "- **Memory Usage**: More memory-efficient for large ranges since it generates numbers as needed.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0arYoclnBxf7",
        "outputId": "65723454-efc9-44cf-c961-501a4bacbd42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "#range\n",
        "for i in range(5):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jx7GH_8MB_Y8",
        "outputId": "c4e711c4-a906-43e1-acc7-3103e3246737"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'xrange' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6f99fd2190dd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# xrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output: xrange(1, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output: 1 2 3 4 5 6 7 8 9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
          ]
        }
      ],
      "source": [
        "# xrange\n",
        "numbers = xrange(1, 10)\n",
        "print(numbers)  # Output: xrange(1, 10)\n",
        "for num in numbers:\n",
        "    print(num)  # Output: 1 2 3 4 5 6 7 8 9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9gfNq3gCSA0"
      },
      "source": [
        "###21. Pillars of Oops?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emOyXc1kCbDI"
      },
      "source": [
        "Object-oriented programming (OOP) is a programming paradigm that uses objects and classes to structure software in a way that is both modular and reusable. The four main pillars of OOP are encapsulation, abstraction, inheritance, and polymorphism.\n",
        "\n",
        "\n",
        "1. Encapsulation\n",
        "\n",
        "Encapsulation is the bundling of data (attributes) and methods (functions) that operate on that data into a single unit or class. It also involves restricting direct access to some of an object's components, which is a means of preventing accidental or unauthorized manipulation of data.\n",
        "-->Data Hiding: Internal state of the object is hidden from the outside world; only the methods of the object can access and modify its state.\n",
        "-->Public, Private, and Protected Members: In many OOP languages, you can define the visibility of the class members (public, private, protected).\n",
        "\n",
        "\n",
        "2. Abstraction\n",
        "\n",
        "Abstraction involves hiding the complex implementation details of a system and exposing only the essential features. This reduces complexity and allows the programmer to focus on interactions at a higher level.\n",
        "\n",
        "-->Interface: The set of public methods and properties of a class.\n",
        "-->Abstract Classes and Methods: Classes and methods that are declared, but contain no implementation. These need to be inherited and implemented by subclasses.\n",
        "\n",
        "\n",
        "3. Inheritance\n",
        "\n",
        "Inheritance is a mechanism where a new class inherits properties and behavior (methods) from an existing class. This promotes code reusability and establishes a relationship between classes.\n",
        "\n",
        "\n",
        "-->Base (or Parent) Class: The class being inherited from.\n",
        "-->Derived (or Child) Class: The class that inherits from the base class.\n",
        "-->Method Overriding: Redefining a method in the derived class that is already defined in the base class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls9eODrFDFQR",
        "outputId": "c91a1dd0-47fa-415d-d687-bb2c8320ccf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2020 Toyota Camry\n",
            "2021 Toyota Camry\n"
          ]
        }
      ],
      "source": [
        "#Encapsulation\n",
        "class Car:\n",
        "    def __init__(self, make, model, year):\n",
        "        self.__make = make    # Private attribute\n",
        "        self.__model = model  # Private attribute\n",
        "        self.__year = year    # Private attribute\n",
        "\n",
        "    def get_details(self):\n",
        "        return f\"{self.__year} {self.__make} {self.__model}\"\n",
        "\n",
        "    def set_year(self, year):\n",
        "        if year > 1885:  # Basic validation\n",
        "            self.__year = year\n",
        "\n",
        "car = Car(\"Toyota\", \"Camry\", 2020)\n",
        "print(car.get_details())  # Output: 2020 Toyota Camry\n",
        "car.set_year(2021)\n",
        "print(car.get_details())  # Output: 2021 Toyota Camry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EzPJYvNDTHT",
        "outputId": "f4f6ef1e-f1a1-4042-e942-964597fee290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bark\n",
            "Meow\n"
          ]
        }
      ],
      "source": [
        "#abstraction\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class Animal(ABC):\n",
        "    @abstractmethod\n",
        "    def make_sound(self):\n",
        "        pass\n",
        "\n",
        "class Dog(Animal):\n",
        "    def make_sound(self):\n",
        "        return \"Bark\"\n",
        "\n",
        "class Cat(Animal):\n",
        "    def make_sound(self):\n",
        "        return \"Meow\"\n",
        "\n",
        "dog = Dog()\n",
        "cat = Cat()\n",
        "print(dog.make_sound())  # Output: Bark\n",
        "print(cat.make_sound())  # Output: Meow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9tmYYYyDbcW",
        "outputId": "4c7264e6-859d-4668-d4c8-a2617b6b2649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toyota Corolla's engine started\n"
          ]
        }
      ],
      "source": [
        "#inheritance\n",
        "class Vehicle:\n",
        "    def __init__(self, brand):\n",
        "        self.brand = brand\n",
        "\n",
        "    def start_engine(self):\n",
        "        return \"Engine started\"\n",
        "\n",
        "class Car(Vehicle):\n",
        "    def __init__(self, brand, model):\n",
        "        super().__init__(brand)\n",
        "        self.model = model\n",
        "\n",
        "    def start_engine(self):\n",
        "        return f\"{self.brand} {self.model}'s engine started\"\n",
        "\n",
        "car = Car(\"Toyota\", \"Corolla\")\n",
        "print(car.start_engine())  # Output: Toyota Corolla's engine started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jwz0dboDqAy"
      },
      "source": [
        "###22. How will you check if a class is a child of another class\t?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yw4K4c8DwUn"
      },
      "source": [
        "Using issubclass()\n",
        "\n",
        "The issubclass() function checks if a class is a derived class of another class. It takes two arguments: the class you want to check and the class you want to check against. It returns True if the first class is a subclass of the second class, and False otherwise.\n",
        "\n",
        "Using isinstance()\n",
        "\n",
        "The isinstance() function checks if an object is an instance of a class or a subclass thereof. This is useful when you have an object and you want to check its type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzML-SuqEACV",
        "outputId": "fcde7f98-0788-4f7a-a279-4a1fde2f9dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "#using issubclass\n",
        "class Animal:\n",
        "    pass\n",
        "\n",
        "class Dog(Animal):\n",
        "    pass\n",
        "\n",
        "class Cat(Animal):\n",
        "    pass\n",
        "\n",
        "print(issubclass(Dog, Animal))  # Output: True\n",
        "print(issubclass(Cat, Animal))  # Output: True\n",
        "print(issubclass(Dog, Cat))     # Output: False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWla30LEEI4L",
        "outputId": "bdaafbca-244f-470b-8bed-65214c7600ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#using isinstance\n",
        "dog = Dog()\n",
        "cat = Cat()\n",
        "\n",
        "print(isinstance(dog, Animal))  # Output: True\n",
        "print(isinstance(cat, Animal))  # Output: True\n",
        "print(isinstance(dog, Cat))     # Output: False\n",
        "print(isinstance(dog, Dog))     # Output: True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLA1dC_xEREE"
      },
      "source": [
        "###23. How does inheritance work in python? Explain all types of inheritance with an example?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8AdQ53bE77F"
      },
      "source": [
        "Inheritance in Python is a fundamental feature of object-oriented programming that allows a class (the derived or child class) to inherit attributes and methods from another class (the base or parent class). This promotes code reuse and establishes a hierarchical relationship between classes.\n",
        "\n",
        "## Types of Inheritance\n",
        "\n",
        "1. **Single Inheritance**: A derived class inherits from a single base class.\n",
        "2. **Multiple Inheritance**: A derived class inherits from more than one base class.\n",
        "3. **Multilevel Inheritance**: A derived class inherits from a base class, and then another class inherits from that derived class.\n",
        "4. **Hierarchical Inheritance**: Multiple derived classes inherit from a single base class.\n",
        "5. **Hybrid Inheritance**: A combination of two or more types of inheritance.\n",
        "\n",
        "## Examples\n",
        "\n",
        "## Single Inheritance\n",
        "In single inheritance, a derived class inherits from only one base class.\n",
        "\n",
        "\n",
        "## Multiple Inheritance\n",
        "In multiple inheritance, a derived class inherits from more than one base class.\n",
        "\n",
        "\n",
        "## Multilevel Inheritance\n",
        "In multilevel inheritance, a derived class inherits from another derived class.\n",
        "\n",
        "\n",
        "## Hierarchical Inheritance\n",
        "In hierarchical inheritance, multiple derived classes inherit from a single base class.\n",
        "\n",
        "\n",
        "## Hybrid Inheritance\n",
        "Hybrid inheritance is a combination of two or more types of inheritance. For example, a mix of hierarchical and multiple inheritance.\n",
        "\n",
        "\n",
        "\n",
        "## How Inheritance Works\n",
        "- **Base Class Definition**: The parent class is defined first.\n",
        "- **Derived Class Definition**: The child class is defined, specifying the base class in parentheses.\n",
        "- **Inheritance of Attributes and Methods**: The derived class inherits attributes and methods from the base class.\n",
        "- **Overriding**: The derived class can override methods of the base class.\n",
        "- **Using `super()`**: The `super()` function can be used to call methods from the base class in the derived class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn8vj8pBFbcS",
        "outputId": "7e076244-b0b7-4d39-ca5e-ece14d22d402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Animal speaks\n",
            "Dog barks\n"
          ]
        }
      ],
      "source": [
        "#single inheritance\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Animal speaks\"\n",
        "\n",
        "class Dog(Animal):\n",
        "    def bark(self):\n",
        "        return \"Dog barks\"\n",
        "\n",
        "dog = Dog()\n",
        "print(dog.speak())  # Output: Animal speaks\n",
        "print(dog.bark())   # Output: Dog barks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCuZ8t2FFlGI",
        "outputId": "4c7ea4de-1bed-40f1-959c-249d655347f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flying\n",
            "Swimming\n"
          ]
        }
      ],
      "source": [
        "#multiple inheritance\n",
        "class Flyer:\n",
        "    def fly(self):\n",
        "        return \"Flying\"\n",
        "\n",
        "class Swimmer:\n",
        "    def swim(self):\n",
        "        return \"Swimming\"\n",
        "\n",
        "class Duck(Flyer, Swimmer):\n",
        "    pass\n",
        "\n",
        "duck = Duck()\n",
        "print(duck.fly())   # Output: Flying\n",
        "print(duck.swim())  # Output: Swimming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBDE3EPFr-q",
        "outputId": "b7c75b8b-e153-4620-844d-5aeba3d59b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Animal speaks\n",
            "Mammal walks\n",
            "Dog barks\n"
          ]
        }
      ],
      "source": [
        "#multilevel inheritance\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Animal speaks\"\n",
        "\n",
        "class Mammal(Animal):\n",
        "    def walk(self):\n",
        "        return \"Mammal walks\"\n",
        "\n",
        "class Dog(Mammal):\n",
        "    def bark(self):\n",
        "        return \"Dog barks\"\n",
        "\n",
        "dog = Dog()\n",
        "print(dog.speak())  # Output: Animal speaks\n",
        "print(dog.walk())   # Output: Mammal walks\n",
        "print(dog.bark())   # Output: Dog barks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pczG1D97FyZ3"
      },
      "outputs": [],
      "source": [
        "#Hierarchical Inheritance\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Animal speaks\"\n",
        "\n",
        "class Mammal(Animal):\n",
        "    def walk(self):\n",
        "        return \"Mammal walks\"\n",
        "\n",
        "class Dog(Mammal):\n",
        "    def bark(self):\n",
        "        return \"Dog barks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yCjv69F6Zw",
        "outputId": "2dbf7016-4d73-49d3-8cd0-6cc18b0ebb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Animal speaks\n",
            "Dog barks\n",
            "Animal speaks\n",
            "Flying\n"
          ]
        }
      ],
      "source": [
        "#Hybrid Inheritance\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Animal speaks\"\n",
        "\n",
        "class Flyer:\n",
        "    def fly(self):\n",
        "        return \"Flying\"\n",
        "\n",
        "class Dog(Animal):\n",
        "    def bark(self):\n",
        "        return \"Dog barks\"\n",
        "\n",
        "class Bird(Animal, Flyer):\n",
        "    pass\n",
        "\n",
        "dog = Dog()\n",
        "bird = Bird()\n",
        "print(dog.speak())  # Output: Animal speaks\n",
        "print(dog.bark())   # Output: Dog barks\n",
        "print(bird.speak()) # Output: Animal speaks\n",
        "print(bird.fly())   # Output: Flying\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHjU35NKGN8a"
      },
      "source": [
        "###24. What is encapsulation? Explain it with an example?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfkN0ivSGWpc"
      },
      "source": [
        "Encapsulation is one of the fundamental principles of object-oriented programming (OOP). It refers to the bundling of data (attributes) and methods (functions) that operate on that data into a single unit, typically a class. Encapsulation also involves restricting access to certain components to protect the integrity of the data and prevent unintended interference and misuse.\n",
        "\n",
        "## Key Concepts of Encapsulation:\n",
        "1. **Data Hiding**: Internal state of an object is hidden from the outside world and only accessible through public methods.\n",
        "2. **Public, Private, and Protected Members**:\n",
        "   - **Public Members**: Accessible from outside the class.\n",
        "   - **Protected Members**: Indicated by a single underscore (e.g., `_protectedMember`), intended to be accessed only within the class and its subclasses.\n",
        "   - **Private Members**: Indicated by double underscores (e.g., `__privateMember`), intended to be accessed only within the class itself.\n",
        "\n",
        "### Explanation:\n",
        "1. **Private Attribute**: The `__balance` attribute is private, meaning it cannot be accessed directly from outside the class. This is indicated by the double underscores (`__`).\n",
        "2. **Public Methods**: The `deposit()`, `withdraw()`, and `get_balance()` methods are public, allowing controlled access to the private `__balance` attribute.\n",
        "3. **Data Integrity**: The class methods ensure that the balance is only modified in valid ways (e.g., deposits must be positive, withdrawals must not exceed the balance).\n",
        "\n",
        "### Benefits of Encapsulation:\n",
        "1. **Improved Data Security**: By hiding the internal state, encapsulation helps protect the data from unauthorized access and modifications.\n",
        "2. **Enhanced Code Maintainability**: Changes to the internal implementation can be made without affecting the external interface, making the code easier to maintain and extend.\n",
        "3. **Controlled Access**: Public methods provide controlled access to the private attributes, ensuring that data is modified only in allowed ways.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umoesgOdGsAW",
        "outputId": "1fe982da-1088-47fd-ceb4-86e03b4f88c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deposited 500, new balance is 1500\n",
            "Withdrew 200, new balance is 1300\n",
            "1300\n"
          ]
        }
      ],
      "source": [
        "class BankAccount:\n",
        "    def __init__(self, owner, balance=0):\n",
        "        self.owner = owner\n",
        "        self.__balance = balance  # Private attribute\n",
        "\n",
        "    def deposit(self, amount):\n",
        "        if amount > 0:\n",
        "            self.__balance += amount\n",
        "            print(f\"Deposited {amount}, new balance is {self.__balance}\")\n",
        "        else:\n",
        "            print(\"Invalid deposit amount\")\n",
        "\n",
        "    def withdraw(self, amount):\n",
        "        if 0 < amount <= self.__balance:\n",
        "            self.__balance -= amount\n",
        "            print(f\"Withdrew {amount}, new balance is {self.__balance}\")\n",
        "        else:\n",
        "            print(\"Invalid withdrawal amount or insufficient funds\")\n",
        "\n",
        "    def get_balance(self):\n",
        "        return self.__balance\n",
        "\n",
        "# Create a bank account\n",
        "account = BankAccount(\"Alice\", 1000)\n",
        "\n",
        "# Accessing public method\n",
        "account.deposit(500)  # Output: Deposited 500, new balance is 1500\n",
        "account.withdraw(200)  # Output: Withdrew 200, new balance is 1300\n",
        "\n",
        "# Accessing private attribute directly (not recommended)\n",
        "# print(account.__balance)  # This will raise an AttributeError\n",
        "\n",
        "# Accessing private attribute via a public method\n",
        "print(account.get_balance())  # Output: 1300\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VjB0t2cG7WD"
      },
      "source": [
        "###25. What is polymorphism?  Explain it with an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV1k6xvbG_gQ"
      },
      "source": [
        "Polymorphism is a fundamental concept in object-oriented programming (OOP) that allows objects of different classes to be treated as objects of a common superclass. It enables a single interface to represent different underlying forms (data types). Polymorphism allows methods to do different things based on the object it is acting upon, even though they share the same name.\n",
        "\n",
        "### Types of Polymorphism\n",
        "1. **Compile-time Polymorphism (Method Overloading)**: This type is achieved at compile time. It allows multiple methods with the same name but different parameters to coexist.\n",
        "   - Note: Python does not support method overloading in the traditional sense (as seen in languages like Java or C++), but it can be achieved using default arguments or variable-length arguments.\n",
        "\n",
        "2. **Runtime Polymorphism (Method Overriding)**: This type is achieved at runtime. It allows a subclass to provide a specific implementation of a method that is already defined in its superclass.\n",
        "\n",
        "\n",
        "#### Method Overloading (Compile-time Polymorphism) - Simulated in Python\n",
        "Python does not support method overloading directly. Instead, we can achieve similar functionality using default arguments or variable-length arguments.\n",
        "\n",
        "\n",
        "\n",
        "### Polymorphism with Common Interface\n",
        "Another common use of polymorphism is when different classes implement the same interface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z9pBsObHl_m",
        "outputId": "4b639a21-32b5-43d4-9046-7c9e13cfa2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dog barks\n"
          ]
        }
      ],
      "source": [
        "#method overriding\n",
        "class Animal:\n",
        "    def speak(self):\n",
        "        return \"Animal speaks\"\n",
        "\n",
        "class Dog(Animal):\n",
        "    def speak(self):\n",
        "        return \"Dog barks\"\n",
        "\n",
        "dog = Dog()\n",
        "print(dog.speak())  # Output: Dog barks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvGWyCQHHuGL",
        "outputId": "e8e4721e-d1b0-4c8f-8838-924cb6a783e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "#method overloading\n",
        "class MathOperations:\n",
        "    def add(self, a, b, c=0):\n",
        "        return a + b + c\n",
        "\n",
        "math_ops = MathOperations()\n",
        "print(math_ops.add(1, 2))       # Output: 3\n",
        "print(math_ops.add(1, 2, 3))    # Output: 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvsssfisIMQR"
      },
      "source": [
        "###Question 1. 2. 1.Which of the following identifier names are invalid and why?\n",
        "\n",
        "a) Serial_no.\n",
        "\n",
        "b) 1st_Room\n",
        "\n",
        "c) Hundred$\n",
        "\n",
        "d) Total_Marks\n",
        "\n",
        "e) total-Marks\n",
        "\n",
        "f) Total Marks\n",
        "\n",
        "g) True\n",
        "\n",
        "h) _Percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZZd_65LIdCa"
      },
      "source": [
        "1st_Room\n",
        "\n",
        "Invalid: Identifiers cannot start with a digit (1 in this case).\n",
        "total-Marks\n",
        "\n",
        "Invalid: Identifiers cannot contain hyphens (-). Use underscores (_) instead.\n",
        "Total Marks\n",
        "\n",
        "Invalid: Identifiers cannot contain spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lM6oH5-Ijxa"
      },
      "source": [
        "###Question 1.3.\n",
        "\n",
        "name = [\"Mohan\", \"dash\", \"karam\", \"chandra\",\"gandhi\",\"Bapu\"]\n",
        "\n",
        "do the following operations in this list;\n",
        "\n",
        "\n",
        "a) add an element \"freedom_fighter\" in this list at the 0th index.\n",
        "\n",
        "\n",
        "\n",
        "b) find the output of the following ,and explain how?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "name = [“freedomFighter”,\"Bapuji\",\"MOhan\" \"dash\", \"karam\",\n",
        "\"chandra\",\"gandhi\"]\n",
        "\n",
        "length1=len((name[-len(name)+1:-1:2]))\n",
        "\n",
        "length2=len((name[-len(name)+1:-1]))\n",
        "\n",
        "print(length1+length2)\n",
        "\n",
        "c) add two more elements in the name [\"NetaJi\",\"Bose\"] at the end of the list.\n",
        "\n",
        "\n",
        "d) what will be the value of temp:\n",
        "\n",
        "name = [\"Bapuji\", \"dash\", \"karam\", \"chandra\",\"gandi\",\"Mohan\"]\n",
        "\n",
        "temp=name[-1]\n",
        "\n",
        "name[-1]=name[0]\n",
        "\n",
        "name[0]=temp\n",
        "\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaCQVRPuJAkN",
        "outputId": "53387a20-2b9d-4193-de30-f842e6f7dc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['freedom_fighter', 'Mohan', 'dash', 'karam', 'chandra', 'gandhi', 'Bapu']\n"
          ]
        }
      ],
      "source": [
        "#a.\n",
        "name = [\"Mohan\", \"dash\", \"karam\", \"chandra\", \"gandhi\", \"Bapu\"]\n",
        "name.insert(0, \"freedom_fighter\")\n",
        "print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RPEBYzJJCJH",
        "outputId": "e0e18828-3daf-4844-d211-748718e7542a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#b.\n",
        "name = [\"freedomFighter\", \"Bapuji\", \"MOhandash\", \"karam\", \"chandra\", \"gandhi\"]\n",
        "\n",
        "length1 = len((name[-len(name)+1:-1:2]))\n",
        "length2 = len((name[-len(name)+1:-1]))\n",
        "\n",
        "print(length1 + length2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6nJU8oTJXH6"
      },
      "source": [
        "Explanation:\n",
        "Understanding the Slicing and Length Calculation:\n",
        "\n",
        "name[-len(name)+1:-1:2]: This slicing operation selects elements from the list starting from the second element (-len(name)+1 calculates to -6 in this case) up to the second last element (-1).\n",
        "name[-len(name)+1:-1:2] with step 2 selects every second element within that slice.\n",
        "length1 = len(name[-6:-1:2]): Evaluates to 3, because the slice [\"Bapuji\", \"karam\", \"gandhi\"] has 3 elements (Bapuji, karam, gandhi).\n",
        "Length Calculation without Step:\n",
        "\n",
        "name[-len(name)+1:-1]: This slicing operation selects elements from the second element to the second last element.\n",
        "length2 = len(name[-6:-1]): Evaluates to 5, because the slice [\"Bapuji\", \"MOhandash\", \"karam\", \"chandra\", \"gandhi\"] has 5 elements.\n",
        "Output:\n",
        "\n",
        "length1 + length2 = 3 + 5 = 8.\n",
        "Therefore, the output of print(length1 + length2) is 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T0qqok6JFlA",
        "outputId": "d9055d2f-9c8a-46ae-dd0b-6bd5440176fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['freedomFighter', 'Bapuji', 'MOhandash', 'karam', 'chandra', 'gandhi', 'NetaJi', 'Bose']\n"
          ]
        }
      ],
      "source": [
        "#c.\n",
        "name = [\"freedomFighter\", \"Bapuji\", \"MOhandash\", \"karam\", \"chandra\", \"gandhi\"]\n",
        "name.extend([\"NetaJi\", \"Bose\"])\n",
        "print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcn84HujJHY0",
        "outputId": "b1fc47fb-3850-4d20-b1a2-7b7ef1772ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Mohan', 'dash', 'karam', 'chandra', 'gandi', 'Bapuji']\n"
          ]
        }
      ],
      "source": [
        "#d.\n",
        "name = [\"Bapuji\", \"dash\", \"karam\", \"chandra\", \"gandi\", \"Mohan\"]\n",
        "\n",
        "temp = name[-1]    # temp = \"Mohan\"\n",
        "name[-1] = name[0] # name[-1] = \"Bapuji\"\n",
        "name[0] = temp     # name[0] = \"Mohan\"\n",
        "\n",
        "print(name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrOGXLyxJo6n"
      },
      "source": [
        "###Question 1.4.Find the output of the following.\n",
        "\n",
        "animal = ['Human','cat','mat','cat','rat','Human', 'Lion']\n",
        "\n",
        "print(animal.count('Human'))\n",
        "\n",
        "print(animal.index('rat'))\n",
        "\n",
        "print(len(animal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqQffvkzJzWe",
        "outputId": "b4b23d5c-233c-443e-9d6d-5b81dcca1584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "4\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "animal = ['Human','cat','mat','cat','rat','Human', 'Lion']\n",
        "\n",
        "print(animal.count('Human'))\n",
        "\n",
        "print(animal.index('rat'))\n",
        "\n",
        "print(len(animal))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA4fmDnTJ7FB"
      },
      "source": [
        "###Question 1.5. tuple1=(10,20,\"Apple\",3.4,'a',[\"master\",\"ji\"],(\"sita\",\"geeta\",22),[{\"roll_no\":1},\n",
        "{\"name\":\"Navneet\"}])\n",
        "\n",
        "\n",
        "a)print(len(tuple1))\n",
        "\n",
        "b)print(tuple1[-1][-1][\"name\"])\n",
        "\n",
        "c)fetch the value of roll_no from this tuple.\n",
        "\n",
        "d)print(tuple1[-3][1])\n",
        "\n",
        "e)fetch the element \"22\" from this tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImRJwTsJKDxr",
        "outputId": "1febbe84-a39f-4d77-d4ba-b0b9d471c757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "Navneet\n",
            "1\n",
            "ji\n",
            "22\n"
          ]
        }
      ],
      "source": [
        "tuple1=(10,20,\"Apple\",3.4,'a',[\"master\",\"ji\"],(\"sita\",\"geeta\",22),[{\"roll_no\":1},\n",
        "{\"name\":\"Navneet\"}])\n",
        "\n",
        "\n",
        "print(len(tuple1))\n",
        "\n",
        "print(tuple1[-1][-1][\"name\"])\n",
        "\n",
        "print(tuple1[-1][0][\"roll_no\"])\n",
        "\n",
        "print(tuple1[-3][1])\n",
        "\n",
        "print(tuple1[-2][2])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIRv32CCKzis"
      },
      "source": [
        "###1.6. Write a program to display the appropriate message as per the color of signal\n",
        "(RED-Stop/Yellow-Stay/Green-Go) at the road crossing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eADFql9mK6V4",
        "outputId": "f42bc8d3-ea67-4896-8f88-79d6f9056640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop\n",
            "Stay\n",
            "Go\n",
            "Invalid color! Please enter either Red, Yellow, or Green.\n"
          ]
        }
      ],
      "source": [
        "def traffic_signal(color):\n",
        "    if color.lower() == 'red':\n",
        "        print(\"Stop\")\n",
        "    elif color.lower() == 'yellow':\n",
        "        print(\"Stay\")\n",
        "    elif color.lower() == 'green':\n",
        "        print(\"Go\")\n",
        "    else:\n",
        "        print(\"Invalid color! Please enter either Red, Yellow, or Green.\")\n",
        "\n",
        "# Example usage\n",
        "traffic_signal(\"Red\")\n",
        "traffic_signal(\"Yellow\")\n",
        "traffic_signal(\"Green\")\n",
        "traffic_signal(\"Blue\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OHripT_Lbqa"
      },
      "source": [
        "###1.7 Write a program to create a simple calculator performing only four basic operations(+,-,/,*) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRtibn7lLly4",
        "outputId": "d2ee9487-76ba-4c82-bda1-83b36e15bd68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CALCULATOR\n",
            "Operations available:\n",
            "1. Addition (+)\n",
            "2. Subtraction (-)\n",
            "3. Multiplication (*)\n",
            "4. Division (/)\n"
          ]
        }
      ],
      "source": [
        "# Function to perform addition\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "\n",
        "# Function to perform subtraction\n",
        "def subtract(x, y):\n",
        "    return x - y\n",
        "\n",
        "# Function to perform multiplication\n",
        "def multiply(x, y):\n",
        "    return x * y\n",
        "\n",
        "# Function to perform division\n",
        "def divide(x, y):\n",
        "    # Check if the divisor is zero to avoid division by zero error\n",
        "    if y == 0:\n",
        "        return \"Error! Division by zero.\"\n",
        "    else:\n",
        "        return x / y\n",
        "\n",
        "# Main function to operate the calculator\n",
        "def calculator():\n",
        "    print(\"CALCULATOR\")\n",
        "    print(\"Operations available:\")\n",
        "    print(\"1. Addition (+)\")\n",
        "    print(\"2. Subtraction (-)\")\n",
        "    print(\"3. Multiplication (*)\")\n",
        "    print(\"4. Division (/)\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice (1/2/3/4): \")\n",
        "\n",
        "        # Check if the choice is a valid option\n",
        "        if choice in ('1', '2', '3', '4'):\n",
        "            num1 = float(input(\"Enter first number: \"))\n",
        "            num2 = float(input(\"Enter second number: \"))\n",
        "\n",
        "            if choice == '1':\n",
        "                print(f\"{num1} + {num2} = {add(num1, num2)}\")\n",
        "            elif choice == '2':\n",
        "                print(f\"{num1} - {num2} = {subtract(num1, num2)}\")\n",
        "            elif choice == '3':\n",
        "                print(f\"{num1} * {num2} = {multiply(num1, num2)}\")\n",
        "            elif choice == '4':\n",
        "                print(f\"{num1} / {num2} = {divide(num1, num2)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Run the calculator\n",
        "calculator()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRI4J_qgMGv0"
      },
      "source": [
        "###1.8. Write a program to find the larger of the three pre-specified numbers using ternary operators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT95tTu0NGbE"
      },
      "outputs": [],
      "source": [
        "# Pre-specified numbers\n",
        "num1 = 25\n",
        "num2 = 40\n",
        "num3 = 15\n",
        "\n",
        "# Using a conditional expression to find the largest number\n",
        "largest = num1 if (num1 >= num2 and num1 >= num3) else (num2 if (num2 >= num1 and num2 >= num3) else num3)\n",
        "\n",
        "# Print the largest number\n",
        "print(f\"The largest number among {num1}, {num2}, and {num3} is: {largest}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJYEUCKGMpZa"
      },
      "source": [
        "###1.9.  Write a program to find the factors of a whole number using a while loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MRXFwH2NOag"
      },
      "outputs": [],
      "source": [
        "def find_factors(number):\n",
        "    # Initialize variables\n",
        "    i = 1\n",
        "    factors = []\n",
        "\n",
        "    # Iterate through potential factors using a while loop\n",
        "    while i <= number:\n",
        "        if number % i == 0:\n",
        "            factors.append(i)\n",
        "        i += 1\n",
        "\n",
        "    return factors\n",
        "\n",
        "# Example usage:\n",
        "number = 36\n",
        "print(f\"The factors of {number} are: {find_factors(number)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5h2V__rNi21"
      },
      "source": [
        "###1.10. Write a program to find the sum of all the positive numbers entered by the user. As soon as the user enters a negative number, stop taking in any further input from the user and display the sum ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujo187YtNyZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a90de3c-5fc1-4ae7-a35f-b6b0674358d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a number: 65\n",
            "Enter a number: 65\n",
            "Enter a number: 88\n",
            "Enter a number: -9\n",
            "The sum of all positive numbers entered is: 218.0\n"
          ]
        }
      ],
      "source": [
        "def sum_positive_numbers():\n",
        "    total_sum = 0\n",
        "    while True:\n",
        "        try:\n",
        "            number = float(input(\"Enter a number: \"))\n",
        "            if number < 0:\n",
        "                break\n",
        "            total_sum += number\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid number.\")\n",
        "    print(f\"The sum of all positive numbers entered is: {total_sum}\")\n",
        "\n",
        "sum_positive_numbers()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WllhFDqL9OOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.11   Write a program to find prime numbers between 2 to 100 using nested for loops."
      ],
      "metadata": {
        "id": "iaRDKUH-9VtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:   Write a program to find prime numbers between 2 to 100 using nested for loops.\n",
        "\n",
        "def find_primes(start, end):\n",
        "  primes = []\n",
        "  for num in range(start, end + 1):\n",
        "    if num > 1:\n",
        "      for i in range(2, int(num ** 0.5) + 1):\n",
        "        if num % i == 0:\n",
        "          break\n",
        "      else:\n",
        "        primes.append(num)\n",
        "  return primes\n",
        "\n",
        "primes = find_primes(2, 100)\n",
        "print(\"Prime numbers between 2 and 100:\", primes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnLqZ9yW9aPV",
        "outputId": "8403614b-9bf9-40ca-97de-c720269595ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n",
            "5\n",
            "7\n",
            "11\n",
            "13\n",
            "17\n",
            "19\n",
            "23\n",
            "29\n",
            "31\n",
            "37\n",
            "41\n",
            "43\n",
            "47\n",
            "53\n",
            "59\n",
            "61\n",
            "67\n",
            "71\n",
            "73\n",
            "79\n",
            "83\n",
            "89\n",
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.12 Write the  programs for the following\n",
        "###? Accept the marks of the student in five major subjects and display the sameS\n",
        "###? Calculate the sum of the marks of all subjects.Divide the total marks by number of subjects (i.e. 5), calculate\n",
        "###percentage = total marks/5 and display the percentageS\n",
        "###? Find the grade of the student as per the following criteria . Hint: Use Match & case for this.:"
      ],
      "metadata": {
        "id": "1Am2GScH9new"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_marks():\n",
        "    marks = []\n",
        "    for i in range(1, 6):\n",
        "        while True:\n",
        "            try:\n",
        "                mark = float(input(f\"Enter the marks for subject {i}: \"))\n",
        "                if 0 <= mark <= 100:\n",
        "                    marks.append(mark)\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Please enter a valid mark between 0 and 100.\")\n",
        "            except ValueError:\n",
        "                print(\"Please enter a valid number.\")\n",
        "    return marks\n",
        "\n",
        "def calculate_percentage(marks):\n",
        "    total_marks = sum(marks)\n",
        "    percentage = total_marks / 5\n",
        "    return total_marks, percentage\n",
        "\n",
        "def find_grade(percentage):\n",
        "    match percentage:\n",
        "        case p if p > 85:\n",
        "            return 'A'\n",
        "        case p if p >= 75:\n",
        "            return 'B'\n",
        "        case p if p >= 50:\n",
        "            return 'C'\n",
        "        case p if p >= 30:\n",
        "            return 'D'\n",
        "        case _:\n",
        "            return 'REAPPEAR'\n",
        "\n",
        "def main():\n",
        "    marks = get_marks()\n",
        "    print(\"\\nMarks entered:\")\n",
        "    for i, mark in enumerate(marks, start=1):\n",
        "        print(f\"Subject {i}: {mark}\")\n",
        "\n",
        "    total_marks, percentage = calculate_percentage(marks)\n",
        "    print(f\"\\nTotal Marks: {total_marks}\")\n",
        "    print(f\"Percentage: {percentage:.2f}%\")\n",
        "\n",
        "    grade = find_grade(percentage)\n",
        "    print(f\"Grade: {grade}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGdCWo71-J6r",
        "outputId": "a08eb719-d1f5-4eaa-86da-3b7dd5f256b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the marks for subject 1: 45\n",
            "Enter the marks for subject 2: 50\n",
            "Enter the marks for subject 3: 56\n",
            "Enter the marks for subject 4: 66\n",
            "Enter the marks for subject 5: 77\n",
            "\n",
            "Marks entered:\n",
            "Subject 1: 45.0\n",
            "Subject 2: 50.0\n",
            "Subject 3: 56.0\n",
            "Subject 4: 66.0\n",
            "Subject 5: 77.0\n",
            "\n",
            "Total Marks: 294.0\n",
            "Percentage: 58.80%\n",
            "Grade: C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.13. Write a program for VIBGYOR Spectrum based on their Wavelength using\n",
        "###Wavelength Range:"
      ],
      "metadata": {
        "id": "TCW6H_Vk_Agk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:   Write a program for VIBGYOR Spectrum based on their Wavelength using.\n",
        "# Wavelength Range:\n",
        "\n",
        "def color_from_wavelength(wavelength):\n",
        "  \"\"\"\n",
        "  Returns the color of the visible spectrum based on the given wavelength.\n",
        "\n",
        "  Args:\n",
        "    wavelength: The wavelength in nanometers.\n",
        "\n",
        "  Returns:\n",
        "    The color of the visible spectrum.\n",
        "  \"\"\"\n",
        "  if 400.0 <= wavelength < 440.0:\n",
        "    return \"Violet\"\n",
        "  elif 440.0 <= wavelength < 460.0:\n",
        "    return \"indigo\"\n",
        "  elif 460.0 <= wavelength < 500.0:\n",
        "    return \"Blue\"\n",
        "  elif 500.0 <= wavelength < 570.0:\n",
        "    return \"Green\"\n",
        "  elif 570.0 <= wavelength < 590.0:\n",
        "    return \"Yellow\"\n",
        "  elif 590.0 <= wavelength < 620.0:\n",
        "    return \"Orange\"\n",
        "  elif 620.0 <= wavelength <= 750.0:\n",
        "    return \"Red\"\n",
        "  else:\n",
        "    return \"Not in the visible spectrum\"\n",
        "\n",
        "# Example usage\n",
        "wavelength = float(input(f\"Enter the WAVELENGTH for CALCULATION: \"))\n",
        "color = color_from_wavelength(wavelength)\n",
        "print(f\"The color of light with a wavelength of {wavelength} nm is {color}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ75i7B7_LtU",
        "outputId": "cbff3ad9-f969-4d3a-ff62-9d27a08bb28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the WAVELENGTH for CALCULATION: 550.9\n",
            "The color of light with a wavelength of 550.9 nm is Green.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.14.Consider the gravitational interactions between the Earth, Moon, and Sun in our solar system.\n",
        "\n",
        "###Given:\n",
        "\n",
        "###mass_earth = 5.972e24  # Mass of Earth in kilograms\n",
        "\n",
        "###mass_moon = 7.34767309e22  # Mass of Moon in kilograms\n",
        "\n",
        "###mass_sun = 1.989e30  # Mass of Sun in kilograms\n",
        "\n",
        "\n",
        "###distance_earth_sun = 1.496e11  # Average distance between Earth and Sun in meters\n",
        "\n",
        "###distance_moon_earth = 3.844e8  # Average distance between Moon and Earth in meters\n",
        "\n",
        "\n",
        "###Tasks\n",
        " ###Calculate the gravitational force between the Earth and the Sun\n",
        " ###Calculate the gravitational force between the Moon and the Earth\n",
        " ###Compare the calculated forces to determine which gravitational force is stronger\n",
        "###Explain which celestial body (Earth or Moon) is more attracted to the other based on the comparison.\n",
        "\n"
      ],
      "metadata": {
        "id": "PtBjksqTBHGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "G = 6.67430e-11  # Gravitational constant in m^3 kg^-1 s^-2\n",
        "\n",
        "# Given data\n",
        "mass_earth = 5.972e24  # Mass of Earth in kilograms\n",
        "mass_moon = 7.34767309e22  # Mass of Moon in kilograms\n",
        "mass_sun = 1.989e30  # Mass of Sun in kilograms\n",
        "\n",
        "distance_earth_sun = 1.496e11  # Average distance between Earth and Sun in meters\n",
        "distance_moon_earth = 3.844e8  # Average distance between Moon and Earth in meters\n",
        "\n",
        "# Function to calculate gravitational force\n",
        "def gravitational_force(m1, m2, r):\n",
        "    return G * m1 * m2 / r**2\n",
        "\n",
        "# Calculate forces\n",
        "force_earth_sun = gravitational_force(mass_earth, mass_sun, distance_earth_sun)\n",
        "force_moon_earth = gravitational_force(mass_moon, mass_earth, distance_moon_earth)\n",
        "\n",
        "# Compare forces\n",
        "stronger_force = \"Earth-Sun\" if force_earth_sun > force_moon_earth else \"Moon-Earth\"\n",
        "\n",
        "# Output results\n",
        "print(f\"Gravitational force between Earth and Sun: {force_earth_sun:.2e} N\")\n",
        "print(f\"Gravitational force between Moon and Earth: {force_moon_earth:.2e} N\")\n",
        "print(f\"The stronger gravitational force is: {stronger_force}\")\n",
        "\n",
        "# Explanation\n",
        "if force_earth_sun > force_moon_earth:\n",
        "    print(\"The Earth is more strongly attracted to the Sun than the Moon is to the Earth.\")\n",
        "else:\n",
        "    print(\"The Moon is more strongly attracted to the Earth than the Earth is to the Sun.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BNwqGG5Bcnr",
        "outputId": "96c2eb74-0729-47c0-d8c1-28912812dd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gravitational force between Earth and Sun: 3.54e+22 N\n",
            "Gravitational force between Moon and Earth: 1.98e+20 N\n",
            "The stronger gravitational force is: Earth-Sun\n",
            "The Earth is more strongly attracted to the Sun than the Moon is to the Earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Design and implement a Python program for managing student information using object-oriented\n",
        "###principles. Create a class called `Student` with encapsulated attributes for name, age, and roll number.\n",
        "###Implement getter and setter methods for these attributes. Additionally, provide methods to display student\n",
        "###information and update student details.\n",
        "\n",
        "\n",
        "###Tasks\n",
        "### Define the `Student` class with encapsulated attributes\n",
        "##Implement getter and setter methods for the attributes\n",
        "### Write methods to display student information and update details\n",
        "### Create instances of the `Student` class and test the implemented functionality."
      ],
      "metadata": {
        "id": "bohVwkmUCCeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Student:\n",
        "    def __init__(self, name, age, roll_number):\n",
        "        self.__name = name\n",
        "        self.__age = age\n",
        "        self.__roll_number = roll_number\n",
        "\n",
        "    # Getter methods\n",
        "    def get_name(self):\n",
        "        return self.__name\n",
        "\n",
        "    def get_age(self):\n",
        "        return self.__age\n",
        "\n",
        "    def get_roll_number(self):\n",
        "        return self.__roll_number\n",
        "\n",
        "    # Setter methods\n",
        "    def set_name(self, name):\n",
        "        self.__name = name\n",
        "\n",
        "    def set_age(self, age):\n",
        "        self.__age = age\n",
        "\n",
        "    def set_roll_number(self, roll_number):\n",
        "        self.__roll_number = roll_number\n",
        "\n",
        "    # Method to display student information\n",
        "    def display_info(self):\n",
        "        print(f\"Name: {self.__name}\")\n",
        "        print(f\"Age: {self.__age}\")\n",
        "        print(f\"Roll Number: {self.__roll_number}\")\n",
        "\n",
        "    # Method to update student details\n",
        "    def update_details(self, name=None, age=None, roll_number=None):\n",
        "        if name is not None:\n",
        "            self.set_name(name)\n",
        "        if age is not None:\n",
        "            self.set_age(age)\n",
        "        if roll_number is not None:\n",
        "            self.set_roll_number(roll_number)\n",
        "\n",
        "# Create instances of the Student class and test the functionality\n",
        "student1 = Student(\"Alice\", 20, \"A001\")\n",
        "student2 = Student(\"Bob\", 22, \"B002\")\n",
        "\n",
        "# Display initial information\n",
        "print(\"Initial Information:\")\n",
        "student1.display_info()\n",
        "student2.display_info()\n",
        "\n",
        "# Update details\n",
        "student1.update_details(name=\"Alicia\", age=21)\n",
        "student2.update_details(roll_number=\"B003\")\n",
        "\n",
        "# Display updated information\n",
        "print(\"\\nUpdated Information:\")\n",
        "student1.display_info()\n",
        "student2.display_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQFe5b-TCdJh",
        "outputId": "5c0f948e-eb7f-41e0-bd9f-b7b75c9252cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Information:\n",
            "Name: Alice\n",
            "Age: 20\n",
            "Roll Number: A001\n",
            "Name: Bob\n",
            "Age: 22\n",
            "Roll Number: B002\n",
            "\n",
            "Updated Information:\n",
            "Name: Alicia\n",
            "Age: 21\n",
            "Roll Number: A001\n",
            "Name: Bob\n",
            "Age: 22\n",
            "Roll Number: B003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.Develop a Python program for managing library resources efficiently. Design a class named `LibraryBook` with attributes like book name, author, and availability status. Implement methods for borrowing and returning books while ensuring proper encapsulation of attributes.\n",
        "\n",
        "*    1. Create the `LibraryBook` class with encapsulated attributes\n",
        " 2. Implement methods for borrowing and returning books\n",
        " 3. Ensure proper encapsulation to protect book details\n",
        " 4. Test the borrowing and returning functionality with sample data.\n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "Cn8g_eMQCx6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LibraryBook:\n",
        "    def __init__(self, name, author):\n",
        "        self.__name = name\n",
        "        self.__author = author\n",
        "        self.__is_borrowed = False\n",
        "\n",
        "    # Getter methods\n",
        "    def get_name(self):\n",
        "        return self.__name\n",
        "\n",
        "    def get_author(self):\n",
        "        return self.__author\n",
        "\n",
        "    def is_borrowed(self):\n",
        "        return self.__is_borrowed\n",
        "\n",
        "    # Method to borrow the book\n",
        "    def borrow_book(self):\n",
        "        if not self.__is_borrowed:\n",
        "            self.__is_borrowed = True\n",
        "            print(f\"\\nThe book '{self.__name}' has been borrowed.\")\n",
        "        else:\n",
        "            print(f\"\\nSorry, the book '{self.__name}' is already borrowed.\")\n",
        "\n",
        "    # Method to return the book\n",
        "    def return_book(self):\n",
        "        if self.__is_borrowed:\n",
        "            self.__is_borrowed = False\n",
        "            print(f\"\\nThe book '{self.__name}' has been returned.\")\n",
        "        else:\n",
        "            print(f\"\\nThe book '{self.__name}' was not borrowed.\")\n",
        "\n",
        "    # Method to display book information\n",
        "    def display_info(self):\n",
        "        status = \"Borrowed\" if self.__is_borrowed else \"Available\"\n",
        "        print(f\"\\nBook Information:\\n\"\n",
        "              f\"-----------------\\n\"\n",
        "              f\"Name: {self.__name}\\n\"\n",
        "              f\"Author: {self.__author}\\n\"\n",
        "              f\"Status: {status}\\n\")\n",
        "\n",
        "# Test the borrowing and returning functionality with sample data\n",
        "book1 = LibraryBook(\"1984\", \"George Orwell\")\n",
        "book2 = LibraryBook(\"To Kill a Mockingbird\", \"Harper Lee\")\n",
        "\n",
        "# Display initial information\n",
        "print(\"Initial Information:\")\n",
        "book1.display_info()\n",
        "book2.display_info()\n",
        "\n",
        "# Borrow books\n",
        "book1.borrow_book()\n",
        "book2.borrow_book()\n",
        "\n",
        "# Try to borrow the same book again\n",
        "book1.borrow_book()\n",
        "\n",
        "# Return books\n",
        "book1.return_book()\n",
        "book2.return_book()\n",
        "\n",
        "# Display updated information\n",
        "print(\"Updated Information:\")\n",
        "book1.display_info()\n",
        "book2.display_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPaj91DtD9nD",
        "outputId": "ac5feff9-2c64-4f9a-88b8-279730fc2d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Information:\n",
            "\n",
            "Book Information:\n",
            "-----------------\n",
            "Name: 1984\n",
            "Author: George Orwell\n",
            "Status: Available\n",
            "\n",
            "\n",
            "Book Information:\n",
            "-----------------\n",
            "Name: To Kill a Mockingbird\n",
            "Author: Harper Lee\n",
            "Status: Available\n",
            "\n",
            "\n",
            "The book '1984' has been borrowed.\n",
            "\n",
            "The book 'To Kill a Mockingbird' has been borrowed.\n",
            "\n",
            "Sorry, the book '1984' is already borrowed.\n",
            "\n",
            "The book '1984' has been returned.\n",
            "\n",
            "The book 'To Kill a Mockingbird' has been returned.\n",
            "Updated Information:\n",
            "\n",
            "Book Information:\n",
            "-----------------\n",
            "Name: 1984\n",
            "Author: George Orwell\n",
            "Status: Available\n",
            "\n",
            "\n",
            "Book Information:\n",
            "-----------------\n",
            "Name: To Kill a Mockingbird\n",
            "Author: Harper Lee\n",
            "Status: Available\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.Create a simple banking system using object-oriented concepts in Python. Design classes representing different types of bank accounts such as savings and checking. Implement methods for deposit, withdraw, and balance inquiry. Utilize inheritance to manage different account types efficiently.\n",
        "\n",
        "\n",
        "Tasks\n",
        "1. Define base class(es) for bank accounts with common attributes and methods 2. Implement subclasses for specific account types (e.g., SavingsAccount, CheckingAccount)\n",
        "3. Provide methods for deposit, withdraw, and balance inquiry in each subclass\n",
        "4. Test the banking system by creating instances of different account types anD performing transactions."
      ],
      "metadata": {
        "id": "24Bp3JecEFaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BankAccount:\n",
        "    def __init__(self, account_number, balance=0):\n",
        "        self.account_number = account_number\n",
        "        self.balance = balance\n",
        "\n",
        "    def deposit(self, amount):\n",
        "        if amount > 0:\n",
        "            self.balance += amount\n",
        "            print(f\"Deposited {amount}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Deposit amount must be positive.\")\n",
        "\n",
        "    def withdraw(self, amount):\n",
        "        if 0 < amount <= self.balance:\n",
        "            self.balance -= amount\n",
        "            print(f\"Withdrew {amount}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds or invalid amount.\")\n",
        "\n",
        "    def get_balance(self):\n",
        "        print(f\"Account balance: {self.balance}\")\n",
        "        return self.balance\n",
        "\n",
        "class SavingsAccount(BankAccount):\n",
        "    def __init__(self, account_number, balance=0, interest_rate=0.02):\n",
        "        super().__init__(account_number, balance)\n",
        "        self.interest_rate = interest_rate\n",
        "\n",
        "    def add_interest(self):\n",
        "        interest = self.balance * self.interest_rate\n",
        "        self.deposit(interest)\n",
        "        print(f\"Interest added: {interest}. New balance: {self.balance}\")\n",
        "\n",
        "class CheckingAccount(BankAccount):\n",
        "    def __init__(self, account_number, balance=0, overdraft_limit=500):\n",
        "        super().__init__(account_number, balance)\n",
        "        self.overdraft_limit = overdraft_limit\n",
        "\n",
        "    def withdraw(self, amount):\n",
        "        if 0 < amount <= self.balance + self.overdraft_limit:\n",
        "            self.balance -= amount\n",
        "            print(f\"Withdrew {amount}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds or invalid amount, even with overdraft.\")\n",
        "\n",
        "# Test the banking system\n",
        "savings = SavingsAccount(\"SA123\", 1000)\n",
        "checking = CheckingAccount(\"CA123\", 500)\n",
        "\n",
        "# Display initial balances\n",
        "print(\"\\nInitial Balances:\")\n",
        "savings.get_balance()\n",
        "checking.get_balance()\n",
        "\n",
        "# Perform transactions\n",
        "print(\"\\nPerforming Transactions:\")\n",
        "savings.deposit(200)\n",
        "savings.withdraw(150)\n",
        "savings.add_interest()\n",
        "\n",
        "checking.deposit(300)\n",
        "checking.withdraw(1000)  # Testing overdraft\n",
        "checking.withdraw(100)   # Testing insufficient funds\n",
        "\n",
        "# Display final balances\n",
        "print(\"\\nFinal Balances:\")\n",
        "savings.get_balance()\n",
        "checking.get_balance()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg_-vBHIEUKy",
        "outputId": "6dc184ac-a443-49ac-ed77-9c1bcdd9d2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Balances:\n",
            "Account balance: 1000\n",
            "Account balance: 500\n",
            "\n",
            "Performing Transactions:\n",
            "Deposited 200. New balance: 1200\n",
            "Withdrew 150. New balance: 1050\n",
            "Deposited 21.0. New balance: 1071.0\n",
            "Interest added: 21.0. New balance: 1071.0\n",
            "Deposited 300. New balance: 800\n",
            "Withdrew 1000. New balance: -200\n",
            "Withdrew 100. New balance: -300\n",
            "\n",
            "Final Balances:\n",
            "Account balance: 1071.0\n",
            "Account balance: -300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-300"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.Write a Python program that models different animals and their sounds. Design a base class called `Animal` with a method `make_sound()`. Create subclasses like `Dog` and `Cat` that override the `make_sound()` method to produce appropriate sounds.\n",
        "\n",
        "\n",
        "Tasks\n",
        "1. Define the `Animal` class with a method `make_sound()`\n",
        "2. Create subclasses `Dog` and `Cat` that override the `make_sound()` method\n",
        "3. Implement the sound generation logic for each subclass\n",
        "4. Test the program by creating instances of `Dog` and `Cat` and calling the `make_sound()` method."
      ],
      "metadata": {
        "id": "vYpHj2IhEu3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Animal:\n",
        "    def make_sound(self):\n",
        "        raise NotImplementedError(\"Subclass must implement abstract method\")\n",
        "\n",
        "class Dog(Animal):\n",
        "    def make_sound(self):\n",
        "        return \"Woof!\"\n",
        "\n",
        "class Cat(Animal):\n",
        "    def make_sound(self):\n",
        "        return \"Meow!\"\n",
        "\n",
        "# Test the program\n",
        "dog = Dog()\n",
        "cat = Cat()\n",
        "\n",
        "print(\"Dog sound:\", dog.make_sound())\n",
        "print(\"Cat sound:\", cat.make_sound())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jas1fGUoE8Ky",
        "outputId": "97b0eaf0-7b1e-4f5d-d9fa-5a701cdfb7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dog sound: Woof!\n",
            "Cat sound: Meow!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.Write a code for Restaurant Management System Using OOPS3 & Create a MenuItem class that has attributes such as name, description, price, and category & Implement methods to add a new menu item, update menu item information, and remove a menu item  from the menu & Use encapsulation to hide the menu item's unique identification number & Inherit from the MenuItem class to create a FoodItem class and a BeverageItem class, each with their own specific attributes and methods."
      ],
      "metadata": {
        "id": "zyMVk3c1FOrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MenuItem:\n",
        "    _id_counter = 1\n",
        "\n",
        "    def __init__(self, name, description, price, category):\n",
        "        self.__id = MenuItem._id_counter\n",
        "        MenuItem._id_counter += 1\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.price = price\n",
        "        self.category = category\n",
        "\n",
        "    # Getter for ID\n",
        "    def get_id(self):\n",
        "        return self.__id\n",
        "\n",
        "    # Method to update menu item information\n",
        "    def update_item(self, name=None, description=None, price=None, category=None):\n",
        "        if name is not None:\n",
        "            self.name = name\n",
        "        if description is not None:\n",
        "            self.description = description\n",
        "        if price is not None:\n",
        "            self.price = price\n",
        "        if category is not None:\n",
        "            self.category = category\n",
        "\n",
        "    # Method to display menu item information\n",
        "    def display_info(self):\n",
        "        print(f\"ID: {self.__id}\")\n",
        "        print(f\"Name: {self.name}\")\n",
        "        print(f\"Description: {self.description}\")\n",
        "        print(f\"Price: {self.price}\")\n",
        "        print(f\"Category: {self.category}\")\n",
        "\n",
        "class FoodItem(MenuItem):\n",
        "    def __init__(self, name, description, price, category, cuisine_type):\n",
        "        super().__init__(name, description, price, category)\n",
        "        self.cuisine_type = cuisine_type\n",
        "\n",
        "    # Method to display food item information\n",
        "    def display_info(self):\n",
        "        super().display_info()\n",
        "        print(f\"Cuisine Type: {self.cuisine_type}\")\n",
        "\n",
        "class BeverageItem(MenuItem):\n",
        "    def __init__(self, name, description, price, category, is_alcoholic):\n",
        "        super().__init__(name, description, price, category)\n",
        "        self.is_alcoholic = is_alcoholic\n",
        "\n",
        "    # Method to display beverage item information\n",
        "    def display_info(self):\n",
        "        super().display_info()\n",
        "        print(f\"Alcoholic: {'Yes' if self.is_alcoholic else 'No'}\")\n",
        "\n",
        "# Test the Restaurant Management System\n",
        "menu = []\n",
        "\n",
        "# Add new menu items\n",
        "food1 = FoodItem(\"Pasta\", \"Creamy Alfredo Pasta\", 12.99, \"Main Course\", \"Italian\")\n",
        "beverage1 = BeverageItem(\"Coke\", \"Chilled Coca-Cola\", 1.99, \"Beverage\", False)\n",
        "\n",
        "menu.append(food1)\n",
        "menu.append(beverage1)\n",
        "\n",
        "# Display initial menu\n",
        "print(\"Initial Menu:\")\n",
        "for item in menu:\n",
        "    item.display_info()\n",
        "    print()\n",
        "\n",
        "# Update a menu item\n",
        "food1.update_item(price=13.99, description=\"Creamy Alfredo Pasta with Chicken\")\n",
        "\n",
        "# Remove a menu item\n",
        "menu.remove(beverage1)\n",
        "\n",
        "# Display updated menu\n",
        "print(\"Updated Menu:\")\n",
        "for item in menu:\n",
        "    item.display_info()\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVcQiWAdFfAO",
        "outputId": "af3a0f17-eaa2-4bf8-a117-b7be9d763262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Menu:\n",
            "ID: 1\n",
            "Name: Pasta\n",
            "Description: Creamy Alfredo Pasta\n",
            "Price: 12.99\n",
            "Category: Main Course\n",
            "Cuisine Type: Italian\n",
            "\n",
            "ID: 2\n",
            "Name: Coke\n",
            "Description: Chilled Coca-Cola\n",
            "Price: 1.99\n",
            "Category: Beverage\n",
            "Alcoholic: No\n",
            "\n",
            "Updated Menu:\n",
            "ID: 1\n",
            "Name: Pasta\n",
            "Description: Creamy Alfredo Pasta with Chicken\n",
            "Price: 13.99\n",
            "Category: Main Course\n",
            "Cuisine Type: Italian\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Write a code for  Hotel Management System using OOPS 3\n",
        "& Create a Room class that has attributes such as room number, room type, rate, and availability (private) & Implement methods to book a room, check in a guest, and check out a guest & Use encapsulation to hide the room's unique identification number & Inherit from the Room class to create a SuiteRoom class and a StandardRoom class, each with their own specific attributes and methods."
      ],
      "metadata": {
        "id": "mhf0H7yDFrdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Room:\n",
        "    def __init__(self, room_number, room_type, rate):\n",
        "        self.__room_number = room_number  # Encapsulated attribute\n",
        "        self.room_type = room_type\n",
        "        self.rate = rate\n",
        "        self.availability = True\n",
        "\n",
        "    def book_room(self):\n",
        "        if self.availability:\n",
        "            self.availability = False\n",
        "            print(f\"Room {self.__room_number} booked successfully.\")\n",
        "        else:\n",
        "            print(f\"Room {self.__room_number} is already booked.\")\n",
        "\n",
        "    def check_in(self):\n",
        "        if not self.availability:\n",
        "            print(f\"Guest checked into room {self.__room_number}.\")\n",
        "        else:\n",
        "            print(f\"Room {self.__room_number} is not booked yet.\")\n",
        "\n",
        "    def check_out(self):\n",
        "        if not self.availability:\n",
        "            self.availability = True\n",
        "            print(f\"Guest checked out of room {self.__room_number}.\")\n",
        "        else:\n",
        "            print(f\"Room {self.__room_number} is already available.\")\n",
        "\n",
        "    def get_room_number(self):\n",
        "        return self.__room_number\n",
        "\n",
        "class SuiteRoom(Room):\n",
        "    def __init__(self, room_number, rate, suite_features):\n",
        "        super().__init__(room_number, \"Suite\", rate)\n",
        "        self.suite_features = suite_features\n",
        "\n",
        "    def show_suite_features(self):\n",
        "        print(f\"Suite Room {self.get_room_number()} features: {self.suite_features}\")\n",
        "\n",
        "class StandardRoom(Room):\n",
        "    def __init__(self, room_number, rate):\n",
        "        super().__init__(room_number, \"Standard\", rate)\n",
        "\n",
        "# Example usage\n",
        "room1 = SuiteRoom(101, 200, [\"King Bed\", \"Ocean View\", \"Jacuzzi\"])\n",
        "room2 = StandardRoom(102, 100)\n",
        "\n",
        "room1.book_room()\n",
        "room1.check_in()\n",
        "room1.show_suite_features()\n",
        "room1.check_out()\n",
        "\n",
        "room2.book_room()\n",
        "room2.check_in()\n",
        "room2.check_out()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaGLpA1hF3nu",
        "outputId": "1bacda8e-cb67-4f4f-a12a-f583e21b3576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Room 101 booked successfully.\n",
            "Guest checked into room 101.\n",
            "Suite Room 101 features: ['King Bed', 'Ocean View', 'Jacuzzi']\n",
            "Guest checked out of room 101.\n",
            "Room 102 booked successfully.\n",
            "Guest checked into room 102.\n",
            "Guest checked out of room 102.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8.Write a code for  Fitness Club Management System using OOPS & Create a Member class that has attributes such as name, age, membership type, and membership status  (private) & Implement methods to register a new member, renew a membership, and cancel a membership & Use encapsulation to hide the member's unique identification number & Inherit from the Member class to create a FamilyMember class and an IndividualMember class, each with their own specific attributes and methods"
      ],
      "metadata": {
        "id": "5XHVAwUuGZ3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Member:\n",
        "    def __init__(self, member_id, name, age, membership_type):\n",
        "        self.__member_id = member_id  # Encapsulated attribute\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.membership_type = membership_type\n",
        "        self.__membership_status = \"Active\"\n",
        "\n",
        "    def register_member(self):\n",
        "        print(f\"Member {self.name} registered successfully with ID {self.__member_id}.\")\n",
        "\n",
        "    def renew_membership(self):\n",
        "        if self.__membership_status == \"Active\":\n",
        "            print(f\"Membership for {self.name} is already active.\")\n",
        "        else:\n",
        "            self.__membership_status = \"Active\"\n",
        "            print(f\"Membership for {self.name} has been renewed.\")\n",
        "\n",
        "    def cancel_membership(self):\n",
        "        if self.__membership_status == \"Cancelled\":\n",
        "            print(f\"Membership for {self.name} is already cancelled.\")\n",
        "        else:\n",
        "            self.__membership_status = \"Cancelled\"\n",
        "            print(f\"Membership for {self.name} has been cancelled.\")\n",
        "\n",
        "    def get_member_id(self):\n",
        "        return self.__member_id\n",
        "\n",
        "    def get_membership_status(self):\n",
        "        return self.__membership_status\n",
        "\n",
        "class FamilyMember(Member):\n",
        "    def __init__(self, member_id, name, age, membership_type, family_members):\n",
        "        super().__init__(member_id, name, age, membership_type)\n",
        "        self.family_members = family_members\n",
        "\n",
        "    def show_family_members(self):\n",
        "        print(f\"Family members of {self.name}: {', '.join(self.family_members)}\")\n",
        "\n",
        "class IndividualMember(Member):\n",
        "    def __init__(self, member_id, name, age, membership_type):\n",
        "        super().__init__(member_id, name, age, membership_type)\n",
        "\n",
        "# Example usage\n",
        "member1 = FamilyMember(1, \"John Doe\", 40, \"Family\", [\"Jane Doe\", \"Jimmy Doe\"])\n",
        "member2 = IndividualMember(2, \"Alice Smith\", 30, \"Individual\")\n",
        "\n",
        "member1.register_member()\n",
        "member1.show_family_members()\n",
        "member1.cancel_membership()\n",
        "member1.renew_membership()\n",
        "\n",
        "member2.register_member()\n",
        "member2.cancel_membership()\n",
        "member2.renew_membership()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rCj_6JVGk-c",
        "outputId": "19708e05-d000-45cc-bfc9-f2bb29a37e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Member John Doe registered successfully with ID 1.\n",
            "Family members of John Doe: Jane Doe, Jimmy Doe\n",
            "Membership for John Doe has been cancelled.\n",
            "Membership for John Doe has been renewed.\n",
            "Member Alice Smith registered successfully with ID 2.\n",
            "Membership for Alice Smith has been cancelled.\n",
            "Membership for Alice Smith has been renewed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.Write a code for  Event Management System using OOPS & Create an Event class that has attributes such as name, date, time, location, and list of attendees (private) & Implement methods to create a new event, add or remove attendees, and get the total number of attendees & Use encapsulation to hide the event's unique identification number & Inherit from the Event class to create a PrivateEvent class and a PublicEvent class, each with their own specific attributes and methods."
      ],
      "metadata": {
        "id": "HuXx7TcxG3Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Event:\n",
        "    def __init__(self, event_id, name, date, time, location):\n",
        "        self.__event_id = event_id  # Encapsulated attribute\n",
        "        self.name = name\n",
        "        self.date = date\n",
        "        self.time = time\n",
        "        self.location = location\n",
        "        self.__attendees = []\n",
        "\n",
        "    def create_event(self):\n",
        "        print(f\"Event '{self.name}' created successfully with ID {self.__event_id}.\")\n",
        "\n",
        "    def add_attendee(self, attendee):\n",
        "        self.__attendees.append(attendee)\n",
        "        print(f\"Attendee '{attendee}' added to event '{self.name}'.\")\n",
        "\n",
        "    def remove_attendee(self, attendee):\n",
        "        if attendee in self.__attendees:\n",
        "            self.__attendees.remove(attendee)\n",
        "            print(f\"Attendee '{attendee}' removed from event '{self.name}'.\")\n",
        "        else:\n",
        "            print(f\"Attendee '{attendee}' not found in event '{self.name}'.\")\n",
        "\n",
        "    def get_total_attendees(self):\n",
        "        return len(self.__attendees)\n",
        "\n",
        "    def get_event_id(self):\n",
        "        return self.__event_id\n",
        "\n",
        "    def get_attendees(self):\n",
        "        return self.__attendees\n",
        "\n",
        "class PrivateEvent(Event):\n",
        "    def __init__(self, event_id, name, date, time, location, host):\n",
        "        super().__init__(event_id, name, date, time, location)\n",
        "        self.host = host\n",
        "\n",
        "    def show_host(self):\n",
        "        print(f\"The host of the private event '{self.name}' is {self.host}.\")\n",
        "\n",
        "class PublicEvent(Event):\n",
        "    def __init__(self, event_id, name, date, time, location, public_notice):\n",
        "        super().__init__(event_id, name, date, time, location)\n",
        "        self.public_notice = public_notice\n",
        "\n",
        "    def show_public_notice(self):\n",
        "        print(f\"Public notice for the event '{self.name}': {self.public_notice}\")\n",
        "\n",
        "# Example usage\n",
        "event1 = PrivateEvent(1, \"Private Party\", \"2024-08-01\", \"18:00\", \"John's House\", \"John Doe\")\n",
        "event2 = PublicEvent(2, \"Community Fair\", \"2024-08-15\", \"10:00\", \"Central Park\", \"Everyone is welcome!\")\n",
        "\n",
        "event1.create_event()\n",
        "event1.add_attendee(\"Alice\")\n",
        "event1.add_attendee(\"Bob\")\n",
        "event1.show_host()\n",
        "print(f\"Total attendees for {event1.name}: {event1.get_total_attendees()}\")\n",
        "event1.remove_attendee(\"Alice\")\n",
        "print(f\"Total attendees for {event1.name}: {event1.get_total_attendees()}\")\n",
        "\n",
        "event2.create_event()\n",
        "event2.add_attendee(\"Charlie\")\n",
        "event2.show_public_notice()\n",
        "print(f\"Total attendees for {event2.name}: {event2.get_total_attendees()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGEQE3_5HCp3",
        "outputId": "0cb6a754-85a9-4730-80e9-9bb3c1debe7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event 'Private Party' created successfully with ID 1.\n",
            "Attendee 'Alice' added to event 'Private Party'.\n",
            "Attendee 'Bob' added to event 'Private Party'.\n",
            "The host of the private event 'Private Party' is John Doe.\n",
            "Total attendees for Private Party: 2\n",
            "Attendee 'Alice' removed from event 'Private Party'.\n",
            "Total attendees for Private Party: 1\n",
            "Event 'Community Fair' created successfully with ID 2.\n",
            "Attendee 'Charlie' added to event 'Community Fair'.\n",
            "Public notice for the event 'Community Fair': Everyone is welcome!\n",
            "Total attendees for Community Fair: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10.Write a code for Airline Reservation System using OOPS3 & Create a Flight class that has attributes such as flight number, departure and arrival airports, departure and  arrival times, and available seats (private) & Implement methods to book a seat, cancel a reservation, and get the remainingavailable seats & Use encapsulation to hide the flight's unique identification number & Inherit from the Flight class to create a DomesticFlight class and an InternationalFlight class, each with their  own specific attributes and methods."
      ],
      "metadata": {
        "id": "fGOQFkvNHN6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flight:\n",
        "    def __init__(self, flight_id, flight_number, departure_airport, arrival_airport, departure_time, arrival_time, total_seats):\n",
        "        self.__flight_id = flight_id  # Encapsulated attribute\n",
        "        self.flight_number = flight_number\n",
        "        self.departure_airport = departure_airport\n",
        "        self.arrival_airport = arrival_airport\n",
        "        self.departure_time = departure_time\n",
        "        self.arrival_time = arrival_time\n",
        "        self.__available_seats = total_seats\n",
        "\n",
        "    def book_seat(self):\n",
        "        if self.__available_seats > 0:\n",
        "            self.__available_seats -= 1\n",
        "            print(f\"Seat booked on flight {self.flight_number}.\")\n",
        "        else:\n",
        "            print(f\"No available seats on flight {self.flight_number}.\")\n",
        "\n",
        "    def cancel_reservation(self):\n",
        "        self.__available_seats += 1\n",
        "        print(f\"Reservation cancelled on flight {self.flight_number}.\")\n",
        "\n",
        "    def get_remaining_seats(self):\n",
        "        return self.__available_seats\n",
        "\n",
        "    def get_flight_id(self):\n",
        "        return self.__flight_id\n",
        "\n",
        "class DomesticFlight(Flight):\n",
        "    def __init__(self, flight_id, flight_number, departure_airport, arrival_airport, departure_time, arrival_time, total_seats, domestic_features):\n",
        "        super().__init__(flight_id, flight_number, departure_airport, arrival_airport, departure_time, arrival_time, total_seats)\n",
        "        self.domestic_features = domestic_features\n",
        "\n",
        "    def show_domestic_features(self):\n",
        "        print(f\"Domestic flight {self.flight_number} features: {self.domestic_features}\")\n",
        "\n",
        "class InternationalFlight(Flight):\n",
        "    def __init__(self, flight_id, flight_number, departure_airport, arrival_airport, departure_time, arrival_time, total_seats, international_features):\n",
        "        super().__init__(flight_id, flight_number, departure_airport, arrival_airport, departure_time, arrival_time, total_seats)\n",
        "        self.international_features = international_features\n",
        "\n",
        "    def show_international_features(self):\n",
        "        print(f\"International flight {self.flight_number} features: {self.international_features}\")\n",
        "\n",
        "# Example usage\n",
        "flight1 = DomesticFlight(1, \"AI101\", \"DEL\", \"BOM\", \"2024-07-21 10:00\", \"2024-07-21 12:00\", 150, [\"In-flight WiFi\", \"Complimentary Snacks\"])\n",
        "flight2 = InternationalFlight(2, \"AI202\", \"DEL\", \"JFK\", \"2024-07-22 22:00\", \"2024-07-23 10:00\", 300, [\"In-flight Entertainment\", \"Extra Legroom\"])\n",
        "\n",
        "flight1.book_seat()\n",
        "flight1.show_domestic_features()\n",
        "print(f\"Remaining seats on {flight1.flight_number}: {flight1.get_remaining_seats()}\")\n",
        "flight1.cancel_reservation()\n",
        "print(f\"Remaining seats on {flight1.flight_number}: {flight1.get_remaining_seats()}\")\n",
        "\n",
        "flight2.book_seat()\n",
        "flight2.show_international_features()\n",
        "print(f\"Remaining seats on {flight2.flight_number}: {flight2.get_remaining_seats()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4NTa44mHaTD",
        "outputId": "0984dbbf-4af1-43b3-a351-eb54f540b146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seat booked on flight AI101.\n",
            "Domestic flight AI101 features: ['In-flight WiFi', 'Complimentary Snacks']\n",
            "Remaining seats on AI101: 149\n",
            "Reservation cancelled on flight AI101.\n",
            "Remaining seats on AI101: 150\n",
            "Seat booked on flight AI202.\n",
            "International flight AI202 features: ['In-flight Entertainment', 'Extra Legroom']\n",
            "Remaining seats on AI202: 299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11. Define a Python module named constants.py containing constants like pi and the speed of light."
      ],
      "metadata": {
        "id": "4HMMPvB6Hwpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# constants.py\n",
        "PI = 3.14159265359\n",
        "SPEED_OF_LIGHT = 299792458  # meters per second\n",
        "\n"
      ],
      "metadata": {
        "id": "0TD-ZiC1IGA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import constants\n",
        "\n",
        "print(f\"The value of pi is: {constants.PI}\")\n",
        "print(f\"The speed of light is: {constants.SPEED_OF_LIGHT} m/s\")\n"
      ],
      "metadata": {
        "id": "y9iVSbk7InF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12. Write a Python module named calculator.py containing functions for addition, subtraction,  multiplication, and division."
      ],
      "metadata": {
        "id": "VroEo6SYIovk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculator.py\n",
        "\n",
        "def add(a, b):\n",
        "    \"\"\"Return the sum of a and b.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def subtract(a, b):\n",
        "    \"\"\"Return the difference of a and b.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "def multiply(a, b):\n",
        "    \"\"\"Return the product of a and b.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def divide(a, b):\n",
        "    \"\"\"Return the division of a by b. Raise an error if b is zero.\"\"\"\n",
        "    if b == 0:\n",
        "        raise ValueError(\"Cannot divide by zero!\")\n",
        "    return a / b\n",
        "\n",
        "\n",
        "import calculator\n",
        "\n",
        "print(f\"Addition: {calculator.add(10, 5)}\")\n",
        "print(f\"Subtraction: {calculator.subtract(10, 5)}\")\n",
        "print(f\"Multiplication: {calculator.multiply(10, 5)}\")\n",
        "print(f\"Division: {calculator.divide(10, 5)}\")\n"
      ],
      "metadata": {
        "id": "GLukk64MIumx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13. Implement a Python package structure for a project named ecommerce, containing modules for product  management and order processing."
      ],
      "metadata": {
        "id": "VxMQY1VCJGq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ecommerce/product_management/product.py\n",
        "\n",
        "class Product:\n",
        "    def __init__(self, product_id, name, price, stock):\n",
        "        self.product_id = product_id\n",
        "        self.name = name\n",
        "        self.price = price\n",
        "        self.stock = stock\n",
        "\n",
        "    def update_stock(self, quantity):\n",
        "        self.stock += quantity\n",
        "        print(f\"Stock for {self.name} updated to {self.stock}.\")\n",
        "\n",
        "    def apply_discount(self, discount):\n",
        "        self.price -= self.price * (discount / 100)\n",
        "        print(f\"Price for {self.name} after {discount}% discount is {self.price}.\")\n"
      ],
      "metadata": {
        "id": "9MNwSyTwJQvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ecommerce/order_processing/__init__.py\n",
        "# ecommerce/order_processing/order.py\n",
        "\n",
        "from ecommerce.product_management.product import Product\n",
        "\n",
        "class Order:\n",
        "    def __init__(self, order_id, product, quantity):\n",
        "        self.order_id = order_id\n",
        "        self.product = product\n",
        "        self.quantity = quantity\n",
        "        self.status = \"Pending\"\n",
        "\n",
        "    def process_order(self):\n",
        "        if self.product.stock >= self.quantity:\n",
        "            self.product.update_stock(-self.quantity)\n",
        "            self.status = \"Processed\"\n",
        "            print(f\"Order {self.order_id} processed successfully.\")\n",
        "        else:\n",
        "            print(f\"Order {self.order_id} cannot be processed due to insufficient stock.\")\n",
        "\n",
        "    def cancel_order(self):\n",
        "        if self.status == \"Processed\":\n",
        "            self.product.update_stock(self.quantity)\n",
        "        self.status = \"Cancelled\"\n",
        "        print(f\"Order {self.order_id} has been cancelled.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "DOkl6swgJVBf",
        "outputId": "c41b8456-bd62-4472-97a2-8538d9e35bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ecommerce'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8442e7ddbc16>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ecommerce/order_processing/order.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mecommerce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOrder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ecommerce'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ecommerce.product_management.product import Product\n",
        "from ecommerce.order_processing.order import Order\n",
        "\n",
        "# Create a product\n",
        "product1 = Product(1, \"Laptop\", 1000, 50)\n",
        "\n",
        "# Create an order\n",
        "order1 = Order(101, product1, 2)\n",
        "\n",
        "# Process the order\n",
        "order1.process_order()\n",
        "\n",
        "# Cancel the order\n",
        "order1.cancel_order()\n"
      ],
      "metadata": {
        "id": "uTgBG1cYJaL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14. Implement a Python module named string_utils.py containing functions for string manipulation, such as  reversing and capitalizing strings."
      ],
      "metadata": {
        "id": "SCsh8JV0JdCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# string_utils.py\n",
        "\n",
        "def reverse_string(s):\n",
        "    \"\"\"Return the reversed version of the string s.\"\"\"\n",
        "    return s[::-1]\n",
        "\n",
        "def capitalize_string(s):\n",
        "    \"\"\"Return the string s with the first letter capitalized.\"\"\"\n",
        "    return s.capitalize()\n",
        "\n",
        "def to_uppercase(s):\n",
        "    \"\"\"Return the string s in uppercase.\"\"\"\n",
        "    return s.upper()\n",
        "\n",
        "def to_lowercase(s):\n",
        "    \"\"\"Return the string s in lowercase.\"\"\"\n",
        "    return s.lower()\n"
      ],
      "metadata": {
        "id": "17MZT1pGJ0Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string_utils\n",
        "\n",
        "print(f\"Reversed: {string_utils.reverse_string('hello')}\")\n",
        "print(f\"Capitalized: {string_utils.capitalize_string('hello')}\")\n",
        "print(f\"Uppercase: {string_utils.to_uppercase('hello')}\")\n",
        "print(f\"Lowercase: {string_utils.to_lowercase('HELLO')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "pCxOC9x_J6kx",
        "outputId": "29930eae-c1dc-4c41-eee4-226262245b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'string_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4d05150896de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstring_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reversed: {string_utils.reverse_string('hello')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Capitalized: {string_utils.capitalize_string('hello')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Uppercase: {string_utils.to_uppercase('hello')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'string_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15. Write a Python module named file_operations.py with functions for reading, writing, and appending  data to a file."
      ],
      "metadata": {
        "id": "YOq1GwcXJp9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# file_operations.py\n",
        "\n",
        "def read_file(file_path):\n",
        "    \"\"\"Read the contents of a file and return them as a string.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found.\"\n",
        "\n",
        "def write_file(file_path, data):\n",
        "    \"\"\"Write data to a file, overwriting any existing content.\"\"\"\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(data)\n",
        "    print(f\"Data written to {file_path}.\")\n",
        "\n",
        "def append_file(file_path, data):\n",
        "    \"\"\"Append data to a file.\"\"\"\n",
        "    with open(file_path, 'a') as file:\n",
        "        file.write(data)\n",
        "    print(f\"Data appended to {file_path}.\")\n"
      ],
      "metadata": {
        "id": "uJBl-jpmKDj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import file_operations\n",
        "\n",
        "# Writing data to a file\n",
        "file_operations.write_file('example.txt', 'Hello, World!')\n",
        "\n",
        "# Reading data from a file\n",
        "content = file_operations.read_file('example.txt')\n",
        "print(f\"File content: {content}\")\n",
        "\n",
        "# Appending data to a file\n",
        "file_operations.append_file('example.txt', '\\nWelcome to the file operations module.')\n"
      ],
      "metadata": {
        "id": "7O0q-Z9HKLDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16. Write a Python program to create a text file named \"employees.txt\" and write the details of employees, including their name, age, and salary, into the file."
      ],
      "metadata": {
        "id": "akYxob02KO7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the employee details\n",
        "employees = [\n",
        "    {\"name\": \"John Doe\", \"age\": 30, \"salary\": 50000},\n",
        "    {\"name\": \"Jane Smith\", \"age\": 25, \"salary\": 60000},\n",
        "    {\"name\": \"Emily Davis\", \"age\": 35, \"salary\": 70000}\n",
        "]\n",
        "\n",
        "# Create and write to the file\n",
        "with open(\"employees.txt\", \"w\") as file:\n",
        "    for employee in employees:\n",
        "        file.write(f\"Name: {employee['name']}, Age: {employee['age']}, Salary: {employee['salary']}\\n\")\n",
        "\n",
        "print(\"Employee details have been written to employees.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHr4inMVKVBD",
        "outputId": "d2f5bd44-60f3-491c-b097-0093e49d7f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee details have been written to employees.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###17. Develop a Python script that opens an existing text file named \"inventory.txt\" in read mode and displays  the contents of the file line by line"
      ],
      "metadata": {
        "id": "W3_BhoPFKeRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in read mode\n",
        "with open(\"inventory.txt\", \"r\") as file:\n",
        "    # Read and display each line\n",
        "    for line in file:\n",
        "        print(line.strip())\n"
      ],
      "metadata": {
        "id": "4ldBlyLtKuk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###18. Create a Python script that reads a text file named \"expenses.txt\" and calculates the total amount spent  on various expenses listed in the file."
      ],
      "metadata": {
        "id": "kE4aRe3JKvcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file in read mode\n",
        "with open(\"expenses.txt\", \"r\") as file:\n",
        "    total_expenses = 0\n",
        "    # Read each line in the file\n",
        "    for line in file:\n",
        "        # Split the line to get the expense amount\n",
        "        parts = line.strip().split()\n",
        "        if parts:\n",
        "            # Assuming the amount is the last part of the line\n",
        "            amount = float(parts[-1])\n",
        "            total_expenses += amount\n",
        "\n",
        "print(f\"Total amount spent: {total_expenses}\")\n"
      ],
      "metadata": {
        "id": "F4lVPqtSK5mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###19. Create a Python program that reads a text file named \"paragraph.txt\" and counts the occurrences of  each word in the paragraph, displaying the results in alphabetical order."
      ],
      "metadata": {
        "id": "aoZfo8wLceHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def count_words(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read().lower()  # Read the file and convert to lowercase\n",
        "        words = re.findall(r'\\b\\w+\\b', text)  # Find all words using regex\n",
        "        word_count = Counter(words)  # Count the occurrences of each word\n",
        "\n",
        "    # Sort the word count dictionary by word (alphabetically)\n",
        "    sorted_word_count = dict(sorted(word_count.items()))\n",
        "\n",
        "    # Display the results\n",
        "    for word, count in sorted_word_count.items():\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "# Example usage\n",
        "count_words('paragraph.txt')\n"
      ],
      "metadata": {
        "id": "jpZIO0zg8PTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1GhdEWfO8XS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###20. What do you mean by Measure of Central Tendency and Measures of Dispersion .How it can be calculated."
      ],
      "metadata": {
        "id": "oyBR7HrBfCDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###21. What do you mean by skewness.Explain its types.Use graph to show."
      ],
      "metadata": {
        "id": "1GsTQMXKtgxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skewness is a measure of the asymmetry of a probability distribution. It indicates whether the data points in a dataset are skewed to the left (negative skew), to the right (positive skew), or are symmetrically distributed (zero skew).\n",
        "\n",
        "Types of Skewness\n",
        "\n",
        "\n",
        "Positive Skew (Right Skew):\n",
        "\n",
        "The right tail (higher values) is longer or fatter than the left tail.\n",
        "Most of the data points are concentrated on the left side.\n",
        "The mean is greater than the median.\n",
        "\n",
        "\n",
        "Example: Income distribution in many countries, where a small number of people earn significantly more than the majority.\n",
        "\n",
        "\n",
        "Negative Skew (Left Skew):\n",
        "\n",
        "The left tail (lower values) is longer or fatter than the right tail.\n",
        "Most of the data points are concentrated on the right side.\n",
        "The mean is less than the median.\n",
        "\n",
        "Example: Age at retirement, where most people retire around a certain age, but some retire much earlier.\n",
        "\n",
        "Zero Skew (Symmetrical Distribution):\n",
        "\n",
        "The left and right tails are mirror images of each other.\n",
        "The mean and median are equal.\n",
        "Example: Heights of adult men in a specific population"
      ],
      "metadata": {
        "id": "NF0B_mUH8n50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###22. Explain PROBABILITY MASS FUNCTION (PMF) and PROBABILITY DENSITY FUNCTION (PDF). and what is the difference between them?"
      ],
      "metadata": {
        "id": "YoQ8GCrGtnh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probability Mass Function (PMF)\n",
        "\n",
        "A Probability Mass Function (PMF) is used to describe the probability distribution of a discrete random variable. It gives the probability that a discrete random variable is exactly equal to some value. The PMF is defined as:\n",
        "\n",
        "$$ P(X = x) $$\n",
        "\n",
        "where \\( X \\) is a discrete random variable and \\( x \\) is a specific value that \\( X \\) can take. The sum of all probabilities in a PMF is equal to 1.\n",
        "\n",
        "### Probability Density Function (PDF)\n",
        "\n",
        "A Probability Density Function (PDF) is used to describe the probability distribution of a continuous random variable. Unlike the PMF, the PDF does not give the probability that the random variable is exactly equal to a specific value (since the probability of a continuous random variable taking any exact value is zero). Instead, it gives the probability density at a specific value, and the area under the curve of the PDF over an interval gives the probability that the random variable falls within that interval. The PDF is defined as:\n",
        "\n",
        "$$ f(x) $$\n",
        "\n",
        "where \\( f(x) \\) is the probability density function of the continuous random variable \\( X \\).\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "1. **Type of Variable**:\n",
        "   - **PMF**: Used for discrete random variables.\n",
        "   - **PDF**: Used for continuous random variables.\n",
        "\n",
        "2. **Probability Calculation**:\n",
        "   - **PMF**: Gives the probability that a discrete random variable is exactly equal to a specific value.\n",
        "   - **PDF**: Gives the probability density at a specific value, and the area under the curve over an interval gives the probability.\n",
        "\n",
        "3. **Summation vs. Integration**:\n",
        "   - **PMF**: The sum of all probabilities is 1.\n",
        "   - **PDF**: The integral of the PDF over the entire range is 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "gB3YUeLw9NTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###23. What is correlation. Explain its type in details.what are the  methods of determining correlation"
      ],
      "metadata": {
        "id": "oUYBXykNtq4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Correlation?\n",
        "\n",
        "Correlation is a statistical measure that describes the extent to which two variables are related. It indicates the strength and direction of a linear relationship between two variables. The correlation coefficient ranges from -1 to 1:\n",
        "- **+1** indicates a perfect positive correlation.\n",
        "- **-1** indicates a perfect negative correlation.\n",
        "- **0** indicates no linear relationship.\n",
        "\n",
        "### Types of Correlation\n",
        "\n",
        "1. **Positive Correlation**:\n",
        "   - **Definition**: Both variables move in the same direction. As one variable increases, the other also increases.\n",
        "   - **Example**: Height and weight. Taller people tend to weigh more.\n",
        "   - **Graph**: The scatter plot shows an upward trend.\n",
        "\n",
        "2. **Negative Correlation**:\n",
        "   - **Definition**: The variables move in opposite directions. As one variable increases, the other decreases.\n",
        "   - **Example**: Elevation and temperature. Higher elevations tend to have lower temperatures.\n",
        "   - **Graph**: The scatter plot shows a downward trend.\n",
        "\n",
        "3. **Zero Correlation**:\n",
        "   - **Definition**: No linear relationship between the variables.\n",
        "   - **Example**: The amount of tea drunk and intelligence level.\n",
        "   - **Graph**: The scatter plot shows no discernible pattern.\n",
        "\n",
        "### Methods of Determining Correlation\n",
        "\n",
        "1. **Scatter Diagram**:\n",
        "   - **Description**: A graphical representation where each pair of values is plotted as a point on a graph.\n",
        "   - **Usage**: Provides a visual indication of the relationship between variables.\n",
        "\n",
        "2. **Pearson's Correlation Coefficient (r)**:\n",
        "   - **Description**: Measures the linear relationship between two continuous variables.\n",
        "   - **Formula**:\n",
        "    \n",
        "     r = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum (X_i - \\bar{X})^2 \\sum (Y_i - \\bar{Y})^2}}\n",
        "     \n",
        "   - **Usage**: Suitable for interval or ratio data that are normally distributed.\n",
        "\n",
        "3. **Spearman's Rank Correlation Coefficient**:\n",
        "   - **Description**: A non-parametric measure that assesses how well the relationship between two variables can be described using a monotonic function.\n",
        "   - **Formula**:\n",
        "    \n",
        "     \\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}\n",
        "    \n",
        "   - **Usage**: Suitable for ordinal data or when the assumptions of Pearson's correlation are not met.\n",
        "\n",
        "4. **Kendall's Tau**:\n",
        "   - **Description**: A non-parametric measure of the strength and direction of association between two ranked variables.\n",
        "   - **Formula**:\n",
        "     \n",
        "     tau = \\frac{(C - D)}{\\sqrt{(C + D + T)(C + D + U)}}\n",
        "     \n",
        "   - **Usage**: Suitable for small sample sizes and ordinal data.\n",
        "\n"
      ],
      "metadata": {
        "id": "geIJMjy_9ioR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###24. Calculate coefficient of correlation between the marks obtained by 10 students in Accountancy and statistics: Use Karl Pearson’s Coefficient of Correlation Method to find it."
      ],
      "metadata": {
        "id": "EcZ4RH0Ctvaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Marks obtained by students\n",
        "accountancy_marks = [85, 90, 78, 92, 88, 76, 85, 89, 84, 91]\n",
        "statistics_marks = [78, 88, 74, 90, 84, 70, 80, 85, 79, 87]\n",
        "\n",
        "# Calculate the means\n",
        "mean_x = sum(accountancy_marks) / len(accountancy_marks)\n",
        "mean_y = sum(statistics_marks) / len(statistics_marks)\n",
        "\n",
        "# Calculate the deviations and their products\n",
        "deviation_products = [(x - mean_x) * (y - mean_y) for x, y in zip(accountancy_marks, statistics_marks)]\n",
        "squared_deviation_x = [(x - mean_x) ** 2 for x in accountancy_marks]\n",
        "squared_deviation_y = [(y - mean_y) ** 2 for y in statistics_marks]\n",
        "\n",
        "# Sum the values\n",
        "sum_deviation_products = sum(deviation_products)\n",
        "sum_squared_deviation_x = sum(squared_deviation_x)\n",
        "sum_squared_deviation_y = sum(squared_deviation_y)\n",
        "\n",
        "# Calculate the correlation coefficient\n",
        "correlation_coefficient = sum_deviation_products / math.sqrt(sum_squared_deviation_x * sum_squared_deviation_y)\n",
        "\n",
        "print(f\"Correlation Coefficient: {correlation_coefficient}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbQOjDWd-dkN",
        "outputId": "d2cc9776-2ec2-4319-bddb-9035ff935542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Coefficient: 0.9808088067239751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ntNjbInK-DAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###25. Discuss the 4  differences between correlation and regression\n"
      ],
      "metadata": {
        "id": "LZI6gvqAt16d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1. **Purpose**\n",
        "\n",
        "- **Correlation**: Measures the strength and direction of the linear relationship between two variables. It tells us how closely the variables move together.\n",
        "- **Regression**: Explains the relationship between a dependent variable and one or more independent variables. It helps us understand how the dependent variable changes when any one of the independent variables is varied.\n",
        "\n",
        "### 2. **Direction of Relationship**\n",
        "\n",
        "- **Correlation**: Symmetrical; it does not distinguish between dependent and independent variables. The correlation between \\(X\\) and \\(Y\\) is the same as between \\(Y\\) and \\(X\\).\n",
        "- **Regression**: Asymmetrical; it distinguishes between dependent (response) and independent (predictor) variables. The regression of \\(Y\\) on \\(X\\) is not the same as the regression of \\(X\\) on \\(Y\\).\n",
        "\n",
        "### 3. **Quantification**\n",
        "\n",
        "- **Correlation**: Provides a single value (correlation coefficient) that quantifies the degree of linear relationship between two variables, ranging from -1 to 1.\n",
        "- **Regression**: Provides an equation that quantifies the relationship between variables, allowing for predictions. The equation typically takes the form \\(Y = a + bX\\), where \\(a\\) is the intercept and \\(b\\) is the slope.\n",
        "\n",
        "### 4. **Causality**\n",
        "\n",
        "- **Correlation**: Does not imply causation. A high correlation between two variables does not mean that one variable causes the other to change.\n",
        "- **Regression**: Can suggest causality if the model is properly specified and other conditions are met. It shows how changes in the independent variable(s) are associated with changes in the dependent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "mzEb31AC-lyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###26. Find the most likely price at Delhi corresponding to the price of Rs. 70 at Agra from the following data:Coefficient of correlation between the prices of the two places +0.8."
      ],
      "metadata": {
        "id": "xhb_vysJuTPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the most likely price at Delhi corresponding to the price of Rs. 70 at Agra, given the coefficient of correlation (\\( r \\)) between the prices at the two places is +0.8, we can use the concept of linear regression.\n",
        "\n",
        "### Steps to Calculate\n",
        "\n",
        "1. **Given Data**:\n",
        "   - Price at Agra ) = Rs. 70\n",
        "   - Coefficient of correlation  = +0.8\n",
        "\n",
        "2. **Assume**:\n",
        "   - Mean price at Agra = Rs. 60\n",
        "   - Mean price at Delhi  = Rs. 65\n",
        "   - Standard deviation of prices at Agra  = Rs. 10\n",
        "   - Standard deviation of prices at Delhi  = Rs. 12\n",
        "\n",
        "3. **Regression Equation**:\n",
        "   The regression equation of \\( Y \\) on \\( X \\) is given by:\n",
        "   $$\n",
        "   Y = \\bar{Y} + r \\left( \\frac{\\sigma_Y}{\\sigma_X} \\right) (X - \\bar{X})\n",
        "   $$\n",
        "\n",
        "4. **Substitute the Values**:\n",
        "   $$\n",
        "   Y = 65 + 0.8 \\left( \\frac{12}{10} \\right) (70 - 60)\n",
        "   $$\n",
        "\n",
        "5. **Calculate**:\n",
        "   $$\n",
        "   Y = 65 + 0.8 \\times 1.2 \\times 10\n",
        "   $$\n",
        "   $$\n",
        "   Y = 65 + 9.6\n",
        "   $$\n",
        "   $$\n",
        "   Y = 74.6\n",
        "   $$\n",
        "\n",
        "So, the most likely price at Delhi corresponding to the price of Rs. 70 at Agra is approximately **Rs. 74.6**.\n",
        "\n"
      ],
      "metadata": {
        "id": "WHRiYQCt--0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###27. In a partially destroyed laboratory record of an analysis of correlation data, the following results only are legible: Variance of x = 9, Regression equations are: (i) 8x−10y = −66; (ii) 40x − 18y = 214. What are (a) the  mean values of x and y, (b) the coefficient of correlation between x and y, (c) the σ of y."
      ],
      "metadata": {
        "id": "bDPW46p2ua-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###28. What is  Normal Distribution? What are the four Assumptions of Normal Distribution? Explain in detail."
      ],
      "metadata": {
        "id": "7CpD1Huyuirp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Normal Distribution?\n",
        "\n",
        "The normal distribution, also known as the Gaussian distribution, is a continuous probability distribution that is symmetrical around its mean. It is characterized by its bell-shaped curve, where most of the observations cluster around the central peak, and the probabilities for values further away from the mean taper off equally in both directions¹. This distribution is widely used in statistics because many natural phenomena follow a normal distribution, such as heights, blood pressure, and IQ scores¹.\n",
        "\n",
        "### Key Characteristics of Normal Distribution\n",
        "\n",
        "1. **Symmetry**: The distribution is symmetric about the mean.\n",
        "2. **Mean, Median, and Mode**: These three measures of central tendency are all equal in a normal distribution.\n",
        "3. **Bell-Shaped Curve**: The graph of the normal distribution is bell-shaped and peaks at the mean.\n",
        "4. **Asymptotic**: The tails of the distribution approach the horizontal axis but never touch it.\n",
        "\n",
        "### Four Assumptions of Normal Distribution\n",
        "\n",
        "1. **Independence**:\n",
        "   - **Description**: The observations must be independent of each other.\n",
        "   - **Example**: The height of one person does not affect the height of another person.\n",
        "\n",
        "2. **Random Sampling**:\n",
        "   - **Description**: The data should be collected through a process of random sampling.\n",
        "   - **Example**: Selecting a random sample of students from a school to measure their heights.\n",
        "\n",
        "3. **Continuous Data**:\n",
        "   - **Description**: The data should be continuous, meaning it can take any value within a given range.\n",
        "   - **Example**: Heights, weights, and temperatures are continuous data.\n",
        "\n",
        "4. **Normality**:\n",
        "   - **Description**: The data should follow a normal distribution.\n",
        "   - **Example**: The distribution of heights in a large population typically follows a normal distribution.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XRnwS-GX_h_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###29.Write all the characteristics or Properties of the Normal Distribution Curve."
      ],
      "metadata": {
        "id": "DgMZssyXy_9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution, also known as the Gaussian distribution, has several key characteristics and properties:\n",
        "\n",
        "### 1. Symmetry\n",
        "- The normal distribution curve is perfectly symmetrical around its mean. This means the left side of the curve is a mirror image of the right side¹.\n",
        "\n",
        "### 2. Unimodal\n",
        "- The curve has a single peak, or mode, which occurs at the mean of the distribution. This is why it is called unimodal¹.\n",
        "\n",
        "### 3. Mean, Median, and Mode\n",
        "- In a normal distribution, the mean, median, and mode are all equal and located at the center of the distribution.\n",
        "\n",
        "### 4. Asymptotic\n",
        "- The tails of the normal distribution curve approach, but never touch, the horizontal axis. This means that the probability of extreme values never actually reaches zero.\n",
        "\n",
        "### 5. Bell-Shaped Curve\n",
        "- The shape of the normal distribution curve is bell-shaped, with most of the data points clustering around the mean and fewer data points appearing as you move away from the mean.\n",
        "\n",
        "### 6. Defined by Mean and Standard Deviation\n",
        "- The normal distribution is completely described by its mean (μ) and standard deviation (σ). The mean determines the location of the center of the graph, and the standard deviation determines the height and width of the graph.\n",
        "\n",
        "### 7. Area Under the Curve\n",
        "- The total area under the normal distribution curve is equal to 1. This represents the total probability of all possible outcomes.\n",
        "\n",
        "### 8. Empirical Rule (68-95-99.7 Rule)\n",
        "- Approximately 68% of the data falls within one standard deviation of the mean, 95% falls within two standard deviations, and 99.7% falls within three standard deviations.\n",
        "\n"
      ],
      "metadata": {
        "id": "R2tKWPTTMQET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###30.Which of the following options are  correct about Normal Distribution Curve.\n",
        "\n",
        "\n",
        "###(a) Within a range 0.6745 of σ on both sides the middle 50% of the observations occur i,e. mean ±0.6745σ covers 50% area 25% on each side.\n",
        "\n",
        "###(b) Mean ±1S.D. (i,e.µ ± 1σ) covers 68.268% area, 34.134 % area lies on either side of the mean.\n",
        "\n",
        "###(c) Mean ±2S.D. (i,e. µ ± 2σ) covers 95.45% area, 47.725% area lies on either side of the mean.\n",
        "\n",
        "##(d) Mean ±3 S.D. (i,e. µ ±3σ) covers 99.73% area, 49.856% area lies on the either side of the mean.\n",
        "\n",
        "##(e) Only 0.27% area is outside the range µ ±3σ."
      ],
      "metadata": {
        "id": "8tqdcv2GzH1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A\n",
        "B\n",
        "C\n",
        "E"
      ],
      "metadata": {
        "id": "QNj6svMrM190"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###31. The mean of a distribution is 60 with a standard deviation of 10. Assuming that the distribution is normal, what percentage of items be (i) between 60 and 72, (ii) between 50 and 60, (iii) beyond 72 and (iv) between 70 and 80?"
      ],
      "metadata": {
        "id": "2LfuwiowzWc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Given:\n",
        "- Mean ($$\\mu$$)    = 60\n",
        "- Standard deviation ($$\\sigma$$) = 10\n",
        "\n",
        "### (i) Between 60 and 72\n",
        "First, convert the values to Z-scores:\n",
        "$$ Z = \\frac{X - \\mu}{\\sigma} $$\n",
        "\n",
        "For 60:\n",
        "$$ Z_1 = \\frac{60 - 60}{10} = 0 $$\n",
        "\n",
        "For 72:\n",
        "$$ Z_2 = \\frac{72 - 60}{10} = 1.2 $$\n",
        "\n",
        "Using the Z-table, the area under the curve from the mean (Z = 0) to Z = 1.2 is approximately 0.3849. Therefore, the percentage of items between 60 and 72 is:\n",
        "$$ 38.49\\% $$\n",
        "\n",
        "### (ii) Between 50 and 60\n",
        "For 50:\n",
        "$$ Z_3 = \\frac{50 - 60}{10} = -1 $$\n",
        "\n",
        "For 60:\n",
        "$$ Z_4 = \\frac{60 - 60}{10} = 0 $$\n",
        "\n",
        "Using the Z-table, the area under the curve from Z = -1 to Z = 0 is approximately 0.3413. Therefore, the percentage of items between 50 and 60 is:\n",
        "$$ 34.13\\% $$\n",
        "\n",
        "### (iii) Beyond 72\n",
        "For 72:\n",
        "$$ Z_2 = \\frac{72 - 60}{10} = 1.2 $$\n",
        "\n",
        "Using the Z-table, the area to the right of Z = 1.2 is 1 - 0.8849 = 0.1151. Therefore, the percentage of items beyond 72 is:\n",
        "$$ 11.51\\% $$\n",
        "\n",
        "### (iv) Between 70 and 80\n",
        "For 70:\n",
        "$$ Z_5 = \\frac{70 - 60}{10} = 1 $$\n",
        "\n",
        "For 80:\n",
        "$$ Z_6 = \\frac{80 - 60}{10} = 2 $$\n",
        "\n",
        "Using the Z-table, the area under the curve from Z = 1 to Z = 2 is approximately 0.1359. Therefore, the percentage of items between 70 and 80 is:\n",
        "$$ 13.59\\% $$\n"
      ],
      "metadata": {
        "id": "ESwe87ITODgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ip5KLcSoM52Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###32. 15000 students sat for an examination. The mean marks was 49 and the distribution of marks had a standard deviation of 6. Assuming that the marks were normally distributed what proportion of students scored (a) more than 55 marks, (b) more than 70 marks"
      ],
      "metadata": {
        "id": "cXtpuMjEze1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Given:\n",
        "- Mean ($$\\mu$$) = 49\n",
        "- Standard deviation ($$\\sigma$$) = 6\n",
        "\n",
        "### (a) More than 55 marks\n",
        "First, convert the value to a Z-score:\n",
        "$$ Z = \\frac{X - \\mu}{\\sigma} $$\n",
        "\n",
        "For 55:\n",
        "$$ Z = \\frac{55 - 49}{6} = 1 $$\n",
        "\n",
        "Using the Z-table, the area to the left of Z = 1 is approximately 0.8413. Therefore, the area to the right (proportion of students scoring more than 55 marks) is:\n",
        "$$ 1 - 0.8413 = 0.1587 $$\n",
        "\n",
        "So, approximately **15.87%** of students scored more than 55 marks.\n",
        "\n",
        "### (b) More than 70 marks\n",
        "For 70:\n",
        "$$ Z = \\frac{70 - 49}{6} = 3.5 $$\n",
        "\n",
        "Using the Z-table, the area to the left of Z = 3.5 is very close to 1 (approximately 0.9998). Therefore, the area to the right (proportion of students scoring more than 70 marks) is:\n",
        "$$ 1 - 0.9998 = 0.0002 $$\n",
        "\n",
        "So, approximately **0.02%** of students scored more than 70 marks.\n",
        "\n"
      ],
      "metadata": {
        "id": "BJHzcv-3OVQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###33. If the height of 500 students are normally distributed with mean 65 inch and standard deviation 5 inch. How many students have height : a) greater than 70 inch. b) between 60 and 70 inch."
      ],
      "metadata": {
        "id": "BGKRCExXzkGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Given:\n",
        "- Mean ($$\\mu$$) = 65 inches\n",
        "- Standard deviation ($$\\sigma$$) = 5 inches\n",
        "- Total number of students = 500\n",
        "\n",
        "### (a) Greater than 70 inches\n",
        "First, convert the value to a Z-score:\n",
        "$$ Z = \\frac{X - \\mu}{\\sigma} $$\n",
        "\n",
        "For 70 inches:\n",
        "$$ Z = \\frac{70 - 65}{5} = 1 $$\n",
        "\n",
        "Using the Z-table, the area to the left of Z = 1 is approximately 0.8413. Therefore, the area to the right (proportion of students taller than 70 inches) is:\n",
        "$$ 1 - 0.8413 = 0.1587 $$\n",
        "\n",
        "So, the number of students taller than 70 inches is:\n",
        "$$ 0.1587 \\times 500 = 79.35 $$\n",
        "\n",
        "Approximately **79 students** have a height greater than 70 inches.\n",
        "\n",
        "### (b) Between 60 and 70 inches\n",
        "For 60 inches:\n",
        "$$ Z_1 = \\frac{60 - 65}{5} = -1 $$\n",
        "\n",
        "For 70 inches:\n",
        "$$ Z_2 = \\frac{70 - 65}{5} = 1 $$\n",
        "\n",
        "Using the Z-table, the area between Z = -1 and Z = 1 is approximately 0.6826. Therefore, the proportion of students with heights between 60 and 70 inches is:\n",
        "$$ 0.6826 $$\n",
        "\n",
        "So, the number of students with heights between 60 and 70 inches is:\n",
        "$$ 0.6826 \\times 500 = 341.3 $$\n",
        "\n",
        "Approximately **341 students** have a height between 60 and 70 inches.\n",
        "\n"
      ],
      "metadata": {
        "id": "BcOmQ_ZXOs01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###34. What is the statistical hypothesis? Explain the errors in hypothesis testing.b)Explain the  Sample. What are Large Samples & Small Samples?"
      ],
      "metadata": {
        "id": "gvwb-WwPzpVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Hypothesis\n",
        "A **statistical hypothesis** is an assumption or claim about a population parameter (e.g., mean, variance) that can be tested using statistical methods. There are two types of hypotheses in hypothesis testing:\n",
        "\n",
        "1. **Null Hypothesis (H₀)**: This is a statement of no effect or no difference. It is the hypothesis that the researcher tries to disprove.\n",
        "2. **Alternative Hypothesis (H₁ or Ha)**: This is a statement that indicates the presence of an effect or a difference. It is what the researcher wants to prove.\n",
        "\n",
        "### Errors in Hypothesis Testing\n",
        "In hypothesis testing, two types of errors can occur:\n",
        "\n",
        "1. **Type I Error (False Positive)**: This occurs when the null hypothesis is rejected when it is actually true. The probability of making a Type I error is denoted by alpha (α), which is the significance level of the test.\n",
        "2. **Type II Error (False Negative)**: This occurs when the null hypothesis is not rejected when it is actually false. The probability of making a Type II error is denoted by beta (β).\n",
        "\n",
        "### Sample\n",
        "A **sample** is a subset of individuals or observations selected from a larger population. The purpose of sampling is to make inferences about the population without having to study the entire population.\n",
        "\n",
        "### Large Samples vs. Small Samples\n",
        "- **Large Samples**: Typically, a sample size greater than 30 is considered large. Large samples tend to provide more reliable and precise estimates of population parameters because they reduce the effect of random variability. They also increase the statistical power of tests, making it easier to detect true effects⁹.\n",
        "- **Small Samples**: A sample size less than 30 is considered small. Small samples may lead to less reliable estimates and higher variability. Special statistical techniques, such as the t-distribution, are often used to analyze small samples.\n"
      ],
      "metadata": {
        "id": "FwexKojDPF-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###35.A random sample of size 25 from a population gives the sample standard derivation to be 9.0. Test the hypothesis that the population standard derivation is 10.5.\n",
        "Hint(Use chi-square distribution)."
      ],
      "metadata": {
        "id": "yXRvkOB5zwZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###37.100 students of a PW IOI obtained the following grades in Data Science paper :Grade :[A, B, C, D, E] , Total Frequency :[15, 17, 30, 22, 16, 100] Using the  χ 2 test , examine the hypothesis that the distribution of grades is uniform."
      ],
      "metadata": {
        "id": "MBO-IDSuz40A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###38.Anova Test:"
      ],
      "metadata": {
        "id": "4_hwLdNN0KOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###39.How would you create a basic Flask route that displays \"Hello, World!\" on the homepage?"
      ],
      "metadata": {
        "id": "To5VrPXj7XVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "\n",
        "app = Flask(name)\n",
        "\n",
        "@app.route('/') def hello_world(): return 'Hello, World!'\n",
        "\n",
        "if name == 'main': app.run(debug=True"
      ],
      "metadata": {
        "id": "nHjuOXe1Q4fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###40.Explain how to set up a Flask application to handle form submissions using POST requests."
      ],
      "metadata": {
        "id": "UEBv1ZYK7dRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/submit', methods=['POST'])\n",
        "def submit():\n",
        "    # Retrieve form data\n",
        "    name = request.form['name']\n",
        "    email = request.form['email']\n",
        "    return f'Name: {name}, Email: {email}'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "#html\n",
        "\n",
        "    <!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Form Submission</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Submit Your Information</h1>\n",
        "    <form action=\"/submit\" method=\"post\">\n",
        "        <label for=\"name\">Name:</label>\n",
        "        <input type=\"text\" id=\"name\" name=\"name\"><br><br>\n",
        "        <label for=\"email\">Email:</label>\n",
        "        <input type=\"email\" id=\"email\" name=\"email\"><br><br>\n",
        "        <input type=\"submit\" value=\"Submit\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\n"
      ],
      "metadata": {
        "id": "AZuyG3_ORGAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###41.Write a Flask route that accepts a parameter in the URL and displays it on the page."
      ],
      "metadata": {
        "id": "GQi3nAfj7iz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###42.How can you implement user authentication in a Flask application?"
      ],
      "metadata": {
        "id": "H_rW_Jtx7mBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###43.Describe the process of connecting a Flask app to a SQLite database using SQLAlchemy."
      ],
      "metadata": {
        "id": "-udGkziE7qu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###44.How would you create a RESTful API endpoint in Flask that returns JSON data?"
      ],
      "metadata": {
        "id": "fvvuyi7U7tHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###45.Explain how to use Flask-WTF to create and validate forms in a Flask application."
      ],
      "metadata": {
        "id": "-RD6D6NJ7xg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request, flash\n",
        "from flask_wtf import FlaskForm\n",
        "from wtforms import StringField, PasswordField, SubmitField\n",
        "from wtforms.validators import DataRequired, Length, Email\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config['SECRET_KEY'] = 'your_secret_key'\n",
        "\n",
        "class RegistrationForm(FlaskForm):\n",
        "    username = StringField('Username', validators=[DataRequired(), Length(min=4, max=25)])\n",
        "    email = StringField('Email', validators=[DataRequired(), Email()])\n",
        "    password = PasswordField('Password', validators=[DataRequired(), Length(min=6)])\n",
        "    submit = SubmitField('Register')\n",
        "\n",
        "@app.route('/register', methods=['GET', 'POST'])\n",
        "def register():\n",
        "    form = RegistrationForm()\n",
        "    if form.validate_on_submit():\n",
        "        flash(f'Account created for {form.username.data}!', 'success')\n",
        "        return redirect(url_for('home'))\n",
        "    return render_template('register.html', form=form)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return 'Home Page'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "\n",
        "// html\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Register</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Register</h1>\n",
        "    <form method=\"POST\" action=\"\">\n",
        "        {{ form.hidden_tag() }}\n",
        "        <p>\n",
        "            {{ form.username.label }}<br>\n",
        "            {{ form.username(size=32) }}<br>\n",
        "            {% for error in form.username.errors %}\n",
        "                <span style=\"color: red;\">[{{ error }}]</span>\n",
        "            {% endfor %}\n",
        "        </p>\n",
        "        <p>\n",
        "            {{ form.email.label }}<br>\n",
        "            {{ form.email(size=32) }}<br>\n",
        "            {% for error in form.email.errors %}\n",
        "                <span style=\"color: red;\">[{{ error }}]</span>\n",
        "            {% endfor %}\n",
        "        </p>\n",
        "        <p>\n",
        "            {{ form.password.label }}<br>\n",
        "            {{ form.password(size=32) }}<br>\n",
        "            {% for error in form.password.errors %}\n",
        "                <span style=\"color: red;\">[{{ error }}]</span>\n",
        "            {% endfor %}\n",
        "        </p>\n",
        "        <p>{{ form.submit() }}</p>\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "yQqf86fFRnNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###46.How can you implement file uploads in a Flask application?"
      ],
      "metadata": {
        "id": "Rr6kbiwa70IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from flask import Flask, request, redirect, url_for, render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Configure the upload folder\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# Allowed file extensions\n",
        "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif'}\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    # Check if the post request has the file part\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "    file = request.files['file']\n",
        "    # If the user does not select a file, the browser submits an empty file without a filename\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "    if file and allowed_file(file.filename):\n",
        "        filename = secure_filename(file.filename)\n",
        "        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "        return redirect(url_for('uploaded_file', filename=filename))\n",
        "    return redirect(request.url)\n",
        "\n",
        "@app.route('/uploads/<filename>')\n",
        "def uploaded_file(filename):\n",
        "    return f'File {filename} uploaded successfully!'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "#html\n",
        "\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Upload File</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Upload a File</h1>\n",
        "    <form method=\"post\" action=\"/upload\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\">\n",
        "        <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "</body>\n",
        "</html>\n",
        "\n"
      ],
      "metadata": {
        "id": "ZfPwWgAiR6Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###47.Describe the steps to create a Flask blueprint and why you might use one."
      ],
      "metadata": {
        "id": "yHwDfvq373Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "from flask import Blueprint\n",
        "\n",
        "my_blueprint = Blueprint('my_blueprint', __name__)\n",
        "\n",
        "@my_blueprint.route('/hello')\n",
        "def hello():\n",
        "    return 'Hello from the Blueprint!'\n",
        "\n",
        "\n",
        "from flask import Flask\n",
        "from my_blueprint.routes import my_blueprint\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.register_blueprint(my_blueprint, url_prefix='/my_blueprint')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l_Is0Ll4SLv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###48.How would you deploy a Flask application to a production server using Gunicorn and Nginx?"
      ],
      "metadata": {
        "id": "QmMwwAu775v0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Step 1: Install Required Packages\n",
        "First, ensure you have Python, pip, and virtualenv installed on your server. You can install them using the following commands:\n",
        "\n",
        "sudo apt update\n",
        "sudo apt install python3 python3-pip python3-venv nginx\n",
        "\n",
        "\n",
        "### Step 2: Set Up Your Flask Application\n",
        "Create a directory for your Flask application and set up a virtual environment:\n",
        "\n",
        "mkdir ~/myflaskapp\n",
        "cd ~/myflaskapp\n",
        "python3 -m venv venv\n",
        "source venv/bin/activate\n",
        "\n",
        "\n",
        "Install Flask and Gunicorn within the virtual environment:\n",
        "\n",
        "pip install Flask gunicorn\n",
        "\n",
        "\n",
        "Create a simple Flask application, for example, `app.py`:\n",
        "```python\n",
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def hello():\n",
        "    return 'Hello, World!'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n",
        "\n",
        "\n",
        "### Step 3: Test Gunicorn\n",
        "Run Gunicorn to ensure it can serve your Flask application:\n",
        "\n",
        "gunicorn --bind 0.0.0.0:8000 app:app\n",
        "\n",
        "\n",
        "You should be able to access your application at `http://your_server_ip:8000`.\n",
        "\n",
        "### Step 4: Create a Systemd Service File for Gunicorn\n",
        "Create a service file to manage Gunicorn with systemd. Create a file named `gunicorn.service` in `/etc/systemd/system/`:\n",
        "\n",
        "sudo nano /etc/systemd/system/gunicorn.service\n",
        "\n",
        "\n",
        "Add the following content to the file:\n",
        "[Unit]\n",
        "Description=Gunicorn instance to serve myflaskapp\n",
        "After=network.target\n",
        "\n",
        "[Service]\n",
        "User=your_user\n",
        "Group=www-data\n",
        "WorkingDirectory=/home/your_user/myflaskapp\n",
        "Environment=\"PATH=/home/your_user/myflaskapp/venv/bin\"\n",
        "ExecStart=/home/your_user/myflaskapp/venv/bin/gunicorn --workers 3 --bind unix:myflaskapp.sock -m 007 app:app\n",
        "\n",
        "[Install]\n",
        "WantedBy=multi-user.target\n",
        "\n",
        "\n",
        "Replace `your_user` with your actual username.\n",
        "\n",
        "### Step 5: Start and Enable the Gunicorn Service\n",
        "Start the Gunicorn service and enable it to start on boot:\n",
        "\n",
        "sudo systemctl start gunicorn\n",
        "sudo systemctl enable gunicorn\n",
        "\n",
        "\n",
        "### Step 6: Configure Nginx\n",
        "Create an Nginx configuration file for your Flask application:\n",
        "\n",
        "sudo nano /etc/nginx/sites-available/myflaskapp\n",
        "\n",
        "\n",
        "Add the following content:\n",
        "```nginx\n",
        "server {\n",
        "    listen 80;\n",
        "    server_name your_domain_or_IP;\n",
        "\n",
        "    location / {\n",
        "        include proxy_params;\n",
        "        proxy_pass http://unix:/home/your_user/myflaskapp/myflaskapp.sock;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "Enable the Nginx configuration by creating a symbolic link:\n",
        "\n",
        "sudo ln -s /etc/nginx/sites-available/myflaskapp /etc/nginx/sites-enabled\n",
        "\n",
        "\n",
        "Test the Nginx configuration and restart Nginx:\n",
        "\n",
        "sudo nginx -t\n",
        "sudo systemctl restart nginx\n",
        "\n",
        "### Step 7: Adjust Firewall Settings\n",
        "If you have a firewall enabled, allow Nginx traffic:\n",
        "\n",
        "sudo ufw allow 'Nginx Full'\n",
        "\n",
        "\n",
        "### Step 8: Access Your Application\n",
        "Your Flask application should now be accessible at `http://your_domain_or_IP`.\n",
        "\n"
      ],
      "metadata": {
        "id": "1wPYswZOTGUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###49. Make a fully functional web application using flask, Mangodb. Signup,Signin page.And after successfully login .Say hello Geeks message at webpage."
      ],
      "metadata": {
        "id": "E1PLlJ9G78yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ibJ2aPfRTmQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50.1 What is the difference between Series & Dataframes "
      ],
      "metadata": {
        "id": "6i2WazN4JX1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Series: The Solo Act\n",
        "\n",
        "A **Pandas Series** is like a solo violinist—graceful, focused, and playing a single melody. Here's what you need to know:\n",
        "\n",
        "- **One-Dimensional**: A Series is a one-dimensional array-like object. It's your go-to for handling simple, single-variable datasets. Imagine it as a column in a spreadsheet or a single column of a database table.\n",
        "- **Data Variety**: You can store any type of data in a Series—integers, floats, strings, or even your favorite cat memes (okay, maybe not the memes, but you get the idea).\n",
        "- **Index Magic**: Each element in a Series has a unique identifier called an index. It's like having nametags at a party—everyone knows who's who.\n",
        "- **Vectorized Goodness**: Series supports vectorized operations. Fancy term, right? It means you can perform arithmetic on the entire Series without looping through each element manually. Efficiency FTW! 🚀\n",
        "\n",
        "Creating a Series is as easy as whipping up a quick recipe:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = [1, 2, 3, 4, 5]\n",
        "series_from_list = pd.Series(data)\n",
        "\n",
        "data = {'a': 1, 'b': 2, 'c': 3}\n",
        "series_from_dict = pd.Series(data)\n",
        "\n",
        "index = ['a', 'b', 'c', 'd', 'e']\n",
        "series_custom_index = pd.Series(data, index=index)\n",
        "\n",
        "\n",
        "## DataFrames: The Ensemble Cast\n",
        "\n",
        "\n",
        "\n",
        "- **Tabular Marvels**: DataFrames are like the Avengers assembling. They're two-dimensional tables with rows and columns. Each column? Yep, that's a Series! Together, they form a powerful team.\n",
        "- **Complex Tasks**: Need to filter, merge, or pivot your data? DataFrames have your back. They're perfect for advanced analysis and manipulation.\n",
        "- **Mix & Match**: DataFrames allow mixed data types. It's like a potluck dinner—numbers, strings, and dates all sitting at the same table.\n",
        "- **Row Indices & Column Headers**: DataFrames have both. Rows are like audience seats, and columns are like backstage passes. You can access data by row and column labels.\n",
        "\n",
        "Creating a DataFrame? Piece of cake:\n",
        "\n",
        "\n",
        "# Let's say we have some data\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "        'Age': [25, 30, 22]}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BGbgZC7tMcYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###50.2Create a database name Travel_Planner in mysql ,and  create a table name bookings in that which having attributes (user_id INT,  flight_id INT,hotel_id INT, activity_id INT,booking_date DATE) .fill with some dummy value .Now you have to read the content of this table using pandas as dataframe.Show the output"
      ],
      "metadata": {
        "id": "4JGjXJfixcDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the Database and Table:-\n",
        "\n",
        "CREATE DATABASE Travel_Planner;\n",
        "\n",
        "#Table Creation:-\n",
        "\n",
        "USE Travel_Planner;\n",
        "\n",
        "CREATE TABLE bookings (\n",
        "    user_id INT,\n",
        "    flight_id INT,\n",
        "    hotel_id INT,\n",
        "    activity_id INT,\n",
        "    booking_date DATE\n",
        ");\n",
        "\n",
        "#Insert Dummy Data:\n",
        "\n",
        "INSERT INTO bookings (user_id, flight_id, hotel_id, activity_id, booking_date)\n",
        "VALUES\n",
        "    (1, 101, 201, 301, '2024-07-25'),\n",
        "    (2, 102, 202, 302, '2024-07-26'),\n",
        "    (3, 103, 203, 303, '2024-07-27');\n",
        "\n",
        "\n",
        "#Reading Data Using Pandas\n",
        "import pandas as pd\n",
        "import mysql.connector\n",
        "\n",
        "# Connect to the MySQL database\n",
        "db_config = {\n",
        "    'host': 'localhost',\n",
        "    'user': 'your_username',\n",
        "    'password': 'your_password',\n",
        "    'database': 'Travel_Planner'\n",
        "}\n",
        "\n",
        "connection = mysql.connector.connect(**db_config)\n",
        "\n",
        "# Read the table into a Pandas DataFrame\n",
        "query = 'SELECT * FROM bookings'\n",
        "df = pd.read_sql(query, connection)\n",
        "\n",
        "# Close the database connection\n",
        "connection.close()\n",
        "\n",
        "# Show the DataFrame\n",
        "print(df)\n",
        "\n",
        "\n",
        "#Expected Output\n",
        "\n",
        "   user_id  flight_id  hotel_id  activity_id booking_date\n",
        "0        1        101       201          301   2024-07-25\n",
        "1        2        102       202          302   2024-07-26\n",
        "2        3        103       203          303   2024-07-27\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MmUoaZsmxzjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##50.3Difference between loc and iloc?"
      ],
      "metadata": {
        "id": "itP_2e5MyWki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## `loc`: The Label-Based Warrior\n",
        "\n",
        "- **What It Does**: `loc` stands for \"location\" and is all about labels. It's like a GPS for your DataFrame—you tell it where to find stuff based on row and column labels.\n",
        "- **How to Use It**:\n",
        "  - Pass the **row label(s)** and **column label(s)** you want to select.\n",
        "  - It's inclusive, meaning it includes the last element in the range you specify.\n",
        "  - Example: `data.loc[2:5, 'Brand':'City']` selects rows 2 to 5 (inclusive) and columns from 'Brand' to 'City'.\n",
        "\n",
        "  - You can use boolean conditions with `loc`. It's like asking, \"Show me all the rows where the brand is 'Maruti' and the mileage is greater than 25.\"\n",
        "  - Example: `data.loc[(data.Brand == 'Maruti') & (data.Mileage > 25)]`\n",
        "\n",
        "## `iloc`: The Integer-Based Ninja\n",
        "\n",
        "- **What It Does**: `iloc` is the silent assassin—it operates purely by integer positions. No labels, just indices.\n",
        "- **How to Use It**:\n",
        "  - Pass the **integer row index(es)** and **integer column index(es)**.\n",
        "  - It's exclusive, meaning it excludes the last element in the range you specify.\n",
        "  - Example: `data.iloc[2:6, 1:4]` selects rows 2 to 5 (exclusive) and columns 1 to 3.\n",
        "\n",
        "  - You can slice rows and columns using integer positions. It's like saying, \"Give me the first 3 rows and the last 2 columns.\"\n",
        "  - Example: `data.iloc[:3, -2:]`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dKO4eSvLydpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is the difference between supervised and unsupervised learning?"
      ],
      "metadata": {
        "id": "8ePBDwe4y1G_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Supervised Learning: The Guided Journey**\n",
        "\n",
        "- **What It Does**: Imagine a wise mentor guiding an apprentice. That's supervised learning! It's all about labeled data and precise predictions.\n",
        "- **How It Works**:\n",
        "  - **Labeled Data**: In supervised learning, the algorithm trains on a dataset where each input example is paired with a corresponding output label. It's like having a teacher who corrects your homework.\n",
        "  - **Mapping Function**: The goal is to find a mapping or relationship between input variables (features) and the desired output (target). Think of it as deciphering a magical spell.\n",
        "  - **Types**:\n",
        "    - **Regression**: Predicting continuous values. For instance, estimating house prices based on features like square footage, location, and the number of bedrooms.\n",
        "    - **Classification**: Assigning inputs to predefined categories. Examples include spam email detection, image classification (cat or dog?), and sentiment analysis.\n",
        "- **Why It's Called \"Supervised\"**: Picture an apprentice learning under the watchful eye of a master. The algorithm iteratively makes predictions, and the teacher (ground truth) corrects it until it performs well enough.\n",
        "\n",
        "**Example**: Imagine a basket of fresh fruits—apples, bananas, cherries, and grapes. You've learned from past experience that certain features (like shape) determine the fruit type. That's your training data. The algorithm learns this magical connection between features and fruit types.\n",
        "\n",
        "## **Unsupervised Learning: The Hidden Patterns**\n",
        "\n",
        "- **What It Does**: Unsupervised learning is like wandering through an enchanted forest without a map. It explores patterns within unlabeled data.\n",
        "- **How It Works**:\n",
        "  - **No Labels**: The data lacks explicit output labels. It's a mystery waiting to be unraveled.\n",
        "  - **Inherent Structure**: The algorithm seeks hidden structures, clusters, or relationships. It's like finding constellations in the night sky.\n",
        "  - **Types**:\n",
        "    - **Clustering**: Grouping similar data points together. Imagine sorting magical creatures based on their characteristics—fairies, goblins, and trolls.\n",
        "    - **Dimensionality Reduction**: Simplifying complex data. Think of it as folding a treasure map to fit in your pocket.\n",
        "    - **Association Rule Learning**: Discovering interesting connections. Like realizing that wizards who brew potions also tend to collect rare herbs.\n",
        "- **Why It's Called \"Unsupervised\"**: No teacher, no labels—just the algorithm exploring the mystical data forest on its own.\n",
        "\n",
        "**Example**: Imagine a library filled with ancient scrolls. You don't know the language, but you notice patterns—similar symbols, recurring themes. That's unsupervised learning, deciphering the hidden wisdom.\n",
        "\n",
        "\n",
        "\n",
        "- **Supervised**: Precise, guided, and teacher-approved.\n",
        "- **Unsupervised**: Mysterious, exploratory, and full of surprises.\n",
        "\n",
        "So, which path will you choose, brave data adventurer?\n",
        "\n"
      ],
      "metadata": {
        "id": "NMtIwvQUy7Io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explain the bias-variance tradeoff?"
      ],
      "metadata": {
        "id": "8ZBoW6BizSG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## The Bias-Variance Tradeoff: A Magical Dance\n",
        "\n",
        "In the mystical realm of machine learning, we encounter two mystical creatures: **Bias** and **Variance**. They're like yin and yang, constantly influencing our models. Let's meet them:\n",
        "\n",
        "1. **Bias**:\n",
        "   - Imagine Bias as an old wizard who makes assumptions about the world. When a model has high bias, it's like this wizard wearing blinders—it oversimplifies things.\n",
        "   - **Error from Assumptions**: High bias means the model assumes too much about the underlying data distribution. It might miss important patterns or relationships.\n",
        "   - **Underfitting**: The model is like a student who didn't study enough for the magical exam. It performs poorly on both the training data and unseen data.\n",
        "   - **Solution**: To reduce bias, we need a more complex model—one that can capture intricate patterns.\n",
        "\n",
        "2. **Variance**:\n",
        "   - Now meet Variance, the mischievous sprite. It's sensitive to every little detail in the training data. When variance is high, the model dances wildly.\n",
        "   - **Error from Sensitivity**: High variance means the model is too flexible. It molds itself to every training data point, even the noisy ones.\n",
        "   - **Overfitting**: The model memorizes the training data but struggles with new data. It's like a parrot reciting spells without understanding their meaning.\n",
        "   - **Solution**: To tame variance, we need a simpler model—one that doesn't get carried away by noise.\n",
        "\n",
        "\n",
        "- **High Bias, Low Variance**:\n",
        "  - The wizard with blinders. Simple model, but it might miss important patterns.\n",
        "  - Safe for unseen data, but not very accurate.\n",
        "  - Think of it as a cautious fortune teller who predicts the weather—always saying \"partly cloudy.\"\n",
        "- **Low Bias, High Variance**:\n",
        "  - The wild dancer. Complex model, but it might overfit.\n",
        "  - Great on training data, but risky for unseen data.\n",
        "  - Imagine a flamboyant magician who predicts lottery numbers—sometimes right, sometimes way off.\n",
        "\n",
        "## Finding the  Spot\n",
        "\n",
        "- **Cross-Validation**: Test your model on unseen data (validation set). Adjust complexity until it performs well without overfitting.\n",
        "- **Regularization**: Add a magical constraint to your model. It keeps it in check, preventing wild dances or overly cautious predictions.\n",
        "- **Ensemble Magic**: Combine multiple models—each with its bias and variance—to create a harmonious choir. Bagging, boosting, and random forests are our secret spells.\n",
        "\n"
      ],
      "metadata": {
        "id": "tnDfu3PczV-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are precision and recall? How are they different from accuracy?"
      ],
      "metadata": {
        "id": "f0kcDBT_z1_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Precision:\n",
        "\n",
        "- **What It Measures**: Precision is like a skilled archer aiming for the bullseye. It answers the question: \"How often does our model hit the target when it predicts the positive class?\"\n",
        "- **Formula**: Precision = True Positives / (True Positives + False Positives)\n",
        "- **Interpretation**:\n",
        "  - High precision means our model is cautious—it doesn't make many false positive predictions. When it says something is positive, it's usually right.\n",
        "  - Low precision, on the other hand, means our model is trigger-happy—it predicts positives even when it shouldn't. Beware the false alarms!\n",
        "\n",
        "## Recall:\n",
        "\n",
        "- **What It Measures**: Recall (also known as sensitivity or true positive rate) is the adventurer's lantern in the dark forest. It answers: \"How well does our model find all the actual positive instances?\"\n",
        "- **Formula**: Recall = True Positives / (True Positives + False Negatives)\n",
        "- **Interpretation**:\n",
        "  - High recall means our model is thorough—it rarely misses true positives. It hunts down every magical creature in the dataset.\n",
        "  - Low recall, however, means our model is forgetful—it lets some positive instances slip through its fingers. Lost treasures!\n",
        "\n",
        "## Accuracy:\n",
        "\n",
        "- **What It Measures**: Accuracy is the ancient prophecy—the overall correctness of our model's predictions.\n",
        "- **Formula**: Accuracy = (True Positives + True Negatives) / Total Predictions\n",
        "- **Interpretation**:\n",
        "  - High accuracy means our model is a wise sage—it gets most predictions right. The stars align!\n",
        "  - But beware: Accuracy can be deceptive. If your dataset is imbalanced (lots of negatives, few positives), high accuracy might hide poor performance on the positive class.\n",
        "\n",
        "\n",
        "\n",
        "- **Choose Wisely**: Precision and recall are often at odds. Boosting one might diminish the other. It's like balancing a wand on your fingertip.\n",
        "- **Context Matters**: Consider the stakes. In medical diagnoses, high recall (finding all true positives) is crucial. In spam filters, high precision (avoiding false positives) matters more.\n",
        "\n"
      ],
      "metadata": {
        "id": "tm0fWo49z6C8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is overfitting and how can it be prevented?"
      ],
      "metadata": {
        "id": "jOp_ZZF40zhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Overfitting: The Enchantment Gone Awry\n",
        "\n",
        "**Overfitting** occurs when a machine learning model gets too cozy with its training data. It's like a bard who memorizes every tavern song but stumbles when faced with new melodies. Here's the essence:\n",
        "\n",
        "1. **What It Is**:\n",
        "   - The model fits the training data perfectly—like a tailor sewing a custom cloak. But when it encounters new, unseen data, it falters.\n",
        "   - Overfitting is the siren's song that lures models into the treacherous waters of memorizing noise instead of finding true patterns.\n",
        "\n",
        "2. **Prevention Spells**:\n",
        "   - **Simpler Models**: Start with a humble wand (a simpler model). Add complexity only if necessary. Complexity isn't always the answer; sometimes, a well-crafted cantrip suffices.\n",
        "   - **More Data**: Gather more tales, more legends! The larger your dataset, the better your model can learn universal truths. It's like having a library of ancient scrolls at your disposal.\n",
        "   - **Cross-Validation**: Imagine a magical mirror showing how well your model performs on unseen data. Cross-validation splits your dataset, ensuring your model doesn't cling too tightly to its training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bfg382H_03dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explain the concept of cross-validation?"
      ],
      "metadata": {
        "id": "jTXSXWZR1WDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Cross-validation** is a technique used in machine learning to evaluate a model's performance on unseen data. Here's how it works:\n",
        "\n",
        "1. **Divide and Conquer**:\n",
        "   - Take your available data and split it into multiple subsets (folds).\n",
        "   - Reserve one fold as a validation set, and train the model on the remaining folds.\n",
        "\n",
        "2. **Test and Validate**:\n",
        "   - Evaluate the model's performance using the validation set.\n",
        "   - Repeat this process, rotating which fold serves as the validation set each time.\n",
        "\n",
        "3. **Why It Matters**:\n",
        "   - Cross-validation provides a more robust estimate of how well your model will generalize to new, unseen data.\n",
        "   - It helps avoid overfitting (when a model fits the training data too closely but performs poorly on new data).\n",
        "\n"
      ],
      "metadata": {
        "id": "vt0hXQ2-1bbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is the difference between a classification and a regression problem?"
      ],
      "metadata": {
        "id": "rJiuf9kg1of5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Classification**:\n",
        "   - **Objective**: In classification, our goal is to categorize data into predefined classes or discrete labels.\n",
        "   - **Examples**:\n",
        "     - Predicting whether an email is spam or not (binary classification).\n",
        "     - Identifying the species of a flower based on its features (multiclass classification).\n",
        "   - **Output**: The output is a discrete value (e.g., \"spam\" or \"not spam,\" \"cat,\" \"dog,\" or \"bird\").\n",
        "   - **Decision Boundary**: We find a decision boundary that separates different classes.\n",
        "\n",
        "2. **Regression**:\n",
        "   - **Objective**: Regression aims to predict continuous, real-value quantities.\n",
        "   - **Examples**:\n",
        "     - Predicting house prices based on features like square footage, location, and number of bedrooms.\n",
        "     - Estimating the temperature based on historical data and time of day.\n",
        "   - **Output**: The output is a continuous value (e.g., a price, temperature, or weight).\n",
        "   - **Error Measurement**: Regression models are evaluated based on the error in their predictions.\n",
        "\n",
        "In summary:\n",
        "- **Classification**: Discrete labels, decision boundaries.\n",
        "- **Regression**: Continuous values, error measurement.\n",
        "\n"
      ],
      "metadata": {
        "id": "3kvEMMVi1trc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain the concept of ensemble learning?"
      ],
      "metadata": {
        "id": "MbfqdmRKOXVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble learning is a powerful machine learning technique that combines multiple models to improve the overall performance and robustness of predictions. The main idea is to leverage the strengths of different models to produce a more accurate and reliable prediction than any single model could achieve on its own.\n",
        "\n",
        "### Key Concepts of Ensemble Learning\n",
        "\n",
        "1. **Base Learners**: These are the individual models that are combined in an ensemble. They can be of the same type (e.g., multiple decision trees) or different types (e.g., decision trees, neural networks, support vector machines).\n",
        "\n",
        "2. **Aggregation Methods**: The predictions from the base learners are combined using various methods to produce the final output. Common aggregation methods include:\n",
        "   - **Averaging**: For regression tasks, the predictions of all models are averaged.\n",
        "   - **Voting**: For classification tasks, the class with the most votes from the base learners is chosen.\n",
        "   - **Weighted Voting**: Each model's vote is weighted based on its accuracy or other criteria.\n",
        "\n",
        "3. **Types of Ensemble Methods**:\n",
        "   - **Bagging (Bootstrap Aggregating)**: This method involves training multiple models on different subsets of the training data (created by random sampling with replacement) and then averaging their predictions. Random Forest is a popular example of a bagging method.\n",
        "   - **Boosting**: This method trains models sequentially, with each new model focusing on the errors made by the previous ones. The models are combined to reduce bias and variance. Examples include AdaBoost, Gradient Boosting, and XGBoost.\n",
        "   - **Stacking**: This method involves training multiple models (base learners) and then using another model (meta-learner) to combine their predictions. The meta-learner is trained on the outputs of the base learners.\n",
        "\n",
        "### Benefits of Ensemble Learning\n",
        "\n",
        "- **Improved Accuracy**: By combining multiple models, ensemble methods often achieve higher accuracy than individual models.\n",
        "- **Reduced Overfitting**: Ensemble methods can reduce the risk of overfitting, especially when using techniques like bagging.\n",
        "- **Robustness**: Ensembles are generally more robust to noise and outliers in the data.\n",
        "\n",
        "### Example: Random Forest\n",
        "\n",
        "Random Forest is a popular ensemble method that uses bagging with decision trees. Each tree is trained on a different subset of the data, and the final prediction is made by averaging the predictions of all trees (for regression) or by majority voting (for classification).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NtXohRnrOs5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ###What is gradient descent and how does it work/\n"
      ],
      "metadata": {
        "id": "ocDsmTcnPHCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is a fundamental optimization algorithm used in machine learning and deep learning to minimize the cost or loss function of a model. Here's a detailed explanation of what it is and how it works:\n",
        "\n",
        "### What is Gradient Descent?\n",
        "\n",
        "Gradient descent is an iterative optimization algorithm used to find the minimum of a function. In the context of machine learning, it is used to minimize the cost function, which measures the difference between the predicted and actual values. By minimizing this cost function, the model's parameters (weights and biases) are adjusted to improve the model's accuracy.\n",
        "\n",
        "### How Does Gradient Descent Work?\n",
        "\n",
        "1. **Initialization**: Start with initial values for the model parameters (weights and biases). These can be set to zero, small random values, or any other initialization method.\n",
        "\n",
        "2. **Compute the Cost Function**: Calculate the cost function, which measures how well the model's predictions match the actual data. Common cost functions include Mean Squared Error (MSE) for regression and Cross-Entropy Loss for classification.\n",
        "\n",
        "3. **Compute the Gradient**: Calculate the gradient of the cost function with respect to each parameter. The gradient is a vector of partial derivatives that indicates the direction and rate of the steepest increase in the cost function.\n",
        "\n",
        "4. **Update the Parameters**: Adjust the parameters in the opposite direction of the gradient. This step is repeated iteratively to move the parameters towards the minimum of the cost function. The update rule is:\n",
        "   $$ \\theta = \\theta - \\alpha \\nabla J(\\theta) $$\n",
        "   where:\n",
        "   - \\( \\theta \\) represents the parameters (weights and biases).\n",
        "   - \\( \\alpha \\) is the learning rate, a small positive value that controls the step size.\n",
        "   - \\( \\nabla J(\\theta) \\) is the gradient of the cost function with respect to the parameters.\n",
        "\n",
        "5. **Repeat**: Continue the process of computing the cost function, calculating the gradient, and updating the parameters until the cost function converges to a minimum or a predefined number of iterations is reached.\n",
        "\n",
        "### Types of Gradient Descent\n",
        "\n",
        "1. **Batch Gradient Descent**: Uses the entire dataset to compute the gradient at each step. It is computationally expensive for large datasets but provides a stable convergence.\n",
        "\n",
        "2. **Stochastic Gradient Descent (SGD)**: Uses a single data point to compute the gradient at each step. It is faster and can handle large datasets but may have more fluctuations in the cost function.\n",
        "\n",
        "3. **Mini-Batch Gradient Descent**: Uses a small batch of data points to compute the gradient at each step. It balances the trade-offs between batch gradient descent and SGD.\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Hypothetical data\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Parameters\n",
        "theta = np.random.randn(2)\n",
        "learning_rate = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "# Gradient Descent\n",
        "for i in range(iterations):\n",
        "    y_pred = theta[0] + theta[1] * X\n",
        "    error = y_pred - y\n",
        "    cost = (1/2) * np.mean(error**2)\n",
        "    gradient = np.array([np.mean(error), np.mean(error * X)])\n",
        "    theta -= learning_rate * gradient\n",
        "\n",
        "print(f\"Optimized parameters: {theta}\")\n",
        "### Benefits of Gradient Descent\n",
        "\n",
        "- **Efficiency**: It is computationally efficient for large datasets.\n",
        "- **Scalability**: It can be applied to various machine learning models, including linear regression, logistic regression, and neural networks.\n",
        "- **Flexibility**: Different variants (batch, stochastic, mini-batch) can be used based on the problem and dataset size.\n",
        "\n",
        "Gradient descent is a cornerstone of many machine learning algorithms and is essential for training models effectively.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc96GF4EPNCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Describe the difference between batch gradient descent and stochastic gradient descent"
      ],
      "metadata": {
        "id": "nd8NfYMCPk1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Gradient Descent (BGD) and Stochastic Gradient Descent (SGD) are two popular optimization algorithms used to minimize the cost function in machine learning models. Here's a detailed comparison:\n",
        "\n",
        "### Batch Gradient Descent (BGD)\n",
        "\n",
        "1. **Data Processing**: BGD computes the gradient of the cost function using the entire training dataset in each iteration.\n",
        "2. **Convergence Speed**: It takes longer to converge since it processes the entire dataset at each step.\n",
        "3. **Accuracy**: BGD is more accurate as it uses the full dataset to compute the gradient, leading to a more stable convergence.\n",
        "4. **Computation and Memory Requirements**: It requires more computation and memory because it processes the entire dataset in each iteration.\n",
        "5. **Optimization of Non-Convex Functions**: BGD can get stuck in local minima and may not escape easily.\n",
        "\n",
        "### Stochastic Gradient Descent (SGD)\n",
        "\n",
        "1. **Data Processing**: SGD computes the gradient using only a single training example or a small subset of examples in each iteration.\n",
        "2. **Convergence Speed**: It can converge faster since it updates the model parameters after processing each example, leading to more frequent updates.\n",
        "3. **Accuracy**: SGD can be less accurate as it introduces more noise and variance in the gradient estimate due to using a single example or a small subset.\n",
        "4. **Computation and Memory Requirements**: It requires less computation and memory since it processes only one example or a small subset in each iteration.\n",
        "5. **Optimization of Non-Convex Functions**: SGD is more suitable for optimizing non-convex functions as it can escape local minima and find the global minimum more effectively.\n",
        "\n",
        "\n",
        "\n",
        "### Example\n",
        "\n",
        "Here's a simple illustration of the update rule for both methods:\n",
        "\n",
        "- **BGD**:\n",
        "  $$ \\theta = \\theta - \\alpha \\nabla J(\\theta) $$\n",
        "  where \\( \\nabla J(\\theta) \\) is the gradient computed over the entire dataset.\n",
        "\n",
        "- **SGD**:\n",
        "  $$ \\theta = \\theta - \\alpha \\nabla J(\\theta; x^{(i)}, y^{(i)}) $$\n",
        "  where \\( \\nabla J(\\theta; x^{(i)}, y^{(i)}) \\) is the gradient computed using a single training example \\((x^{(i)}, y^{(i)})\\).\n",
        "\n",
        "Both methods have their advantages and are chosen based on the specific problem, dataset size, and computational resources¹²³.\n",
        "\n"
      ],
      "metadata": {
        "id": "mtWIltTPPqCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is the curse of dimensionality in machine learning?"
      ],
      "metadata": {
        "id": "IV4D_dnhP8rT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **curse of dimensionality** refers to the various challenges and complications that arise when working with high-dimensional data in machine learning. As the number of features or dimensions in a dataset increases, several issues can occur:\n",
        "\n",
        "### Key Challenges\n",
        "\n",
        "1. **Data Sparsity**: In high-dimensional spaces, data points become sparse, making it difficult to find meaningful patterns. This sparsity means that the data is spread out over a vast space, and the density of data points is low.\n",
        "\n",
        "2. **Increased Computational Complexity**: Higher dimensions require more computational resources and time to process the data. Algorithms that work well in low-dimensional spaces may become inefficient and slow.\n",
        "\n",
        "3. **Overfitting**: With more dimensions, models can become overly complex and fit the noise in the data rather than the underlying patterns. This reduces the model's ability to generalize to new, unseen data.\n",
        "\n",
        "4. **Distance Metrics Lose Meaning**: In high-dimensional spaces, the difference in distances between data points tends to become negligible. This makes distance-based algorithms, like k-nearest neighbors, less effective.\n",
        "\n",
        "5. **Visualization Challenges**: Visualizing high-dimensional data is difficult, making exploratory data analysis and understanding the data more challenging.\n",
        "\n",
        "### Mitigating the Curse of Dimensionality\n",
        "\n",
        "To address these challenges, several techniques can be employed:\n",
        "\n",
        "1. **Dimensionality Reduction**: Techniques like Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and t-distributed Stochastic Neighbor Embedding (t-SNE) can reduce the number of dimensions while preserving the essential information.\n",
        "\n",
        "2. **Feature Selection**: Identify and select the most relevant features from the dataset, discarding irrelevant or redundant ones. This simplifies the model and improves its efficiency.\n",
        "\n",
        "3. **Regularization**: Techniques like L1 and L2 regularization can help prevent overfitting by adding a penalty for large coefficients in the model.\n",
        "\n",
        "4. **Data Preprocessing**: Normalize or standardize the data to ensure that all features contribute equally to the model. Handle missing values appropriately to maintain data integrity.\n",
        "\n",
        "### Example\n",
        "\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "print(\"Original shape:\", X.shape)\n",
        "print(\"Reduced shape:\", X_reduced.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gavA3eKvQGu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 and L2 regularization are techniques used to prevent overfitting in machine learning models by adding a penalty to the loss function. Here's a detailed comparison:\n",
        "\n",
        "### L1 Regularization (Lasso Regression)\n",
        "\n",
        "1. **Penalty Term**: Adds the absolute value of the magnitude of the coefficients as a penalty term to the loss function.\n",
        "   $$ \\text{L1 Regularization} = \\text{Loss Function} + \\lambda \\sum_{i} |w_i| $$\n",
        "   where \\( \\lambda \\) is the regularization parameter and \\( w_i \\) are the model coefficients.\n",
        "\n",
        "2. **Effect on Coefficients**: Tends to shrink some coefficients to exactly zero, effectively performing feature selection by eliminating less important features.\n",
        "\n",
        "3. **Use Case**: Useful when you have a large number of features and you want to identify the most important ones.\n",
        "\n",
        "### L2 Regularization (Ridge Regression)\n",
        "\n",
        "1. **Penalty Term**: Adds the squared magnitude of the coefficients as a penalty term to the loss function.\n",
        "   $$ \\text{L2 Regularization} = \\text{Loss Function} + \\lambda \\sum_{i} w_i^2 $$\n",
        "   where \\( \\lambda \\) is the regularization parameter and \\( w_i \\) are the model coefficients.\n",
        "\n",
        "2. **Effect on Coefficients**: Tends to shrink coefficients evenly but does not eliminate any, leading to smaller, more evenly distributed weights.\n",
        "\n",
        "3. **Use Case**: Useful when you have collinear or codependent features and you want to keep all features but reduce their impact.\n",
        "\n",
        "### Practical Differences\n",
        "\n",
        "- **Feature Selection**: L1 regularization can be used for feature selection as it can shrink some coefficients to zero, effectively removing those features from the model. L2 regularization, on the other hand, does not perform feature selection but rather reduces the impact of less important features by shrinking their coefficients.\n",
        "- **Model Complexity**: L1 regularization tends to produce simpler models with fewer features, while L2 regularization produces models where all features are retained but with reduced impact.\n",
        "- **Handling Multicollinearity**: L2 regularization is more effective in handling multicollinearity (when features are highly correlated) by distributing the weights more evenly.\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=10, noise=0.1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# L1 Regularization (Lasso)\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "print(\"Lasso coefficients:\", lasso.coef_)\n",
        "\n",
        "# L2 Regularization (Ridge)\n",
        "ridge = Ridge(alpha=0.1)\n",
        "ridge.fit(X_train, y_train)\n",
        "print(\"Ridge coefficients:\", ridge.coef_)\n",
        "\n"
      ],
      "metadata": {
        "id": "6nwyf1E_QWZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is a confusion matrix and how is it used?\n"
      ],
      "metadata": {
        "id": "f07liAXuQt1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **confusion matrix** is a performance evaluation tool used in machine learning, particularly for classification problems. It provides a detailed breakdown of the model's predictions compared to the actual outcomes, helping to understand the performance and identify areas for improvement.\n",
        "\n",
        "### Structure of a Confusion Matrix\n",
        "\n",
        "For a binary classification problem, the confusion matrix is a 2x2 table with the following components:\n",
        "\n",
        "|                | Predicted Positive | Predicted Negative |\n",
        "|----------------|--------------------|--------------------|\n",
        "| **Actual Positive** | True Positive (TP)      | False Negative (FN)     |\n",
        "| **Actual Negative** | False Positive (FP)     | True Negative (TN)      |\n",
        "\n",
        "- **True Positive (TP)**: The model correctly predicts the positive class.\n",
        "- **True Negative (TN)**: The model correctly predicts the negative class.\n",
        "- **False Positive (FP)**: The model incorrectly predicts the positive class (Type I error).\n",
        "- **False Negative (FN)**: The model incorrectly predicts the negative class (Type II error).\n",
        "\n",
        "### Metrics Derived from the Confusion Matrix\n",
        "\n",
        "1. **Accuracy**: The ratio of correctly predicted instances (both true positives and true negatives) to the total instances.\n",
        "   $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "2. **Precision**: The ratio of true positive predictions to the total number of positive predictions (both true positives and false positives).\n",
        "   $$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n",
        "\n",
        "3. **Recall (Sensitivity)**: The ratio of true positive predictions to the total number of actual positives (both true positives and false negatives).\n",
        "   $$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n",
        "\n",
        "4. **Specificity**: The ratio of true negative predictions to the total number of actual negatives (both true negatives and false positives).\n",
        "   $$ \\text{Specificity} = \\frac{TN}{TN + FP} $$\n",
        "\n",
        "5. **F1 Score**: The harmonic mean of precision and recall, providing a single metric that balances both.\n",
        "   $$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
        "\n",
        "### Example Usage\n",
        "\n",
        "Imagine you have a model that classifies emails as spam or not spam. After running the model on a test dataset, you get the following confusion matrix:\n",
        "\n",
        "|                | Predicted Spam | Predicted Not Spam |\n",
        "|----------------|----------------|--------------------|\n",
        "| **Actual Spam** | 50             | 10                 |\n",
        "| **Actual Not Spam** | 5              | 35                 |\n",
        "\n",
        "From this matrix, you can calculate:\n",
        "- **Accuracy**: \\( \\frac{50 + 35}{50 + 35 + 5 + 10} = 0.85 \\) or 85%\n",
        "- **Precision**: \\( \\frac{50}{50 + 5} = 0.91 \\) or 91%\n",
        "- **Recall**: \\( \\frac{50}{50 + 10} = 0.83 \\) or 83%\n",
        "- **F1 Score**: \\( 2 \\times \\frac{0.91 \\times 0.83}{0.91 + 0.83} \\approx 0.87 \\) or 87%\n",
        "\n",
        "### Importance of the Confusion Matrix\n",
        "\n",
        "The confusion matrix provides a comprehensive view of the model's performance, highlighting not just the overall accuracy but also the types of errors the model is making. This is especially useful in scenarios with imbalanced datasets, where accuracy alone might be misleading¹²³.\n",
        "\n"
      ],
      "metadata": {
        "id": "8bs04bHeQz8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define AUC-ROC curve?"
      ],
      "metadata": {
        "id": "wZaIVOC5REhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **AUC-ROC curve** is a crucial tool in evaluating the performance of binary classification models. Let's break down what it is and how it's used:\n",
        "\n",
        "### ROC Curve (Receiver Operating Characteristic Curve)\n",
        "\n",
        "The ROC curve is a graphical representation that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It plots two parameters:\n",
        "- **True Positive Rate (TPR)**, also known as Sensitivity or Recall, on the y-axis.\n",
        "- **False Positive Rate (FPR)**, also known as 1-Specificity, on the x-axis.\n",
        "\n",
        "### AUC (Area Under the Curve)\n",
        "\n",
        "The AUC represents the area under the ROC curve. It provides a single scalar value that summarizes the performance of the classifier across all possible thresholds. The AUC value ranges from 0 to 1:\n",
        "- **AUC = 1**: Perfect model.\n",
        "- **AUC = 0.5**: Model with no discrimination ability (equivalent to random guessing).\n",
        "- **AUC < 0.5**: Model performing worse than random guessing.\n",
        "\n",
        "### How It Works\n",
        "\n",
        "1. **Plotting the ROC Curve**: For different threshold values, calculate the TPR and FPR and plot these points on the graph.\n",
        "2. **Calculating AUC**: The AUC is the integral of the ROC curve. It measures the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a model that predicts whether an email is spam or not. By varying the threshold, you can plot the TPR and FPR to create the ROC curve. The AUC will then give you an overall measure of how well your model distinguishes between spam and non-spam emails.\n",
        "\n",
        "### Importance\n",
        "\n",
        "- **Model Comparison**: AUC-ROC is useful for comparing different models. A model with a higher AUC is generally better.\n",
        "- **Threshold Selection**: Helps in selecting the optimal threshold that balances TPR and FPR based on the specific needs of the application.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example of how to plot an ROC curve and calculate AUC in Python using scikit-learn:\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_true are the true labels and y_scores are the predicted scores\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "auc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code will plot the ROC curve and display the AUC value, providing a visual and quantitative measure of your model's performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "vcCRVaytRZaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain the k-nearest neighbors algorithm?\n",
        "\n"
      ],
      "metadata": {
        "id": "j1T4253pR4my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **k-nearest neighbors (k-NN)** algorithm is a simple, yet powerful, supervised learning algorithm used for both classification and regression tasks. Here's a detailed explanation:\n",
        "\n",
        "### How k-NN Works\n",
        "\n",
        "1. **Training Phase**:\n",
        "   - k-NN is an instance-based or lazy learning algorithm, meaning it doesn't explicitly train a model. Instead, it stores the entire training dataset.\n",
        "   \n",
        "2. **Prediction Phase**:\n",
        "   - **Classification**: For a given test instance, the algorithm finds the \\( k \\) training instances closest to the test instance (using a distance metric like Euclidean distance). The test instance is then assigned the class that is most common among these \\( k \\) nearest neighbors.\n",
        "   - **Regression**: For regression tasks, the algorithm finds the \\( k \\) nearest neighbors and predicts the value as the average of the values of these neighbors.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "- **Distance Metric**: The most commonly used distance metric is Euclidean distance, but other metrics like Manhattan distance or Minkowski distance can also be used.\n",
        "- **Choosing \\( k \\)**: The value of \\( k \\) is a crucial hyperparameter. A small \\( k \\) can lead to a noisy model, while a large \\( k \\) can smooth out the predictions too much. Cross-validation is often used to find the optimal \\( k \\).\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset of points in a 2D space, each labeled as either \"red\" or \"blue\". To classify a new point, you would:\n",
        "1. Calculate the distance from the new point to all points in the dataset.\n",
        "2. Identify the \\( k \\) nearest points.\n",
        "3. Assign the new point the label that is most common among these \\( k \\) points.\n",
        "\n",
        "### Advantages\n",
        "\n",
        "- **Simplicity**: Easy to understand and implement.\n",
        "- **No Training Phase**: Since it stores the entire dataset, there's no explicit training phase.\n",
        "- **Versatility**: Can be used for both classification and regression tasks.\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- **Computationally Intensive**: As it requires calculating the distance to all training points, it can be slow for large datasets.\n",
        "- **Memory Intensive**: Needs to store the entire training dataset.\n",
        "- **Sensitive to Irrelevant Features**: Performance can degrade if the dataset has many irrelevant features.\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "Here's a simple implementation of k-NN using scikit-learn:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize k-NN classifier with k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "This code demonstrates how to use k-NN for classification on the Iris dataset, splitting the data into training and testing sets, fitting the model, making predictions, and evaluating accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "xh2lTkOcR9XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain the basic concept of a Support Vector Machine (SVM)?"
      ],
      "metadata": {
        "id": "EnfS8PgESPcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Support Vector Machine (SVM)** is a supervised machine learning algorithm used for both classification and regression tasks, though it is more commonly used for classification. Here's a breakdown of the basic concept:\n",
        "\n",
        "### Key Concepts of SVM\n",
        "\n",
        "1. **Hyperplane**: In SVM, the goal is to find the optimal hyperplane that separates the data points of different classes. In a 2D space, this hyperplane is a line, while in higher dimensions, it becomes a plane or a hyperplane.\n",
        "\n",
        "2. **Support Vectors**: These are the data points that are closest to the hyperplane. They are critical in defining the position and orientation of the hyperplane. The algorithm uses these points to maximize the margin between the classes.\n",
        "\n",
        "3. **Margin**: The margin is the distance between the hyperplane and the nearest data points from each class. SVM aims to maximize this margin, ensuring that the hyperplane is as far away as possible from any data point of both classes.\n",
        "\n",
        "### How SVM Works\n",
        "\n",
        "1. **Linear SVM**: For linearly separable data, SVM finds the hyperplane that maximizes the margin between the two classes. This is known as the maximum-margin hyperplane.\n",
        "\n",
        "2. **Non-Linear SVM**: For data that is not linearly separable, SVM uses a technique called the **kernel trick** to transform the data into a higher-dimensional space where it becomes linearly separable. Common kernels include polynomial, radial basis function (RBF), and sigmoid.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset with two features (e.g., height and weight) and two classes (e.g., male and female). SVM will plot these data points in a 2D space and find the line (hyperplane) that best separates the two classes while maximizing the margin between them.\n",
        "\n",
        "### Advantages\n",
        "\n",
        "- **Effective in High Dimensions**: SVM is effective in high-dimensional spaces and is still effective when the number of dimensions exceeds the number of samples.\n",
        "- **Versatile**: It can be used for both linear and non-linear classification using different kernel functions.\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "- **Computationally Intensive**: Training an SVM can be computationally intensive, especially with large datasets.\n",
        "- **Choice of Kernel**: The performance of SVM depends on the choice of the kernel and its parameters, which may require careful tuning.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple visualization of how SVM works:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "\n",
        "# Create a simple dataset\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [6, 6], [7, 8], [8, 8]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])\n",
        "\n",
        "# Fit the model\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "\n",
        "# Create grid to evaluate model\n",
        "xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = clf.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "# Plot decision boundary and margins\n",
        "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
        "           linestyles=['--', '-', '--'])\n",
        "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
        "           linewidth=1, facecolors='none', edgecolors='k')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code demonstrates how to create a simple SVM classifier with a linear kernel and visualize the decision boundary along with the support vectors.\n"
      ],
      "metadata": {
        "id": "YQURm4MoSWU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How does the kernel trick work in SVM?"
      ],
      "metadata": {
        "id": "bIDbty90SpXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **kernel trick** is a fundamental technique used in Support Vector Machines (SVMs) to handle non-linear data by implicitly mapping it into a higher-dimensional space. Here's how it works:\n",
        "\n",
        "### Concept of the Kernel Trick\n",
        "\n",
        "1. **Linear vs. Non-Linear Problems**:\n",
        "   - For linearly separable data, SVMs can easily find a hyperplane that separates the classes.\n",
        "   - However, many real-world problems involve non-linear data, where a linear separator is not sufficient.\n",
        "\n",
        "2. **Feature Mapping**:\n",
        "   - One approach to handle non-linear data is to map it into a higher-dimensional space where it becomes linearly separable. This transformation is known as feature mapping.\n",
        "   - For example, data points that are not separable in a 2D space might become separable in a 3D space.\n",
        "\n",
        "3. **Kernel Functions**:\n",
        "   - The kernel trick allows SVMs to perform this mapping implicitly, without explicitly computing the coordinates in the higher-dimensional space.\n",
        "   - A kernel function computes the dot product of the data points in the higher-dimensional space directly from the original input space.\n",
        "\n",
        "### How the Kernel Trick Works\n",
        "\n",
        "1. **Kernel Function**:\n",
        "   - A kernel function \\( K(x_i, x_j) \\) takes two input vectors \\( x_i \\) and \\( x_j \\) and returns the dot product of their images in the higher-dimensional space.\n",
        "   - Common kernel functions include:\n",
        "     - **Linear Kernel**: \\( K(x_i, x_j) = x_i \\cdot x_j \\)\n",
        "     - **Polynomial Kernel**: \\( K(x_i, x_j) = (x_i \\cdot x_j + c)^d \\)\n",
        "     - **Radial Basis Function (RBF) Kernel**: \\( K(x_i, x_j) = \\exp(-\\gamma \\|x_i - x_j\\|^2) \\)\n",
        "     - **Sigmoid Kernel**: \\( K(x_i, x_j) = \\tanh(\\alpha x_i \\cdot x_j + c) \\)\n",
        "\n",
        "2. **Implicit Mapping**:\n",
        "   - The kernel function allows SVMs to operate in the original input space while implicitly considering the higher-dimensional feature space.\n",
        "   - This avoids the computational complexity of explicitly mapping the data to a higher dimension.\n",
        "\n",
        "3. **Optimization**:\n",
        "   - The SVM optimization problem is formulated in terms of the kernel function, enabling the algorithm to find the optimal hyperplane in the higher-dimensional space.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset that is not linearly separable in 2D. By using an RBF kernel, the SVM can implicitly map the data into a higher-dimensional space where a linear separator (hyperplane) can be found.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example of using an RBF kernel in Python with scikit-learn:\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]  # Use only the first two features for visualization\n",
        "y = iris.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM with RBF kernel\n",
        "clf = SVC(kernel='rbf', gamma=0.5, C=1.0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot decision boundary\n",
        "def plot_decision_boundary(X, y, model):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X_test, y_test, clf)\n",
        "\n",
        "\n",
        "This code demonstrates how to use an RBF kernel with SVM to classify the Iris dataset and visualize the decision boundary.\n",
        "\n"
      ],
      "metadata": {
        "id": "2UympViOSvCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the diferent types of kernels used in SVM and when would you use each?"
      ],
      "metadata": {
        "id": "3xgMLaajTBiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVMs) use various kernel functions to handle different types of data. Here are the most common types of kernels and their use cases:\n",
        "\n",
        "### 1. Linear Kernel\n",
        "- **Use Case**: Suitable for linearly separable data or when the number of features is large compared to the number of samples.\n",
        "- **Applications**: Text classification, document classification, and other high-dimensional data problems.\n",
        "\n",
        "### 2. Polynomial Kernel\n",
        "- **Use Case**: Effective for non-linear data where the relationship between features is polynomial.\n",
        "- **Applications**: Image processing and natural language processing tasks where interactions between features are important.\n",
        "\n",
        "### 3. Radial Basis Function (RBF) Kernel\n",
        "- **Use Case**: Default choice for non-linear problems, especially when there is no prior knowledge about the data.\n",
        "- **Applications**: General-purpose kernel used in various fields like biology, finance, and more.\n",
        "\n",
        "### 4. Sigmoid Kernel\n",
        "- **Use Case**: Similar to neural networks, useful for certain types of non-linear problems.\n",
        "- **Applications**: Not as commonly used as RBF or polynomial kernels but can be effective in specific scenarios.\n",
        "\n",
        "### 5. Custom Kernels\n",
        "- **Use Case**: Tailored to specific problems where standard kernels do not perform well.\n",
        "- **Applications**: Specialized tasks requiring domain-specific knowledge.\n",
        "\n",
        "Choosing the right kernel depends on the nature of the problem, the characteristics of the data, and the computational complexity.\n",
        "\n"
      ],
      "metadata": {
        "id": "EKr1mu8_TH2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is the hyperplane in SVM and how is it determined?"
      ],
      "metadata": {
        "id": "NXDJV_YTTWsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Support Vector Machines (SVM), the **hyperplane** is a decision boundary that separates different classes in the feature space. Here's a detailed explanation of what it is and how it is determined:\n",
        "\n",
        "### What is a Hyperplane?\n",
        "\n",
        "A hyperplane is a flat affine subspace of one dimension less than its ambient space. In simpler terms:\n",
        "- In a 2D space, a hyperplane is a line.\n",
        "- In a 3D space, a hyperplane is a plane.\n",
        "- In higher dimensions, it is a generalization of these concepts.\n",
        "\n",
        "### How is the Hyperplane Determined?\n",
        "\n",
        "1. **Equation of the Hyperplane**:\n",
        "   The hyperplane in SVM is defined by the equation:\n",
        "   $$ w \\cdot x + b = 0 $$\n",
        "   where:\n",
        "   - \\( w \\) is the weight vector (normal to the hyperplane).\n",
        "   - \\( x \\) is the input feature vector.\n",
        "   - \\( b \\) is the bias term.\n",
        "   - \\( \\cdot \\) denotes the dot product.\n",
        "\n",
        "2. **Support Vectors**:\n",
        "   The hyperplane is determined by the support vectors, which are the data points closest to the hyperplane. These points are critical as they define the margin of the classifier.\n",
        "\n",
        "3. **Maximizing the Margin**:\n",
        "   SVM aims to find the hyperplane that maximizes the margin, which is the distance between the hyperplane and the nearest data points from each class. The margin is defined as:\n",
        "   $$ \\text{Margin} = \\frac{2}{\\|w\\|} $$\n",
        "   where \\( \\|w\\| \\) is the norm of the weight vector.\n",
        "\n",
        "4. **Optimization Problem**:\n",
        "   The process of finding the optimal hyperplane involves solving the following optimization problem:\n",
        "   $$ \\min_{w, b} \\frac{1}{2} \\|w\\|^2 $$\n",
        "   subject to the constraints:\n",
        "   $$ y_i (w \\cdot x_i + b) \\geq 1 $$\n",
        "   for all training examples \\( (x_i, y_i) \\), where \\( y_i \\) is the class label (+1 or -1).\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Imagine you have a dataset with two classes that are linearly separable. The SVM algorithm will:\n",
        "1. Identify the support vectors.\n",
        "2. Calculate the optimal hyperplane that maximizes the margin between the classes.\n",
        "3. Ensure that the hyperplane is equidistant from the support vectors of both classes.\n",
        "\n",
        "### Example\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to visualize the hyperplane:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "\n",
        "# Create a simple dataset\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [6, 6], [7, 8], [8, 8]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])\n",
        "\n",
        "# Fit the model\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Plot decision boundary\n",
        "def plot_decision_boundary(X, y, model):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X, y, clf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RDgsvy0VTgNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the pros and cons of using a Support Vector Machine (SVM)?"
      ],
      "metadata": {
        "id": "-AQQIN6iT2VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVMs) are powerful and versatile machine learning algorithms, but like any tool, they come with their own set of advantages and disadvantages. Here's a detailed look at the pros and cons:\n",
        "\n",
        "### Pros of SVM\n",
        "\n",
        "1. **High Accuracy**: SVMs are known for their high accuracy, especially in high-dimensional spaces. They are effective in scenarios where the number of features is large compared to the number of samples¹.\n",
        "\n",
        "2. **Effective in High-Dimensional Spaces**: SVMs perform well in high-dimensional spaces and are particularly useful when the number of dimensions exceeds the number of samples².\n",
        "\n",
        "3. **Robustness Against Overfitting**: SVMs are robust against overfitting, especially in high-dimensional space, due to the regularization parameter that controls the trade-off between achieving a low error on the training data and minimizing model complexity².\n",
        "\n",
        "4. **Versatility with Kernels**: SVMs can handle non-linear data effectively using kernel functions like polynomial, RBF, and sigmoid, allowing them to find complex decision boundaries¹.\n",
        "\n",
        "5. **Memory Efficiency**: SVMs are memory efficient because they use a subset of the training data (support vectors) to make decisions³.\n",
        "\n",
        "### Cons of SVM\n",
        "\n",
        "1. **Computational Complexity**: Training an SVM can be computationally intensive, especially with large datasets. The time complexity can be high, making it less suitable for very large datasets³.\n",
        "\n",
        "2. **Choice of Kernel and Parameters**: The performance of SVMs heavily depends on the choice of the kernel and its parameters. Finding the optimal kernel and tuning its parameters can be challenging and time-consuming¹.\n",
        "\n",
        "3. **Less Effective on Noisy Data**: SVMs can be less effective on noisier datasets with overlapping classes. They are sensitive to the choice of the regularization parameter, which can affect their performance on such data³.\n",
        "\n",
        "4. **Lack of Transparency**: SVMs are often considered \"black box\" models because it can be difficult to interpret the results and understand how the model makes decisions¹.\n",
        "\n",
        "5. **Not Suitable for Large Datasets**: Due to the high training time, SVMs are not well-suited for very large datasets³.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **Pros**: High accuracy, effective in high-dimensional spaces, robust against overfitting, versatile with kernels, memory efficient.\n",
        "- **Cons**: Computationally intensive, challenging parameter tuning, less effective on noisy data, lack of transparency, not suitable for large datasets.\n",
        "\n",
        "Understanding these pros and cons can help you decide when to use SVMs based on the specific requirements and characteristics of your dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "i_tsCOXzT89N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain the difference between a hard margin and a soft margin SVM?"
      ],
      "metadata": {
        "id": "JeLzmA11UPYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between **hard margin** and **soft margin** SVMs lies in how they handle the separability of data and the presence of noise or outliers. Here's a detailed explanation:\n",
        "\n",
        "### Hard Margin SVM\n",
        "\n",
        "1. **Definition**: A hard margin SVM aims to find a hyperplane that perfectly separates the data points of different classes without any misclassifications.\n",
        "2. **Use Case**: Suitable for linearly separable data where there are no overlaps between classes.\n",
        "3. **Constraints**: The optimization problem for a hard margin SVM is:\n",
        "   $$ y_i (w \\cdot x_i + b) \\geq 1 $$\n",
        "   for all training examples \\( (x_i, y_i) \\), where \\( y_i \\) is the class label (+1 or -1).\n",
        "4. **Advantages**: Provides a clear and distinct separation between classes.\n",
        "5. **Disadvantages**: Not robust to noise or outliers. If the data is not perfectly separable, the hard margin SVM will fail to find a solution.\n",
        "\n",
        "### Soft Margin SVM\n",
        "\n",
        "1. **Definition**: A soft margin SVM allows for some misclassifications by introducing slack variables. This makes it more flexible and capable of handling non-linearly separable data.\n",
        "2. **Use Case**: Suitable for data that is not perfectly separable or contains noise and outliers.\n",
        "3. **Constraints**: The optimization problem for a soft margin SVM is:\n",
        "   $$ y_i (w \\cdot x_i + b) \\geq 1 - \\xi_i $$\n",
        "   where \\( \\xi_i \\geq 0 \\) are slack variables that allow some data points to be within the margin or misclassified.\n",
        "4. **Objective Function**: The objective is to minimize:\n",
        "   $$ \\frac{1}{2} \\|w\\|^2 + C \\sum_{i} \\xi_i $$\n",
        "   where \\( C \\) is a regularization parameter that controls the trade-off between maximizing the margin and minimizing the classification error.\n",
        "5. **Advantages**: More robust to noise and outliers, and can handle non-linearly separable data.\n",
        "6. **Disadvantages**: Requires careful tuning of the regularization parameter \\( C \\).\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Imagine you have a dataset with some overlap between classes. A hard margin SVM would try to find a hyperplane that perfectly separates the classes, which might not be possible. A soft margin SVM, on the other hand, would allow some misclassifications to achieve a better overall separation.\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "Here's a simple example to illustrate the difference:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "\n",
        "# Create a simple dataset\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [6, 6], [7, 8], [8, 8]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1])\n",
        "\n",
        "# Hard Margin SVM\n",
        "clf_hard = svm.SVC(kernel='linear', C=1e10)\n",
        "clf_hard.fit(X, y)\n",
        "\n",
        "# Soft Margin SVM\n",
        "clf_soft = svm.SVC(kernel='linear', C=1.0)\n",
        "clf_soft.fit(X, y)\n",
        "\n",
        "# Plot decision boundaries\n",
        "def plot_decision_boundary(X, y, model, title):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X, y, clf_hard, \"Hard Margin SVM\")\n",
        "plot_decision_boundary(X, y, clf_soft, \"Soft Margin SVM\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r5Sse1GVUkUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Describe the process of constructing a decision tree?"
      ],
      "metadata": {
        "id": "wLk86hyQaOrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing a decision tree involves several steps, from defining the problem to optimizing the final model. Here's a detailed breakdown of the process:\n",
        "\n",
        "### Steps to Construct a Decision Tree\n",
        "\n",
        "1. **Define the Decision Objective**:\n",
        "   - Clearly articulate the goal or decision you need to make. This is the root node of your decision tree.\n",
        "\n",
        "2. **Gather Relevant Data**:\n",
        "   - Collect all necessary information related to your decision. This includes the dataset you'll use to train the decision tree.\n",
        "\n",
        "3. **Identify Decision Points and Outcomes**:\n",
        "   - Determine the key decision points (features) and possible outcomes (classes) in your dataset.\n",
        "\n",
        "4. **Select the Best Feature to Split**:\n",
        "   - Use criteria like Gini impurity, information gain, or entropy to choose the best feature to split the data at each node. This process is known as **recursive partitioning**.\n",
        "\n",
        "5. **Split the Data**:\n",
        "   - Partition the dataset into subsets based on the selected feature's different criteria or classes. Each subset forms a branch of the tree.\n",
        "\n",
        "6. **Repeat the Process**:\n",
        "   - For each subset, repeat the process of selecting the best feature and splitting the data. This continues recursively until a stopping condition is met (e.g., maximum depth, minimum samples per leaf, or no further information gain).\n",
        "\n",
        "7. **Assign Probabilities and Values**:\n",
        "   - For each leaf node, assign probabilities or values based on the outcomes of the training data that reach that node.\n",
        "\n",
        "8. **Calculate Expected Values**:\n",
        "   - Calculate the expected values for each decision path to evaluate the potential outcomes.\n",
        "\n",
        "9. **Optimize and Prune the Tree**:\n",
        "   - Prune the tree to remove branches that have little importance or contribute to overfitting. This can be done using techniques like cost complexity pruning or reduced error pruning.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you are constructing a decision tree to classify whether an email is spam or not. Here's how the process might look:\n",
        "\n",
        "1. **Root Node**: Start with the entire dataset of emails.\n",
        "2. **First Split**: Choose the best feature (e.g., presence of certain keywords) to split the data.\n",
        "3. **Subsequent Splits**: Continue splitting the data based on the best features at each node.\n",
        "4. **Leaf Nodes**: Assign the final classification (spam or not spam) to each leaf node based on the majority class of the training samples that reach that node.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to construct a decision tree:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "tree.plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code demonstrates how to load a dataset, split it into training and testing sets, train a decision tree classifier, and visualize the resulting tree."
      ],
      "metadata": {
        "id": "cAFmFVWhadCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Describe the working principle of a decision tree?"
      ],
      "metadata": {
        "id": "TxXMKtzjbEqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **decision tree** is a flowchart-like structure used for both classification and regression tasks. It consists of nodes representing decisions or tests on attributes, branches representing the outcome of these decisions, and leaf nodes representing final outcomes or predictions. Here's a detailed look at how it works:\n",
        "\n",
        "### Working Principle of a Decision Tree\n",
        "\n",
        "1. **Root Node**:\n",
        "   - The root node represents the entire dataset and the initial decision to be made. It is the starting point of the tree.\n",
        "\n",
        "2. **Internal Nodes**:\n",
        "   - Each internal node represents a test or decision on an attribute. For example, in a dataset of emails, an internal node might test whether an email contains a specific keyword.\n",
        "\n",
        "3. **Branches**:\n",
        "   - Branches represent the outcome of the test or decision at each internal node. Each branch leads to another node (either an internal node or a leaf node).\n",
        "\n",
        "4. **Leaf Nodes**:\n",
        "   - Leaf nodes represent the final decision or prediction. No further splits occur at these nodes. For instance, in a classification task, a leaf node might represent the class label (e.g., spam or not spam).\n",
        "\n",
        "### Steps to Construct a Decision Tree\n",
        "\n",
        "1. **Selecting the Best Attribute**:\n",
        "   - The algorithm selects the best attribute to split the data at each node. This is done using metrics like Gini impurity, entropy, or information gain.\n",
        "   - **Gini Impurity**: Measures the likelihood of an incorrect classification of a new instance if it was randomly classified according to the distribution of classes in the dataset.\n",
        "     $$ \\text{Gini} = 1 - \\sum_{i=1}^{n} (p_i)^2 $$\n",
        "   - **Entropy**: Measures the amount of uncertainty or impurity in the dataset.\n",
        "     $$ \\text{Entropy} = -\\sum_{i=1}^{n} p_i \\log_2 (p_i) $$\n",
        "   - **Information Gain**: Measures the reduction in entropy or Gini impurity after a dataset is split on an attribute.\n",
        "     $$ \\text{Information Gain} = \\text{Entropy}_{\\text{parent}} - \\sum_{i=1}^{n} \\left( \\frac{|D_i|}{|D|} \\times \\text{Entropy}(D_i) \\right) $$\n",
        "\n",
        "2. **Splitting the Dataset**:\n",
        "   - The dataset is split into subsets based on the selected attribute. Each subset forms a branch of the tree.\n",
        "\n",
        "3. **Repeating the Process**:\n",
        "   - The process is repeated recursively for each subset, creating new internal nodes or leaf nodes until a stopping criterion is met (e.g., all instances in a node belong to the same class or a predefined depth is reached).\n",
        "\n",
        "4. **Pruning**:\n",
        "   - To prevent overfitting, the tree can be pruned by removing branches that have little importance. This can be done using techniques like cost complexity pruning or reduced error pruning.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you are constructing a decision tree to classify whether an email is spam or not. The process might look like this:\n",
        "1. **Root Node**: Start with the entire dataset of emails.\n",
        "2. **First Split**: Choose the best feature (e.g., presence of certain keywords) to split the data.\n",
        "3. **Subsequent Splits**: Continue splitting the data based on the best features at each node.\n",
        "4. **Leaf Nodes**: Assign the final classification (spam or not spam) to each leaf node based on the majority class of the training samples that reach that node.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to construct a decision tree:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "tree.plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code demonstrates how to load a dataset, split it into training and testing sets, train a decision tree classifier, and visualize the resulting tree.\n"
      ],
      "metadata": {
        "id": "7N2_GHbEbJwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is information gain and how is it used in decision trees?"
      ],
      "metadata": {
        "id": "rPvKGdxUbhfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Information gain** is a key concept used in decision trees to measure the effectiveness of an attribute in classifying the data. It quantifies the reduction in entropy (uncertainty) of the target variable when a particular feature is used to split the dataset.\n",
        "\n",
        "### How Information Gain Works\n",
        "\n",
        "1. **Entropy**:\n",
        "   - Entropy is a measure of the uncertainty or impurity in a dataset. For a binary classification problem, the entropy \\( H \\) is calculated as:\n",
        "     $$ H(D) = -p_1 \\log_2(p_1) - p_2 \\log_2(p_2) $$\n",
        "     where \\( p_1 \\) and \\( p_2 \\) are the proportions of the two classes in the dataset \\( D \\).\n",
        "\n",
        "2. **Information Gain**:\n",
        "   - Information gain is the difference between the entropy of the dataset before and after a split on a given attribute. It measures how much information a feature provides about the target variable.\n",
        "   - The information gain \\( IG \\) for an attribute \\( A \\) is calculated as:\n",
        "     $$ IG(D, A) = H(D) - \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} H(D_v) $$\n",
        "     where:\n",
        "     - \\( H(D) \\) is the entropy of the original dataset.\n",
        "     - \\( D_v \\) is the subset of \\( D \\) where attribute \\( A \\) has value \\( v \\).\n",
        "     - \\( |D_v| \\) is the number of instances in \\( D_v \\).\n",
        "     - \\( |D| \\) is the total number of instances in \\( D \\).\n",
        "\n",
        "### Using Information Gain in Decision Trees\n",
        "\n",
        "1. **Selecting the Best Attribute**:\n",
        "   - At each node of the decision tree, the algorithm calculates the information gain for each attribute and selects the attribute with the highest information gain to split the data. This ensures that each split results in the most significant reduction in entropy.\n",
        "\n",
        "2. **Splitting the Data**:\n",
        "   - The selected attribute is used to partition the dataset into subsets. Each subset corresponds to a branch of the tree, and the process is repeated recursively for each subset.\n",
        "\n",
        "3. **Building the Tree**:\n",
        "   - The process continues until a stopping criterion is met, such as all instances in a node belonging to the same class or reaching a maximum tree depth.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset of emails labeled as spam or not spam. To build a decision tree, you would:\n",
        "1. Calculate the entropy of the entire dataset.\n",
        "2. For each attribute (e.g., presence of certain keywords), calculate the information gain.\n",
        "3. Select the attribute with the highest information gain to split the data.\n",
        "4. Repeat the process for each subset until the tree is fully constructed.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to demonstrate information gain in decision trees:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the decision tree classifier\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code demonstrates how to load a dataset, split it into training and testing sets, train a decision tree classifier using entropy (which is related to information gain), and visualize the resulting tree.\n"
      ],
      "metadata": {
        "id": "hwdimRgxboRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain Gini impurity and its role in decision trees?"
      ],
      "metadata": {
        "id": "FTlNsf6XcC7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gini impurity** is a metric used in decision trees to measure the impurity or disorder of a dataset. It helps in selecting the best feature to split the data at each node of the tree. Here's a detailed explanation:\n",
        "\n",
        "### What is Gini Impurity?\n",
        "\n",
        "Gini impurity quantifies the likelihood of an incorrect classification of a randomly chosen element if it was randomly labeled according to the distribution of labels in the dataset. It ranges from 0 (pure) to 0.5 (maximum impurity for a binary classification).\n",
        "\n",
        "The formula for Gini impurity is:\n",
        "$$ \\text{Gini}(D) = 1 - \\sum_{i=1}^{C} p_i^2 $$\n",
        "where:\n",
        "- \\( D \\) is the dataset.\n",
        "- \\( C \\) is the number of classes.\n",
        "- \\( p_i \\) is the proportion of instances belonging to class \\( i \\).\n",
        "\n",
        "### Role of Gini Impurity in Decision Trees\n",
        "\n",
        "1. **Selecting the Best Feature**:\n",
        "   - At each node, the decision tree algorithm calculates the Gini impurity for each feature and selects the feature that results in the lowest Gini impurity after the split. This ensures that the chosen feature provides the most significant reduction in impurity.\n",
        "\n",
        "2. **Splitting the Data**:\n",
        "   - The selected feature is used to partition the dataset into subsets. Each subset corresponds to a branch of the tree, and the process is repeated recursively for each subset.\n",
        "\n",
        "3. **Building the Tree**:\n",
        "   - The process continues until a stopping criterion is met, such as all instances in a node belonging to the same class or reaching a maximum tree depth.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset with two classes (e.g., \"spam\" and \"not spam\"). To build a decision tree, you would:\n",
        "1. Calculate the Gini impurity of the entire dataset.\n",
        "2. For each feature (e.g., presence of certain keywords), calculate the Gini impurity after splitting the data based on that feature.\n",
        "3. Select the feature with the lowest Gini impurity to split the data.\n",
        "4. Repeat the process for each subset until the tree is fully constructed.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to demonstrate Gini impurity in decision trees:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the decision tree classifier\n",
        "clf = DecisionTreeClassifier(criterion='gini')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.\n",
        "\n",
        "target_names)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "This code demonstrates how to load a dataset, split it into training and testing sets, train a decision tree classifier using Gini impurity, and visualize the resulting tree¹²³.\n",
        "\n"
      ],
      "metadata": {
        "id": "6v9vmijTcTXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the advantages and disadvantages of decision trees"
      ],
      "metadata": {
        "id": "V-APC9KFcnYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision trees are popular machine learning algorithms due to their simplicity and interpretability. However, they also have some limitations. Here's a detailed look at the advantages and disadvantages:\n",
        "\n",
        "### Advantages of Decision Trees\n",
        "\n",
        "1. **Easy to Understand and Interpret**:\n",
        "   - Decision trees are intuitive and easy to visualize. They can be understood by non-technical stakeholders, making them useful for explaining model decisions¹.\n",
        "\n",
        "2. **Handles Both Numerical and Categorical Data**:\n",
        "   - Decision trees can handle both numerical and categorical data, making them versatile for various types of datasets².\n",
        "\n",
        "3. **Minimal Data Preparation**:\n",
        "   - They require little data preprocessing. For example, they do not require feature scaling or normalization².\n",
        "\n",
        "4. **Non-Parametric**:\n",
        "   - Decision trees do not assume any underlying distribution in the data, making them suitable for a wide range of problems¹.\n",
        "\n",
        "5. **Handles Missing Values**:\n",
        "   - They can handle missing values in the dataset, which can be beneficial when dealing with incomplete data².\n",
        "\n",
        "6. **Robust to Outliers**:\n",
        "   - Decision trees are relatively robust to outliers compared to other algorithms¹.\n",
        "\n",
        "### Disadvantages of Decision Trees\n",
        "\n",
        "1. **Prone to Overfitting**:\n",
        "   - Decision trees can easily overfit the training data, especially if they are deep and complex. This can lead to poor generalization on unseen data¹.\n",
        "\n",
        "2. **Unstable**:\n",
        "   - Small changes in the data can result in significantly different trees. This instability can be mitigated by using ensemble methods like Random Forests².\n",
        "\n",
        "3. **Greedy Algorithm**:\n",
        "   - The algorithm makes locally optimal decisions at each node, which may not lead to the globally optimal tree¹.\n",
        "\n",
        "4. **Bias Towards Dominant Classes**:\n",
        "   - If the dataset is imbalanced, decision trees can be biased towards the dominant class².\n",
        "\n",
        "5. **Computationally Expensive**:\n",
        "   - Training a decision tree can be computationally expensive, especially with large datasets¹.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **Advantages**: Easy to understand, handles both numerical and categorical data, minimal data preparation, non-parametric, handles missing values, robust to outliers.\n",
        "- **Disadvantages**: Prone to overfitting, unstable, greedy algorithm, bias towards dominant classes, computationally expensive.\n",
        "\n",
        "Understanding these pros and cons can help you decide when to use decision trees based on the specific requirements and characteristics of your dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "FNmGMLDNcueu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How do random forests improve upon decision tree?"
      ],
      "metadata": {
        "id": "BNYkMRkqc_nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forests improve upon decision trees by addressing some of their key limitations. Here are the main ways in which random forests enhance the performance and robustness of decision trees:\n",
        "\n",
        "### 1. **Reduction of Overfitting**\n",
        "- **Decision Trees**: Prone to overfitting, especially when they are deep and complex.\n",
        "- **Random Forests**: By averaging the results of multiple decision trees, random forests reduce the risk of overfitting. Each tree is trained on a different subset of the data, which helps in capturing a broader range of patterns and reduces the model's variance¹.\n",
        "\n",
        "### 2. **Improved Accuracy**\n",
        "- **Decision Trees**: Can be less accurate due to their tendency to overfit and their sensitivity to small changes in the data.\n",
        "- **Random Forests**: Typically more accurate because they aggregate the predictions of multiple trees. This ensemble approach leads to more stable and reliable predictions².\n",
        "\n",
        "### 3. **Handling Variability**\n",
        "- **Decision Trees**: Sensitive to the specific data they are trained on, leading to high variability in their predictions.\n",
        "- **Random Forests**: By using a technique called **bagging** (Bootstrap Aggregating), random forests create multiple trees from different random samples of the data. This reduces the variability and makes the model more robust³.\n",
        "\n",
        "### 4. **Feature Importance**\n",
        "- **Decision Trees**: Can sometimes give misleading importance to features due to their greedy nature.\n",
        "- **Random Forests**: Provide a more reliable estimate of feature importance by averaging the importance scores across all trees in the forest².\n",
        "\n",
        "### 5. **Handling Missing Values**\n",
        "- **Decision Trees**: Can handle missing values, but the approach might not be optimal.\n",
        "- **Random Forests**: More robust in handling missing values as they can use the majority vote from multiple trees to make predictions³.\n",
        "\n",
        "### 6. **Reduction of Bias and Variance**\n",
        "- **Decision Trees**: Can have high variance and sometimes high bias.\n",
        "- **Random Forests**: Reduce both bias and variance by combining multiple trees. This leads to better generalization on unseen data⁴.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset with high variability and some noise. A single decision tree might overfit the noise and provide unstable predictions. A random forest, by averaging the predictions of multiple trees, can smooth out the noise and provide more accurate and stable predictions.\n",
        "\n",
        "### Visualization\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to demonstrate the difference:\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy}\")\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "\n",
        "\n",
        "This code demonstrates how to train both a decision tree and a random forest on the Iris dataset and compare their accuracies.\n",
        "\n"
      ],
      "metadata": {
        "id": "gG-e5OKcdOnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How does a random forest algorithm work?"
      ],
      "metadata": {
        "id": "NvRfL03_dmOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The random forest algorithm is an ensemble learning method that combines multiple decision trees to improve the accuracy and robustness of predictions. Here’s a detailed explanation of how it works:\n",
        "\n",
        "\n",
        "####Working Principle of Random Forest\n",
        "\n",
        "->Bootstrap Sampling:\n",
        "\n",
        "\n",
        "The algorithm starts by creating multiple subsets of the original dataset using a technique called bootstrap sampling. Each subset is created by randomly selecting samples from the original dataset with replacement. This means some samples may appear multiple times in a subset, while others may not appear at all.\n",
        "\n",
        "\n",
        "->Building Decision Trees:\n",
        "\n",
        "\n",
        "For each subset, a decision tree is constructed. However, instead of considering all features for splitting nodes, the algorithm randomly selects a subset of features at each node. This introduces additional randomness and helps in creating diverse trees.\n",
        "\n",
        "\n",
        "->Training the Trees:\n",
        "\n",
        "\n",
        "Each decision tree is trained independently on its respective subset. The trees are grown to their maximum depth without pruning, which allows them to capture complex patterns in the data.\n",
        "\n",
        "\n",
        "->Aggregating Predictions:\n",
        "\n",
        "\n",
        "Once all the trees are trained, the random forest makes predictions by aggregating the results of the individual trees. For classification tasks, the final prediction is made by majority voting (i.e., the class that gets the most votes from the trees). For regression tasks, the final prediction is the average of the predictions from all the trees"
      ],
      "metadata": {
        "id": "iilmFDPpdunl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is bootstrapping in the context of random forests?"
      ],
      "metadata": {
        "id": "RKnn_amgeKKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bootstrapping in the context of random forests is a technique used to create diverse subsets of the training data for each decision tree. This method, also known as bagging (short for bootstrap aggregating), involves sampling with replacement from the original dataset to form new datasets of the same size. Here’s a detailed explanation:\n",
        "\n",
        "####How Bootstrapping Works\n",
        "\n",
        "####Sampling with Replacement:\n",
        "\n",
        "\n",
        "From the original dataset, multiple subsets are created by randomly selecting samples with replacement. This means that some samples may appear multiple times in a subset, while others may not appear at all.\n",
        "\n",
        "\n",
        "####Creating Diverse Subsets:\n",
        "\n",
        "\n",
        "Each subset is used to train a separate decision tree. Because the subsets are different, the trees will also be different, capturing various patterns in the data.\n",
        "\n",
        "\n",
        "####Training Decision Trees:\n",
        "\n",
        "\n",
        "Each decision tree is trained independently on its respective bootstrap sample. The trees are grown to their maximum depth without pruning, allowing them to capture complex patterns.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####Aggregating Predictions:\n",
        "\n",
        "\n",
        "Once all the trees are trained, the random forest makes predictions by aggregating the results of the individual trees. For classification tasks, the final prediction is made by majority voting. For regression tasks, the final prediction is the average of the predictions from all the trees."
      ],
      "metadata": {
        "id": "Ra0ykZmfeOwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explain the concept of feature importance in random forests"
      ],
      "metadata": {
        "id": "F_LmtPhresju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature importance in random forests is a measure of how much each feature contributes to the prediction of the model. It helps in identifying the most influential features in your dataset, which can be crucial for understanding the model and improving its performance. Here’s a detailed explanation:\n",
        "\n",
        "\n",
        "How Feature Importance is Calculated\n",
        "\n",
        "\n",
        "Gini Importance (Mean Decrease in Impurity):\n",
        "\n",
        "\n",
        "This method calculates the importance of a feature by measuring the total decrease in node impurity (e.g., Gini impurity) that the feature brings about across all the trees in the forest. The more a feature decreases the impurity, the more important it is considered.\n",
        "\n",
        "\n",
        "For each feature, the algorithm sums up the impurity decrease for all nodes where the feature is used to split the data, weighted by the number of samples that reach the node.\n",
        "\n",
        "\n",
        "Permutation Importance (Mean Decrease in Accuracy):\n",
        "\n",
        "\n",
        "This method assesses the importance of a feature by measuring the decrease in the model’s accuracy when the values of that feature are randomly shuffled. If shuffling a feature’s values significantly decreases the model’s accuracy, the feature is considered important.\n",
        "This approach provides a more direct measure of a feature’s impact on the model’s performance.\n",
        "\n",
        "\n",
        "Why Feature Importance Matters\n",
        "\n",
        "\n",
        "Enhanced Model Performance:\n",
        "\n",
        "\n",
        "By identifying and focusing on the most important features, you can improve the model’s accuracy and efficiency.\n",
        "\n",
        "\n",
        "Faster Training Times:\n",
        "\n",
        "\n",
        "Reducing the number of features to only the most important ones can streamline the training process, saving time and computational resources.\n",
        "Reduced Overfitting:\n",
        "\n",
        "\n",
        "By focusing on the most relevant features, you can prevent the model from becoming overly reliant on specific data points, thus reducing overfitting."
      ],
      "metadata": {
        "id": "8TAEbkNje05K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the key hyperparameters of a random forest and how do they affect the model?"
      ],
      "metadata": {
        "id": "OCHyI5zQflds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forests have several key hyperparameters that can significantly impact the model's performance. Here's a detailed look at some of the most important ones and how they affect the model:\n",
        "\n",
        "### Key Hyperparameters\n",
        "\n",
        "1. **n_estimators**:\n",
        "   - **Description**: The number of trees in the forest.\n",
        "   - **Effect**: Increasing the number of trees generally improves the model's performance by reducing variance, but it also increases computational cost. The default value is often 100.\n",
        "\n",
        "2. **max_depth**:\n",
        "   - **Description**: The maximum depth of each tree.\n",
        "   - **Effect**: Limiting the depth of the trees can prevent overfitting. Deeper trees can capture more complex patterns but may overfit the training data. The default value is `None`, meaning nodes are expanded until all leaves are pure or contain fewer than `min_samples_split` samples.\n",
        "\n",
        "3. **min_samples_split**:\n",
        "   - **Description**: The minimum number of samples required to split an internal node.\n",
        "   - **Effect**: Higher values prevent the model from learning overly specific patterns, reducing overfitting. Lower values allow the tree to grow deeper and more complex.\n",
        "\n",
        "4. **min_samples_leaf**:\n",
        "   - **Description**: The minimum number of samples required to be at a leaf node.\n",
        "   - **Effect**: Setting this parameter helps in smoothing the model, especially for regression tasks. Higher values can prevent overfitting by ensuring that leaf nodes have enough samples.\n",
        "\n",
        "5. **max_features**:\n",
        "   - **Description**: The number of features to consider when looking for the best split.\n",
        "   - **Effect**: Reducing the number of features can decrease the correlation between trees and improve the model's performance. Common values are `sqrt(n_features)` for classification and `n_features` for regression.\n",
        "\n",
        "6. **bootstrap**:\n",
        "   - **Description**: Whether bootstrap samples are used when building trees.\n",
        "   - **Effect**: If `True`, each tree is trained on a bootstrap sample of the data, which helps in reducing overfitting. If `False`, the entire dataset is used to build each tree.\n",
        "\n",
        "7. **criterion**:\n",
        "   - **Description**: The function to measure the quality of a split (e.g., \"gini\" for Gini impurity or \"entropy\" for information gain).\n",
        "   - **Effect**: Different criteria can lead to different splits and thus different trees. The choice of criterion can affect the model's performance.\n",
        "\n",
        "### Example\n",
        "\n",
        "Here's a simple example in Python using scikit-learn to demonstrate how to set these hyperparameters:\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest with custom hyperparameters\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=4, min_samples_leaf=2, max_features='sqrt', bootstrap=True, criterion='gini')\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "```\n",
        "\n",
        "This code demonstrates how to load a dataset, split it into training and testing sets, train a random forest classifier with custom hyperparameters, and evaluate its accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "TpcaU5Pnfrnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe the logistic regression model and its assumptions?"
      ],
      "metadata": {
        "id": "QZ4aRmohgHhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is a statistical model used for binary classification problems, where the outcome variable is binary (e.g., 0 or 1, true or false, yes or no). It models the probability that a given input point belongs to a particular class.\n",
        "\n",
        "### Key Concepts of Logistic Regression\n",
        "\n",
        "1. **Logit Function**: Logistic regression uses the logit function to model the probability of the binary outcome. The logit function is the natural logarithm of the odds of the outcome occurring.\n",
        "2. **Sigmoid Function**: The logistic function (or sigmoid function) converts the logit into a probability value between 0 and 1.\n",
        "3. **Odds and Log-Odds**: The odds represent the ratio of the probability of the event occurring to the probability of it not occurring. The log-odds is the natural logarithm of the odds.\n",
        "\n",
        "### Assumptions of Logistic Regression\n",
        "\n",
        "1. **Binary Outcome**: The response variable must be binary¹.\n",
        "2. **Independence of Observations**: The observations should be independent of each other.\n",
        "3. **No Multicollinearity**: There should be no high correlation among the predictor variables.\n",
        "4. **Linear Relationship**: There should be a linear relationship between the logit of the outcome and each predictor variable.\n",
        "5. **Large Sample Size**: Logistic regression requires a sufficiently large sample size to provide reliable results.\n",
        "6. **No Extreme Outliers**: The model assumes there are no extreme outliers that can unduly influence the results."
      ],
      "metadata": {
        "id": "PqzTPjr3lJ9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How does logistic regression handle binary classification problems?"
      ],
      "metadata": {
        "id": "DNSlWw08lcN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is specifically designed to handle binary classification problems by modeling the probability that a given input belongs to one of two classes. Here's how it works:\n",
        "\n",
        "### Steps in Logistic Regression for Binary Classification\n",
        "\n",
        "1. **Modeling the Probability**: Logistic regression models the probability that the dependent variable \\( Y \\) belongs to a particular class (e.g., \\( Y = 1 \\)). This probability is denoted as \\( P(Y=1|X) \\), where \\( X \\) represents the independent variables.\n",
        "\n",
        "2. **Logit Function**: The model uses the logit function, which is the natural logarithm of the odds of the event occurring. The logit function is defined as:\n",
        "   $$\n",
        "   \\text{logit}(P) = \\ln\\left(\\frac{P}{1-P}\\right)\n",
        "   $$\n",
        "   where \\( P \\) is the probability of the event occurring.\n",
        "\n",
        "3. **Linear Relationship**: The logit of the probability is modeled as a linear combination of the input features:\n",
        "   $$\n",
        "   \\text{logit}(P) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n\n",
        "   $$\n",
        "   Here, \\( \\beta_0 \\) is the intercept, and \\( \\beta_1, \\beta_2, \\ldots, \\beta_n \\) are the coefficients of the input features \\( X_1, X_2, \\ldots, X_n \\).\n",
        "\n",
        "4. **Sigmoid Function**: The logistic function (or sigmoid function) is used to convert the logit into a probability value between 0 and 1:\n",
        "   $$\n",
        "   P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n)}}\n",
        "   $$\n",
        "\n",
        "5. **Prediction**: For a given input, the model calculates the probability \\( P(Y=1|X) \\). If this probability is greater than a threshold (commonly 0.5), the model predicts the class as 1; otherwise, it predicts the class as 0.\n",
        "\n",
        "### Example\n",
        "\n",
        "Let's say we have a dataset with features like age, income, and education level, and we want to predict whether a person will buy a product (1) or not (0). Logistic regression will:\n",
        "\n",
        "1. Estimate the coefficients for each feature.\n",
        "2. Use these coefficients to calculate the logit for each individual.\n",
        "3. Apply the sigmoid function to get the probability of buying the product.\n",
        "4. Compare the probability to the threshold to make the final prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "QOlVJRs6liSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is the difference between L1 and L2 regularization in logistic regression?"
      ],
      "metadata": {
        "id": "6TE6IHhVlswi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 and L2 regularization are techniques used to prevent overfitting in logistic regression by adding a penalty to the loss function. Here's a breakdown of their differences:\n",
        "\n",
        "### L1 Regularization (Lasso)\n",
        "\n",
        "- **Penalty Term**: Adds the absolute value of the coefficients to the loss function.\n",
        "  $$\n",
        "  \\text{Loss} = \\text{Original Loss} + \\lambda \\sum_{i=1}^{n} |\\beta_i|\n",
        "  $$\n",
        "- **Effect on Coefficients**: Can shrink some coefficients to exactly zero, effectively performing feature selection.\n",
        "- **Use Case**: Useful when you have a large number of features and want to identify the most important ones.\n",
        "\n",
        "### L2 Regularization (Ridge)\n",
        "\n",
        "- **Penalty Term**: Adds the squared value of the coefficients to the loss function.\n",
        "  $$\n",
        "  \\text{Loss} = \\text{Original Loss} + \\lambda \\sum_{i=1}^{n} \\beta_i^2\n",
        "  $$\n",
        "- **Effect on Coefficients**: Shrinks coefficients more evenly, but does not set any of them to zero.\n",
        "- **Use Case**: Useful when you have collinear or highly correlated features and want to reduce their impact without eliminating them.\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "- **Feature Selection**: L1 can perform feature selection by shrinking some coefficients to zero, while L2 does not.\n",
        "- **Penalty Type**: L1 uses the absolute value of coefficients, whereas L2 uses the squared value.\n",
        "- **Impact on Model**: L1 tends to produce sparse models (with fewer features), while L2 tends to produce models where all features are retained but with smaller coefficients.\n",
        "\n"
      ],
      "metadata": {
        "id": "tW3gmN1Fl1Ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is XGBoost and how does it differ from other boosting algorithms?"
      ],
      "metadata": {
        "id": "Uq_osNOamEXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost, short for **eXtreme Gradient Boosting**, is a powerful machine learning algorithm known for its efficiency, speed, and accuracy. It belongs to the family of boosting algorithms, which are ensemble learning techniques that combine the predictions of multiple weak learners to create a strong learner.\n",
        "\n",
        "### Key Features of XGBoost\n",
        "\n",
        "1. **Regularization**: XGBoost includes L1 (Lasso) and L2 (Ridge) regularization terms in the objective function, which helps prevent overfitting and improves model generalization¹.\n",
        "2. **Parallel Processing**: Unlike traditional gradient boosting, XGBoost can build trees in parallel, significantly speeding up the training process⁴.\n",
        "3. **Handling Missing Values**: XGBoost has a built-in mechanism to handle missing values, making it robust for real-world datasets¹.\n",
        "4. **Tree Pruning**: XGBoost uses a more sophisticated algorithm for splitting trees and includes a pruning step to remove splits that add little to no value, enhancing model performance¹.\n",
        "5. **Second-Order Approximation**: It uses a second-order Taylor approximation of the loss function, which provides more accurate estimates of the gradients and improves the optimization process³.\n",
        "\n",
        "### Differences from Other Boosting Algorithms\n",
        "\n",
        "1. **AdaBoost**:\n",
        "   - **Weight Adjustment**: AdaBoost adjusts the weights of incorrectly classified instances, focusing more on hard-to-classify examples in subsequent iterations.\n",
        "   - **No Regularization**: AdaBoost does not include regularization terms, which can lead to overfitting in some cases.\n",
        "\n",
        "2. **Gradient Boosting (GBM)**:\n",
        "   - **Sequential Tree Building**: Traditional GBM builds trees sequentially, which can be slower compared to XGBoost's parallel processing.\n",
        "   - **No Built-in Regularization**: GBM typically does not include regularization terms, whereas XGBoost does, making XGBoost more robust against overfitting.\n",
        "\n",
        "3. **LightGBM**:\n",
        "   - **Leaf-Wise Tree Growth**: LightGBM grows trees leaf-wise rather than level-wise, which can lead to deeper trees and potentially better accuracy.\n",
        "   - **Speed**: LightGBM is designed to be even faster than XGBoost, especially on large datasets with many features.\n",
        "\n",
        "4. **CatBoost**:\n",
        "   - **Categorical Features**: CatBoost is specifically designed to handle categorical features without the need for extensive preprocessing.\n",
        "   - **Symmetric Trees**: CatBoost builds symmetric trees, which can lead to faster predictions and more stable models.\n",
        "\n",
        "### Summary\n",
        "\n",
        "XGBoost stands out due to its regularization techniques, parallel processing capabilities, and advanced optimization methods, making it a popular choice for many machine learning tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "UWUHF6TimJQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explain the concept of boosting in the context of ensemble learning?"
      ],
      "metadata": {
        "id": "deEx7yg-mZcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting is an ensemble learning technique that aims to create a strong classifier from a series of weak classifiers. Here's a detailed look at how it works and its key concepts:\n",
        "\n",
        "### Key Concepts of Boosting\n",
        "\n",
        "1. **Sequential Learning**: Boosting algorithms train models sequentially, with each new model focusing on correcting the errors made by the previous ones.\n",
        "2. **Weighted Data**: Initially, all data points are given equal weight. As the models are trained, the weights of misclassified data points are increased, making the next model focus more on these hard-to-classify examples.\n",
        "3. **Combining Models**: The final prediction is a weighted sum of the predictions from all the models, with more accurate models given higher weights.\n",
        "\n",
        "### How Boosting Works\n",
        "\n",
        "1. **Initialize Weights**: Start with equal weights for all training data points.\n",
        "2. **Train Weak Learner**: Train a weak learner (a model that performs slightly better than random guessing) on the weighted data.\n",
        "3. **Update Weights**: Increase the weights of the misclassified data points so that the next weak learner focuses more on these points.\n",
        "4. **Combine Learners**: Combine the predictions of all weak learners to form a strong final prediction.\n",
        "\n",
        "### Popular Boosting Algorithms\n",
        "\n",
        "1. **AdaBoost (Adaptive Boosting)**: One of the earliest boosting algorithms, AdaBoost adjusts the weights of misclassified instances and combines the weak learners using a weighted majority vote.\n",
        "2. **Gradient Boosting**: This algorithm builds models sequentially, where each new model tries to correct the residual errors of the previous models by optimizing a loss function.\n",
        "3. **XGBoost (eXtreme Gradient Boosting)**: An optimized version of gradient boosting that includes regularization, parallel processing, and other enhancements to improve performance and speed.\n",
        "\n",
        "### Differences from Other Ensemble Methods\n",
        "\n",
        "- **Bagging**: Unlike boosting, bagging (Bootstrap Aggregating) trains multiple models in parallel on different subsets of the data and combines their predictions to reduce variance.\n",
        "- **Stacking**: Stacking involves training multiple models and then using another model to combine their predictions, typically using a meta-learner².\n",
        "\n",
        "### Summary\n",
        "\n",
        "Boosting is a powerful technique that improves model performance by focusing on the mistakes of previous models and combining multiple weak learners into a strong one.\n",
        "\n"
      ],
      "metadata": {
        "id": "TMARNpWimk09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does XGBoost handle missing values?"
      ],
      "metadata": {
        "id": "6957QjE0myuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost handles missing values efficiently and automatically during the training process. Here's how it works:\n",
        "\n",
        "### Handling Missing Values in XGBoost\n",
        "\n",
        "1. **Sparsity Awareness**: XGBoost is designed to handle sparse data, which includes missing values. It treats missing values as a separate category and learns the best way to handle them during training¹.\n",
        "\n",
        "2. **Branch Directions**: During the training of decision trees, XGBoost decides the optimal direction (left or right) for missing values at each split. This decision is based on minimizing the loss function¹².\n",
        "\n",
        "3. **No Imputation Needed**: Unlike some other algorithms, XGBoost does not require explicit imputation of missing values. It inherently manages them, making it robust and easy to use with datasets that have missing entries².\n",
        "\n",
        "4. **Default Handling**: If there are no missing values during training, XGBoost defaults to sending any new missing values to the right node during prediction³.\n",
        "\n",
        "### Example\n",
        "\n",
        "When you train an XGBoost model, you don't need to preprocess your data to handle missing values. The algorithm will automatically learn how to best handle these gaps in the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "N9REzYm0nC81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the key hyperparameters in XGBoost and how do they affect model performance?"
      ],
      "metadata": {
        "id": "iJl8rh6qnL_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost has several key hyperparameters that significantly influence its performance. Here's a breakdown of the most important ones and their effects:\n",
        "\n",
        "### Key Hyperparameters\n",
        "\n",
        "1. **Learning Rate (eta)**:\n",
        "   - **Description**: Controls the step size at each iteration while moving toward a minimum of the loss function.\n",
        "   - **Effect**: Smaller values make the model more robust to overfitting but require more boosting rounds. Typical values range from 0.01 to 0.3.\n",
        "\n",
        "2. **Max Depth (max_depth)**:\n",
        "   - **Description**: The maximum depth of each tree.\n",
        "   - **Effect**: Higher values increase model complexity and risk of overfitting. Typical values range from 3 to 10.\n",
        "\n",
        "3. **Minimum Child Weight (min_child_weight)**:\n",
        "   - **Description**: Minimum sum of instance weight (hessian) needed in a child.\n",
        "   - **Effect**: Higher values prevent overfitting by making the algorithm more conservative. Typical values range from 1 to 10.\n",
        "\n",
        "4. **Subsample**:\n",
        "   - **Description**: Fraction of the training data used for each boosting round.\n",
        "   - **Effect**: Lower values prevent overfitting but can increase variance. Typical values range from 0.5 to 1.0.\n",
        "\n",
        "5. **Colsample_bytree**:\n",
        "   - **Description**: Fraction of features used for each tree.\n",
        "   - **Effect**: Lower values prevent overfitting but can increase variance. Typical values range from 0.5 to 1.0.\n",
        "\n",
        "6. **Gamma**:\n",
        "   - **Description**: Minimum loss reduction required to make a further partition on a leaf node.\n",
        "   - **Effect**: Higher values make the algorithm more conservative. Typical values range from 0 to 10.\n",
        "\n",
        "7. **Regularization Parameters (lambda and alpha)**:\n",
        "   - **Description**: L2 (lambda) and L1 (alpha) regularization terms on weights.\n",
        "   - **Effect**: Control model complexity and prevent overfitting. Higher values make the model more conservative.\n",
        "\n",
        "8. **Number of Boosting Rounds (n_estimators)**:\n",
        "   - **Description**: Number of trees to be built.\n",
        "   - **Effect**: More trees can improve performance but also increase the risk of overfitting.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Tuning these hyperparameters is crucial for optimizing XGBoost's performance. It often involves a trade-off between bias and variance, and the best values depend on the specific dataset and problem at hand.\n",
        "\n"
      ],
      "metadata": {
        "id": "G2BKZ7e6nR9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Describe the process of gradient boosting in XGBoost?"
      ],
      "metadata": {
        "id": "VusBAIiWojuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient boosting in XGBoost is a powerful technique that builds an ensemble of weak learners (typically decision trees) to create a strong predictive model. Here's a step-by-step overview of the process:\n",
        "\n",
        "### Steps in Gradient Boosting with XGBoost\n",
        "\n",
        "1. **Initialize the Model**:\n",
        "   - Start with an initial prediction, often the mean of the target variable for regression or the log-odds for classification.\n",
        "\n",
        "2. **Calculate Residuals**:\n",
        "   - Compute the residuals (errors) of the current model. For each data point, the residual is the difference between the actual value and the predicted value.\n",
        "\n",
        "3. **Fit a Weak Learner**:\n",
        "   - Train a weak learner (e.g., a decision tree) on the residuals. This weak learner aims to predict the residuals from the previous step.\n",
        "\n",
        "4. **Update the Model**:\n",
        "   - Add the predictions of the weak learner to the current model. This step updates the model to reduce the residuals.\n",
        "\n",
        "5. **Apply Regularization**:\n",
        "   - XGBoost includes regularization terms (L1 and L2) in the objective function to prevent overfitting and improve generalization¹.\n",
        "\n",
        "6. **Repeat**:\n",
        "   - Repeat steps 2-5 for a specified number of iterations or until the residuals are minimized. Each iteration adds a new weak learner to the ensemble.\n",
        "\n",
        "7. **Combine Predictions**:\n",
        "   - The final prediction is a weighted sum of the predictions from all the weak learners. The weights are determined by the learning rate and the performance of each learner.\n",
        "\n",
        "### Key Features of XGBoost\n",
        "\n",
        "- **Second-Order Approximation**: XGBoost uses a second-order Taylor approximation of the loss function, which provides more accurate gradient estimates and improves optimization.\n",
        "- **Parallel Processing**: XGBoost can build trees in parallel, significantly speeding up the training process.\n",
        "- **Handling Missing Values**: XGBoost has a built-in mechanism to handle missing values, making it robust for real-world datasets.\n",
        "- **Tree Pruning**: XGBoost prunes trees by removing splits that add little to no value, enhancing model performance.\n",
        "\n",
        "### Example\n",
        "\n",
        "Imagine you have a dataset with features like age, income, and education level, and you want to predict whether a person will buy a product (1) or not (0). XGBoost will:\n",
        "\n",
        "1. Start with an initial prediction (e.g., the average probability of buying the product).\n",
        "2. Calculate the residuals for each data point.\n",
        "3. Train a decision tree on these residuals.\n",
        "4. Update the model by adding the tree's predictions.\n",
        "5. Repeat the process, adding more trees to reduce the residuals further.\n",
        "\n"
      ],
      "metadata": {
        "id": "EAMz1t5cprD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What are the advantages and disadvantages of using XGBoost?"
      ],
      "metadata": {
        "id": "0X1XDnUep3ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost is a highly popular and powerful machine learning algorithm, especially known for its performance in structured data problems. Here are some of its key advantages and disadvantages:\n",
        "\n",
        "### Advantages\n",
        "\n",
        "1. **High Performance and Accuracy**:\n",
        "   - XGBoost often achieves state-of-the-art results in many machine learning competitions and real-world applications.\n",
        "\n",
        "2. **Efficient Handling of Missing Values**:\n",
        "   - It can handle missing values internally, making it robust for datasets with incomplete data.\n",
        "\n",
        "3. **Built-in Regularization**:\n",
        "   - Includes L1 (Lasso) and L2 (Ridge) regularization terms to prevent overfitting and improve model generalization.\n",
        "\n",
        "4. **Parallel Processing**:\n",
        "   - XGBoost can build trees in parallel, significantly speeding up the training process.\n",
        "\n",
        "5. **Scalability**:\n",
        "   - It scales well to large datasets and can handle millions of instances efficiently.\n",
        "\n",
        "6. **Feature Importance**:\n",
        "   - Provides feature importance scores, which help in understanding the impact of different features on the model's predictions.\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "1. **Parameter Tuning**:\n",
        "   - Requires careful tuning of hyperparameters to achieve optimal performance, which can be time-consuming.\n",
        "\n",
        "2. **Computationally Expensive**:\n",
        "   - Training can be computationally intensive, especially with large datasets.\n",
        "\n",
        "3. **Complexity**:\n",
        "   - The model can become complex and difficult to interpret, making it challenging to understand the underlying decision process.\n",
        "\n",
        "4. **Sensitivity to Noisy Data**:\n",
        "   - Can be sensitive to noisy data and outliers, which may affect the model's performance.\n",
        "\n",
        "5. **Not Ideal for High-Dimensional Sparse Data**:\n",
        "   - May not perform as well with high-dimensional sparse data compared to other algorithms.\n",
        "\n",
        "### Summary\n",
        "\n",
        "XGBoost is a powerful tool for many predictive modeling tasks, particularly when dealing with structured data. However, it requires careful tuning and can be computationally demanding. Understanding its strengths and limitations can help you decide when and how to use it effectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "b0QZ-gGGqSjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***THANK YOU***###"
      ],
      "metadata": {
        "id": "UqGQmTqzqryH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}